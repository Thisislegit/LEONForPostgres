{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 示例数据\n",
    "models = [\"Tree_conv\", \"Transformer\", \"Tree_transformer\"]\n",
    "categories = [\"Analysis\", \"Encoding\", \"Inference\"]\n",
    "\n",
    "data = {\n",
    "    \"Tree_conv\": {\n",
    "        \"Analysis\": 1.699415797899809e-05,\n",
    "        \"Encoding\": 0.32585111174058884,\n",
    "        \"Inference\": 0.011281246731840956\n",
    "    },\n",
    "    \"Transformer\": {\n",
    "        \"Analysis\": 1.5631804619756436e-05,\n",
    "        \"Encoding\": 0.18211924681502545,\n",
    "        \"Inference\": 0.004838372474140837\n",
    "    },\n",
    "    \"Tree_transformer\": {\n",
    "        \"Analysis\": 1.7068361274007607e-05,\n",
    "        \"Encoding\": 0.3275578327122506,\n",
    "        \"Inference\": 0.020449148399678294\n",
    "    }\n",
    "}\n",
    "\n",
    "# 绘制柱状图\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "bar_width = 0.2\n",
    "bar_positions = np.arange(len(models))\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    values = [data[model][category] for model in models]\n",
    "    ax.bar(bar_positions + i * bar_width, values, bar_width, label=category)\n",
    "\n",
    "# 设置坐标轴标签和标题\n",
    "ax.set_xticks(bar_positions + bar_width)\n",
    "ax.set_xticklabels(models)\n",
    "ax.set_yscale('log')  # 设置纵坐标为对数坐标\n",
    "ax.set_ylabel('Log Scale')\n",
    "\n",
    "# 添加图例\n",
    "ax.legend()\n",
    "\n",
    "plt.savefig('./bar_chart.svg', format='svg', bbox_inches='tight')\n",
    "# 显示图形\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_scientific_notation(number):\n",
    "    # 将科学计数法转为字符串\n",
    "    str_number = \"{:e}\".format(number)\n",
    "    # 分离有效数字和指数部分\n",
    "    mantissa, exponent = str_number.split('e')\n",
    "    # 将有效数字转为浮点数，以便进行格式化\n",
    "    mantissa = 9.994 if float(mantissa) >= 9.995 else float(mantissa)\n",
    "    # 限制有效位数为两位\n",
    "    mantissa = format(mantissa, '.2f')\n",
    "    # 将指数部分转为整数\n",
    "    exponent = int(exponent)\n",
    "    # 限制指数的范围在[-9, 9]之间\n",
    "    exponent = max(-9, min(9, exponent))\n",
    "    # 输出格式化后的结果\n",
    "    result = \"{},{},{:d}\".format(mantissa, '1' if exponent >= 0 else '0', abs(exponent))\n",
    "    return result\n",
    "\n",
    "# 示例\n",
    "number = 9.998\n",
    "result = format_scientific_notation(number)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# 生成示例数据\n",
    "\n",
    "\n",
    "with open('./pg.txt','rb') as f:\n",
    "    y1_values = pickle.load(f)\n",
    "with open('./tf.txt','rb') as f:\n",
    "    y2_values = pickle.load(f)\n",
    "\n",
    "num_data_points = len(y1_values)\n",
    "x_values = np.linspace(0, len(y1_values), len(y1_values))\n",
    "\n",
    "# 绘制折线图\n",
    "plt.plot(x_values, y1_values, label='pg')\n",
    "plt.plot(x_values, y2_values, label='tf')\n",
    "\n",
    "# 设置坐标轴标签和标题\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Line Chart with Two Labels')\n",
    "\n",
    "# 添加图例\n",
    "plt.legend()\n",
    "\n",
    "# 显示图形\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# 生成示例数据\n",
    "with open('./log/pg10.txt', 'rb') as f:\n",
    "    y1_values = pickle.load(f)\n",
    "with open('./log/tf10.txt', 'rb') as f:\n",
    "    y2_values = pickle.load(f)\n",
    "\n",
    "# y1_values = [894, 892, 902, 859, 865, 881, 892, 845, 866, 869, 885, 898, 891, 887, 880, 882, 879, 876, 825, 816, 878, 872, 875, 861, 870, 870, 871, 861, 904, 883, 889, 872, 880, 872, 889, 883, 904, 861, 871, 870]\n",
    "\n",
    "# y2_values = [990, 561, 533, 517, 1019, 561, 1026, 568, 541, 978, 552, 567, 1008, 428, 1013, 525, 513, 516, 483, 1448, 539, 530, 432, 946, 1441, 499, 2623, 980, 1000, 488, 620, 507, 947, 505, 620, 488, 1000, 980, 2623, 499]\n",
    "num_data_points = len(y1_values)\n",
    "x_labels = range(0, len(y1_values), 1)\n",
    "\n",
    "# 设置图形大小\n",
    "plt.figure(figsize=(30, 5))\n",
    "\n",
    "# 绘制折线图，设置线的透明度为50%\n",
    "plt.plot(x_labels, y1_values, label='pg', alpha=0.5)\n",
    "plt.plot(x_labels, y2_values, label='tf', alpha=0.5)\n",
    "\n",
    "# 设置坐标轴标签和标题\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Line Chart with Two Labels')\n",
    "\n",
    "# 设置 x 轴刻度和标签\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# 添加图例\n",
    "plt.legend(fontsize='large')\n",
    "\n",
    "# 显示图形\n",
    "plt.show()\n",
    "print(len(y1_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# 生成示例数据\n",
    "with open('./log/pg1.txt', 'rb') as f:\n",
    "    y1_values = pickle.load(f)\n",
    "with open('./log/tf1.txt', 'rb') as f:\n",
    "    y2_values = pickle.load(f)\n",
    "\n",
    "num_data_points = len(y1_values)\n",
    "x_labels =  ['1a', '1b', '1c', '1d', '2a', '2b', '2c', '2d', '3a', '3b', '3c', '4a',\n",
    "             '4b', '4c', '5a', '5b', '5c', '6a', '6b', '6c', '6d', '6e', '6f', '7a', \n",
    "             '7b', '7c', '8a', '8b', '8c', '8d', '9a', '9b', '9c', '9d', '10a', '10b', \n",
    "             '10c', '11a', '11b', '11c', '11d', '12a', '12b', '12c', '13a', '13b', '13c', \n",
    "             '13d', '14a', '14b', '14c', '15a', '15b', '15c', '15d', '16a', '16b', '16c',\n",
    "             '16d', '17a', '17b', '17c', '17d', '17e', '17f', '18a', '18b', '18c', '19a',\n",
    "             '19b', '19c', '19d', '20a', '20b', '20c', '21a', '21b', '21c', '22a', '22b']\n",
    "\n",
    "# 设置图形大小\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "# 绘制柱状图\n",
    "bar_width = 0.4\n",
    "bar_positions1 = np.arange(len(x_labels))\n",
    "bar_positions2 = bar_positions1 + bar_width\n",
    "\n",
    "plt.bar(bar_positions1, y1_values, width=bar_width, label='pg', alpha=0.5)\n",
    "plt.bar(bar_positions2, y2_values, width=bar_width, label='tf', alpha=0.5)\n",
    "\n",
    "# 设置坐标轴标签和标题\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Bar Chart with Two Labels')\n",
    "\n",
    "# 设置 x 轴刻度和标签\n",
    "plt.xticks(bar_positions1 + bar_width / 2, x_labels, rotation=45, ha='right')\n",
    "\n",
    "# 添加图例\n",
    "plt.legend(fontsize='large')\n",
    "\n",
    "# 显示图形\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# 生成示例数据\n",
    "with open('./log/pg5.txt', 'rb') as f:\n",
    "    y1_values = pickle.load(f)\n",
    "with open('./log/tf5.txt', 'rb') as f:\n",
    "    y2_values = pickle.load(f)\n",
    "\n",
    "num_data_points = len(y1_values)\n",
    "x_labels =  ['1a', '1b', '1c', '1d', '2a', '2b', '2c', '2d', '3a', '3b', '3c', '4a',\n",
    "             '4b', '4c', '5a', '5b', '5c', '6a', '6b', '6c', '6d', '6e', '6f', '7a', \n",
    "             '7b', '7c', '8a', '8b', '8c', '8d', '9a', '9b', '9c', '9d', '10a', '10b', \n",
    "             '10c', '11a', '11b', '11c', '11d', '12a', '12b', '12c', '13a', '13b', '13c', \n",
    "             '13d', '14a', '14b', '14c', '15a', '15b', '15c', '15d', '16a', '16b', '16c',\n",
    "             '16d', '17a', '17b', '17c', '17d', '17e', '17f', '18a', '18b', '18c', '19a',\n",
    "             '19b', '19c', '19d', '20a', '20b', '20c', '21a', '21b', '21c', '22a', '22b',\n",
    "             '22c', '22d', '23a', '23b', '23c', '24a', '24b', '25a', '25b', '25c', '26a', \n",
    "             '26b', '26c', '27a', '27b', '27c', '28a', '28b', '28c']\n",
    "\n",
    "# 设置图形大小\n",
    "plt.figure(figsize=(25, 5))\n",
    "\n",
    "# 绘制柱状图，设置线的透明度为50%\n",
    "bar_width = 0.4\n",
    "bar_positions1 = np.arange(len(x_labels))\n",
    "bar_positions2 = bar_positions1 + bar_width\n",
    "\n",
    "plt.bar(bar_positions1, y1_values, width=bar_width, label='pg', alpha=0.5)\n",
    "plt.bar(bar_positions2, y2_values, width=bar_width, label='tf', alpha=0.5)\n",
    "\n",
    "# 设置坐标轴标签和标题\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis (log scale)')\n",
    "plt.title('Bar Chart with Two Labels (log scale)')\n",
    "\n",
    "# 设置 x 轴刻度和标签\n",
    "plt.xticks(bar_positions1 + bar_width / 2, x_labels, rotation=45, ha='right')\n",
    "\n",
    "# 设置 y 轴为对数刻度\n",
    "# plt.yscale('log')\n",
    "\n",
    "# 添加图例\n",
    "plt.legend(fontsize='large')\n",
    "\n",
    "# 显示图形\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# 生成示例数据\n",
    "with open('./log/pg2.txt', 'rb') as f:\n",
    "    y1_values = pickle.load(f)\n",
    "with open('./log/tf2.txt', 'rb') as f:\n",
    "    y2_values = pickle.load(f)\n",
    "# with open('./log/tf3.txt', 'rb') as f:\n",
    "#     y3_values = pickle.load(f)\n",
    "y3_values = [4197.779, 6310.663, 2685.923, 6786.553]\n",
    "y3_values += [0] * (len(y2_values) - len(y3_values))\n",
    "num_data_points = len(y1_values)\n",
    "x_labels =  ['1a', '1b', '1c', '1d', '2a', '2b', '2c', '2d', '3a', '3b', '3c', '4a',\n",
    "             '4b', '4c', '5a', '5b', '5c', '6a', '6b', '6c', '6d', '6e', '6f', '7a', \n",
    "             '7b', '7c', '8a', '8b', '8c', '8d', '9a', '9b', '9c', '9d', '10a', '10b', \n",
    "             '10c', '11a', '11b', '11c', '11d', '12a', '12b', '12c', '13a', '13b', '13c', \n",
    "             '13d', '14a', '14b', '14c', '15a', '15b', '15c', '15d', '16a', '16b', '16c',\n",
    "             '16d', '17a', '17b', '17c', '17d', '17e', '17f', '18a', '18b', '18c', '19a',\n",
    "             '19b', '19c', '19d', '20a', '20b', '20c', '21a', '21b', '21c', '22a', '22b',\n",
    "             '22c', '22d', '23a', '23b', '23c', '24a', '24b', '25a', '25b', '25c', '26a', \n",
    "             '26b', '26c', '27a', '27b', '27c', '28a', '28b', '28c']\n",
    "\n",
    "# 设置图形大小\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# 绘制柱状图，设置线的透明度为50%\n",
    "bar_width = 0.2\n",
    "bar_positions1 = np.arange(len(x_labels))\n",
    "bar_positions2 = bar_positions1 + bar_width\n",
    "bar_positions3 = bar_positions2 + bar_width\n",
    "\n",
    "plt.bar(bar_positions1, y1_values, width=bar_width, label='pg', alpha=0.5)\n",
    "plt.bar(bar_positions2, y2_values, width=bar_width, label='tf_par', alpha=0.5)\n",
    "plt.bar(bar_positions3, y3_values, width=bar_width, label='tf_no', alpha=0.5)\n",
    "\n",
    "# 设置坐标轴标签和标题\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Bar Chart with Two Labels (log scale)')\n",
    "\n",
    "# 设置 x 轴刻度和标签\n",
    "plt.xticks(bar_positions1 + bar_width / 2, x_labels, rotation=45, ha='right')\n",
    "\n",
    "# 设置 y 轴为对数刻度\n",
    "# plt.yscale('log')\n",
    "\n",
    "# 添加图例\n",
    "plt.legend(fontsize='large')\n",
    "\n",
    "# 显示图形\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# # 生成示例数据\n",
    "# with open('./log/pg5.txt', 'rb') as f:\n",
    "#     a = pickle.load(f)\n",
    "# with open('./log/tf5.txt', 'rb') as f:\n",
    "#     b = pickle.load(f)\n",
    "a = [894, 892, 902, 859, 865, 881, 892, 845, 866, 869, 885, 898, 891, 887, 880, 882, 879, 876, 825, 816, 878, 872, 875, 861, 870, 870, 871, 861, 904, 883, 889, 872, 880, 872, 889, 883, 904, 861, 871, 870]\n",
    "\n",
    "b = [990, 561, 533, 517, 1019, 561, 1026, 568, 541, 978, 552, 567, 1008, 428, 1013, 525, 513, 516, 483, 1448, 539, 530, 432, 946, 1441, 499, 2623, 980, 1000, 488, 620, 507, 947, 505, 620, 488, 1000, 980, 2623, 499]\n",
    "# x_labels =  ['1a', '1b', '1c', '1d', '2a', '2b', '2c', '2d', '3a', '3b', '3c', '4a',\n",
    "#              '4b', '4c', '5a', '5b', '5c', '6a', '6b', '6c', '6d', '6e', '6f', '7a', \n",
    "#              '7b', '7c', '8a', '8b', '8c', '8d', '9a', '9b', '9c', '9d', '10a', '10b', \n",
    "#              '10c', '11a', '11b', '11c', '11d', '12a', '12b', '12c', '13a', '13b', '13c', \n",
    "#              '13d', '14a', '14b', '14c', '15a', '15b', '15c', '15d', '16a', '16b', '16c',\n",
    "#              '16d', '17a', '17b', '17c', '17d', '17e', '17f', '18a', '18b', '18c', '19a',\n",
    "#              '19b', '19c', '19d', '20a', '20b', '20c', '21a', '21b', '21c', '22a', '22b',\n",
    "#              '22c', '22d', '23a', '23b', '23c', '24a', '24b', '25a', '25b', '25c', '26a', \n",
    "#              '26b', '26c', '27a', '27b', '27c', '28a', '28b', '28c']\n",
    "print(len(a))\n",
    "sum = 0\n",
    "sum1 = 0\n",
    "sum2 = 0\n",
    "sum3 = 0\n",
    "x = []\n",
    "for i in range(0, len(a)):\n",
    "    if(a[i] > b[i]):\n",
    "        x.append(x_labels[i])\n",
    "        sum += 1\n",
    "    sum1 += a[i]\n",
    "    sum2 += b[i]\n",
    "    sum3 += 0 if b[i] == b[-1] else b[i]\n",
    "print(sum)\n",
    "print(sum1)\n",
    "print(sum2)\n",
    "print(sum3)\n",
    "print(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.rand((3,20)) # 720\n",
    "b = a.view(3,4,5) # 40 18 \n",
    "c = a.view(3,5,4).transpose(1,2)\n",
    "print(a)\n",
    "print(c)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from leon_pl import *\n",
    "sqls_chunk = load_sql(['8c'])\n",
    "query_latency2, json_dict = getPG_latency(sqls_chunk[0], ENABLE_LEON=True, timeout_limit=0)\n",
    "node = postgres.ParsePostgresPlanJson(json_dict)\n",
    "print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hint_node = plans_lib.FilterScansOrJoins(node.Copy())\n",
    "hint_node.info['latency'], json = getPG_latency(sqls_chunk[0], hint_node.hint_str(), ENABLE_LEON=False, timeout_limit=0) # timeout 10s\n",
    "node1 = postgres.ParsePostgresPlanJson(json)\n",
    "print(node1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query_latency2)\n",
    "print(hint_node.info['latency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "cali_all = torch.tensor([1.111, 1100])\n",
    "cali_all = random_tensor = 10 * torch.rand(cali_all.shape[0])\n",
    "def format_scientific_notation(number):\n",
    "            str_number = \"{:e}\".format(number)\n",
    "            mantissa, exponent = str_number.split('e')\n",
    "            mantissa = 9.994 if float(mantissa) >= 9.995 else float(mantissa)\n",
    "            mantissa = format(mantissa, '.2f')\n",
    "            exponent = int(exponent)\n",
    "            exponent = max(-9, min(9, exponent))\n",
    "            result = \"{},{},{:d}\".format(mantissa, '1' if exponent >= 0 else '0', abs(exponent))\n",
    "            return result\n",
    "cali_str = [format_scientific_notation(i) for i in cali_all.tolist()]\n",
    "print(cali_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "# 示例用法\n",
    "import os\n",
    "\n",
    "folder_path = 'job'  # 请根据实际文件夹路径进行设置\n",
    "a =[]\n",
    "# 获取文件夹中的所有文件\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# 遍历每个文件并处理\n",
    "for file_name in files:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    # 判断是否为文件\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            # 读取文件内容\n",
    "            content = file.read()\n",
    "            from_where_content = re.search('FROM(.*)WHERE', content.replace(\"\\n\", \"\")).group(1)\n",
    "\n",
    "            # 提取别名\n",
    "            aliases = re.findall(r'AS (\\w+)', from_where_content)\n",
    "\n",
    "            aliases = \",\".join(sorted(aliases))\n",
    "            a.append(aliases)\n",
    "\n",
    "print(a)  # 输出: ['ct', 'it', 'mc', 'mi_idx', 't']\n",
    "\n",
    "print(\"处理完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./log/exp_v4.pkl', 'rb') as f:\n",
    "    exp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = None\n",
    "sum = 0\n",
    "for plan in exp['chn,ci,cn,ct,mc,rt,t']:\n",
    "    node = plan[0]\n",
    "    if node.info['sql_str'] != sql:\n",
    "        sql = node.info['sql_str']\n",
    "        sum += 1\n",
    "    print(sum)\n",
    "    print(node.info['latency'])\n",
    "    print(node.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from pympler import asizeof\n",
    "import gc\n",
    "from enum import Enum\n",
    "i = 0\n",
    "while True:\n",
    "    print(i)\n",
    "    i += 1\n",
    "    with open('./log/exp_v4.pkl', 'rb') as f:\n",
    "        exp = pickle.load(f)\n",
    "    del exp\n",
    "    gc.collect()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureType(Enum):\n",
    "    numeric = \"numeric\"\n",
    "    categorical = \"categorical\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_size = asizeof.asizeof(exp['an,chn,ci,cn,it,mc,mi,n,rt,t'])\n",
    "\n",
    "# 将字节数转换为 MB\n",
    "total_size_in_mb = total_size / (1024.0 ** 2)\n",
    "\n",
    "# 打印结果\n",
    "print(f\"The total size of my_dict and its references is approximately: {total_size_in_mb:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_elements = [sublist[1] for sublist in exp['an,chn,ci,cn,it,mc,mi,n,rt,t']]\n",
    "first_elements[0].shape\n",
    "memory_size_bytes = first_elements[0].element_size() * first_elements[0].numel()\n",
    "\n",
    "# 将字节数转换为 MB\n",
    "memory_size_mb = memory_size_bytes / (1024.0 ** 2)\n",
    "\n",
    "# 打印结果\n",
    "print(f\"The memory size of the tensor is approximately: {memory_size_mb:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pympler import muppy, summary\n",
    "all_objects = muppy.get_objects()\n",
    "sum1 = summary.summarize(all_objects)# Prints out a summary of the large objects\n",
    "summary.print_(sum1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "def get_statistic(exp):\n",
    "    plans = exp\n",
    "\n",
    "    # get statistics\n",
    "    db_plans = {}\n",
    "    db_max_node_len = 0\n",
    "    runtimes = []\n",
    "    cards = []\n",
    "    costs = []\n",
    "\n",
    "    # get all node types, including subplan, implement by dfs\n",
    "    node_types = set()\n",
    "    for eq in exp.keys():\n",
    "        for plan in exp[eq]:\n",
    "            plan = plan[0]\n",
    "            try:\n",
    "                runtimes.append(plan.info['latency'])\n",
    "            except:\n",
    "                pass\n",
    "            costs.append(plan.cost)\n",
    "            cards.append(0)\n",
    "            node_types.add(plan.node_type)\n",
    "            stack = [plan]\n",
    "            node_len = 1\n",
    "            while len(stack) > 0:\n",
    "                node = stack.pop()\n",
    "                for child in node.children:\n",
    "                    node_len += 1\n",
    "                    node_types.add(child.node_type)\n",
    "                    stack.append(child)\n",
    "                    try:\n",
    "                        runtimes.append(child.info['latency'])\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    costs.append(child.cost)\n",
    "                    cards.append(0)\n",
    "            db_max_node_len = max(db_max_node_len, node_len)\n",
    "    print(db_max_node_len)\n",
    "\n",
    "    runtimes, cards, costs = np.array(runtimes), np.array(cards), np.array(costs)\n",
    "\n",
    "    # write to a json file\n",
    "    node_types = list(node_types)\n",
    "    statistics = {\n",
    "        \"Actual Total Time\": {\n",
    "            \"type\": str(FeatureType.numeric),\n",
    "            \"max\": float(np.max(runtimes)),\n",
    "            \"min\": float(np.min(runtimes)),\n",
    "            \"center\": float(np.median(runtimes)),\n",
    "            \"scale\": float(np.quantile(runtimes, 0.75))\n",
    "            - float(np.quantile(runtimes, 0.25)),\n",
    "        },\n",
    "        \"Plan Rows\": {\n",
    "            \"type\": str(FeatureType.numeric),\n",
    "            \"max\": float(np.max(cards)),\n",
    "            \"min\": float(np.min(cards)),\n",
    "            \"center\": float(np.median(cards)),\n",
    "            \"scale\": float(np.quantile(cards, 0.75)) - float(np.quantile(cards, 0.25)),\n",
    "        },\n",
    "        \"Total Cost\": {\n",
    "            \"type\": str(FeatureType.numeric),\n",
    "            \"max\": float(np.max(costs)),\n",
    "            \"min\": float(np.min(costs)),\n",
    "            \"center\": float(np.median(costs)),\n",
    "            \"scale\": float(np.quantile(costs, 0.75)) - float(np.quantile(costs, 0.25)),\n",
    "        },\n",
    "        \"node_types\": {\n",
    "            \"type\": str(FeatureType.categorical),\n",
    "            \"value_dict\": {node_type: i for i, node_type in enumerate(node_types)},\n",
    "        },\n",
    "    }\n",
    "    return statistics\n",
    "\n",
    "statistics = get_statistic(exp)\n",
    "with open(os.getcwd() + '/statistics1.json', \"w\") as f:\n",
    "    json.dump(statistics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_id='1,2,3,4,5,6'\n",
    "len(join_id.split(','))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 假设输入张量 x 的形状为 512 * 40 * node_length\n",
    "x = torch.rand((512, 40, 18))\n",
    "\n",
    "# 将 x 展平成二维张量\n",
    "# x = x.view(-1, 18)\n",
    "\n",
    "# 定义 nn.Sequential\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(18, 32),\n",
    "    nn.ReLU(),  # 假设你的激活函数是 ReLU\n",
    "    nn.Linear(32, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 32)\n",
    ")\n",
    "\n",
    "# 将 x_flattened 输入到 MLP 中\n",
    "output = mlp(x)\n",
    "\n",
    "# 输出的形状为 20480 * 32，即 (512 * 40) * 32\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class EqSetInfo:\n",
    "    first_latency: float = 90000.0\n",
    "    current_latency: float = 90000.0\n",
    "    opt_time: float = 0.0\n",
    "    query_ids: List[str] = field(default_factory=list)\n",
    "\n",
    "# 示例数据\n",
    "all_set = [(1, EqSetInfo(query_ids=['1a', '2a'], opt_time=0.0)),\n",
    "           (2, EqSetInfo(query_ids=['3a', '4a'], opt_time=10.0)),\n",
    "           (3, EqSetInfo(query_ids=['5a', '6a'], opt_time=-5.0)),\n",
    "           (4, EqSetInfo(query_ids=['5a', '6a'], opt_time=0.0)),\n",
    "           (5, EqSetInfo(query_ids=['2a', '6a'], opt_time=5.0)),\n",
    "           (6, EqSetInfo(query_ids=['5a', '6a'], opt_time=0.0)),\n",
    "           (7, EqSetInfo(query_ids=['5a', '6a'], opt_time=-5.0)),\n",
    "           (8, EqSetInfo(query_ids=['5a', '6a'], opt_time=0.0))]\n",
    "\n",
    "sql_id = ['1a']\n",
    "\n",
    "# 过滤条件\n",
    "updated_set = [item for item in all_set if not (any(x in sql_id for x in item[1].query_ids) or item[1].opt_time==0)]\n",
    "\n",
    "# 打印结果\n",
    "for item in updated_set:\n",
    "    print(item[0], item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个1400x720的tensor，默认使用float32数据类型\n",
    "tensor_var = torch.zeros(1400, 720)\n",
    "\n",
    "# 获取tensor的数据类型\n",
    "dtype = tensor_var.dtype\n",
    "\n",
    "# 获取tensor的元素个数\n",
    "num_elements = tensor_var.numel()\n",
    "\n",
    "# 计算内存占用\n",
    "memory_size_bytes = num_elements * dtype.itemsize\n",
    "\n",
    "# 将字节数转换为兆字节\n",
    "memory_size_mb = memory_size_bytes / (1024 ** 2)\n",
    "\n",
    "print(f\"Tensor size: {memory_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def fix_json_msg(json):\n",
    "    # pattern_any = r'ANY \\((.*?):text\\[\\]\\)'\n",
    "    pattern_all = r'(ANY|ALL) \\((.*?):text\\[\\]\\)'\n",
    "\n",
    "    # matches_any = re.findall(pattern_any, json)\n",
    "    matches_all = re.findall(pattern_all, json)\n",
    "\n",
    "    # for match in matches_any:\n",
    "    #     extracted_string = match\n",
    "    #     cleaned_string = extracted_string.replace('\"', '')\n",
    "    #     json = json.replace(f'ANY ({extracted_string}):text[]', cleaned_string)\n",
    "    \n",
    "    for match_type, match in matches_all:\n",
    "        extracted_string = match\n",
    "        cleaned_string = extracted_string.replace('\"', '')\n",
    "        json = json.replace(extracted_string, cleaned_string)\n",
    "\n",
    "    return json\n",
    "\n",
    "json_data = '\"Base Restrict Info\": \"((mi.info)::text <> ALL (\\'{MET:,UK,Color,\\\"Black and White\\\"}\\'::text[]))\" '\n",
    "fixed_json = fix_json_msg(json_data)\n",
    "print(fixed_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_list_to_disk(file_path, data):\n",
    "    with open(file_path, 'ab') as file:\n",
    "        pickle.dump(data, file)\n",
    "\n",
    "def data_generator(file_path, batch_size=1000):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        try:\n",
    "            while True:\n",
    "                batch = []\n",
    "                for _ in range(batch_size):\n",
    "                    try:\n",
    "                        item = pickle.load(file)\n",
    "                        batch.append(item)\n",
    "                    except EOFError:\n",
    "                        break\n",
    "                \n",
    "                if not batch:\n",
    "                    break\n",
    "                \n",
    "                yield batch\n",
    "        except EOFError:\n",
    "            pass\n",
    "\n",
    "def process_batch(batch):\n",
    "    # 在这里对批次进行处理，这里简单地打印每个元素\n",
    "    print(batch)\n",
    "    # for item in batch:\n",
    "    #     print(item)\n",
    "\n",
    "# 生成示例数据\n",
    "large_list = list(range(999))\n",
    "for i in range(1000):\n",
    "    save_list_to_disk('large_list.pkl', [i])\n",
    "\n",
    "# 使用生成器逐批次读取和处理数据\n",
    "file_path = 'large_list.pkl'\n",
    "generator = data_generator(file_path, batch_size=100)\n",
    "print(generator)\n",
    "# for batch in generator:\n",
    "#     # print(len(batch[0]))\n",
    "#     process_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "# 创建 PyTorch 张量\n",
    "def fun():\n",
    "    a = torch.randn((90000, 1000, 27), device='cuda:3')\n",
    "\n",
    "# 删除张量\n",
    "# del a\n",
    "fun()\n",
    "# 清空 GPU 缓存\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_list = [torch.randint(0, 10, (y, 1)) for y in range(5, 8)]\n",
    "indexes_list[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/wyz/miniconda3/envs/leon/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-01-10 08:35:04,793\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read Workload: job\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['chn,ci,cn,ct,mc,rt,t', 'at,cn,ct,it1,k,mc,mi,mk,t', 'ct,it,mc,mi_idx,t', 'cn,ct,it1,it2,mc,mi,mi_idx,t', 'an1,ci,cn,mc,n1,rt,t', 'ci,k,mk,n,t', 'cn,ct,it1,it2,k,kt,mc,mi,mi_idx,mk,t', 'cc,cct1,cct2,ci,it1,it2,k,mi,mi_idx,mk,n,t', 'it1,it2,k,kt,mi,mi_idx,mk,t', 'cn,ct,it,it2,kt,mc,mi,miidx,t', 'cn,ct,k,lt,mc,mi,mk,ml,t', 'cn,ct,k,lt,mc,mk,ml,t', 'cc,cct1,cct2,cn,ct,k,lt,mc,mi,mk,ml,t', 'an,chn,ci,cn,it,k,mc,mi,mk,n,rt,t', 'an,ci,it,lt,ml,n,pi,t', 'an,cc,cct1,cct2,chn,ci,cn,it,it3,k,mc,mi,mk,n,pi,rt,t', 'k,lt,mk,ml,t1,t2', 'cn,k,mc,mk,t', 'cc,cct1,cct2,chn,ci,it2,k,kt,mi_idx,mk,n,t', 'cc,cct1,cn,ct,it1,k,kt,mc,mi,mk,t', 'cc,cct1,cct2,chn,ci,k,kt,mk,n,t', 'ct,it,mc,mi,t', 'a1,ci,cn,mc,n1,rt,t', 'an,chn,ci,cn,it,mc,mi,n,rt,t', 'an,ci,cn,mc,n,rt,t', 'cc,cct1,cct2,cn,ct,it1,it2,k,kt,mc,mi,mi_idx,mk,t', 'it,k,mi_idx,mk,t', 'aka_t,cn,ct,it1,k,mc,mi,mk,t', 'ci,cn,k,mc,mk,n,t', 'an,chn,ci,cn,mc,n,rt,t', 'k,mi,mk,t', 'ci,it1,it2,mi,mi_idx,n,t', 'cn1,cn2,it1,it2,kt1,kt2,lt,mc1,mc2,mi_idx1,mi_idx2,ml,t1,t2', 'an,ci,cn,k,mc,mk,n,t', 'ci,it1,it2,k,mi,mi_idx,mk,n,t', 'ci,cn,it1,it2,k,mc,mi,mi_idx,mk,n,t'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from util import envs, plans_lib, treeconv, encoding\n",
    "with open('./log/exp_v4.pkl', 'rb') as f:\n",
    "    exp = pickle.load(f)\n",
    "model = torch.load('./log/model.pth')\n",
    "workload = envs.wordload_init('job')\n",
    "nodeFeaturizer = plans_lib.TreeNodeFeaturizer_V2(workload.workload_info)\n",
    "exp.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./log/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./log/exp_v4.pkl', 'rb') as f:\n",
    "    exp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "sql 1\n",
      "index 4869\n",
      "11895.399966\n",
      "3056.893\n",
      "tensor([0.0456], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4276], grad_fn=<MulBackward0>)\n",
      "1\n",
      "sql 1\n",
      "index 4925\n",
      "20755280318.07862\n",
      "1000000\n",
      "tensor([1.5188], grad_fn=<SqueezeBackward1>)\n",
      "tensor([36.0810], grad_fn=<MulBackward0>)\n",
      "2\n",
      "sql 1\n",
      "index 4923\n",
      "6312988773.722534\n",
      "1000000\n",
      "tensor([1.6824], grad_fn=<SqueezeBackward1>)\n",
      "tensor([37.9645], grad_fn=<MulBackward0>)\n",
      "3\n",
      "sql 1\n",
      "index 4921\n",
      "148387350.10089\n",
      "1000000\n",
      "tensor([1.7360], grad_fn=<SqueezeBackward1>)\n",
      "tensor([32.6640], grad_fn=<MulBackward0>)\n",
      "4\n",
      "sql 1\n",
      "index 4902\n",
      "83689258.022945\n",
      "1000000\n",
      "tensor([1.9967], grad_fn=<SqueezeBackward1>)\n",
      "tensor([36.4242], grad_fn=<MulBackward0>)\n",
      "5\n",
      "sql 1\n",
      "index 4898\n",
      "83654121.3864\n",
      "1000000\n",
      "tensor([1.9851], grad_fn=<SqueezeBackward1>)\n",
      "tensor([36.2131], grad_fn=<MulBackward0>)\n",
      "6\n",
      "sql 1\n",
      "index 4919\n",
      "83653617.72465\n",
      "1000000\n",
      "tensor([1.7948], grad_fn=<SqueezeBackward1>)\n",
      "tensor([32.7418], grad_fn=<MulBackward0>)\n",
      "7\n",
      "sql 1\n",
      "index 4914\n",
      "56971535.552618\n",
      "1000000\n",
      "tensor([1.7676], grad_fn=<SqueezeBackward1>)\n",
      "tensor([31.5656], grad_fn=<MulBackward0>)\n",
      "8\n",
      "sql 1\n",
      "index 4910\n",
      "56950514.475429\n",
      "1000000\n",
      "tensor([1.9710], grad_fn=<SqueezeBackward1>)\n",
      "tensor([35.1970], grad_fn=<MulBackward0>)\n",
      "9\n",
      "sql 1\n",
      "index 4917\n",
      "56910857.67483\n",
      "1000000\n",
      "tensor([1.6522], grad_fn=<SqueezeBackward1>)\n",
      "tensor([29.5025], grad_fn=<MulBackward0>)\n",
      "10\n",
      "sql 1\n",
      "index 4915\n",
      "22527903.197051\n",
      "1000000\n",
      "tensor([1.9972], grad_fn=<SqueezeBackward1>)\n",
      "tensor([33.8137], grad_fn=<MulBackward0>)\n",
      "11\n",
      "sql 1\n",
      "index 4913\n",
      "15033279.486006\n",
      "1000000\n",
      "tensor([1.4786], grad_fn=<SqueezeBackward1>)\n",
      "tensor([24.4349], grad_fn=<MulBackward0>)\n",
      "12\n",
      "sql 1\n",
      "index 4871\n",
      "10667013.575978\n",
      "1000000\n",
      "tensor([1.8766], grad_fn=<SqueezeBackward1>)\n",
      "tensor([30.3677], grad_fn=<MulBackward0>)\n",
      "13\n",
      "sql 1\n",
      "index 4944\n",
      "10559639.23983\n",
      "1000000\n",
      "tensor([1.6778], grad_fn=<SqueezeBackward1>)\n",
      "tensor([27.1348], grad_fn=<MulBackward0>)\n",
      "14\n",
      "sql 1\n",
      "index 4911\n",
      "8633071.064662\n",
      "1000000\n",
      "tensor([1.9992], grad_fn=<SqueezeBackward1>)\n",
      "tensor([31.9297], grad_fn=<MulBackward0>)\n",
      "15\n",
      "sql 1\n",
      "index 4909\n",
      "4558527.583499\n",
      "11283.407\n",
      "tensor([1.1069], grad_fn=<SqueezeBackward1>)\n",
      "tensor([16.9720], grad_fn=<MulBackward0>)\n",
      "16\n",
      "sql 1\n",
      "index 4907\n",
      "3300216.447374\n",
      "1000000\n",
      "tensor([1.9901], grad_fn=<SqueezeBackward1>)\n",
      "tensor([29.8709], grad_fn=<MulBackward0>)\n",
      "17\n",
      "sql 1\n",
      "index 4903\n",
      "1413047.920327\n",
      "14983.257\n",
      "tensor([1.3137], grad_fn=<SqueezeBackward1>)\n",
      "tensor([18.6037], grad_fn=<MulBackward0>)\n",
      "18\n",
      "sql 1\n",
      "index 4905\n",
      "2015491.537625\n",
      "1000000\n",
      "tensor([1.9993], grad_fn=<SqueezeBackward1>)\n",
      "tensor([29.0230], grad_fn=<MulBackward0>)\n",
      "19\n",
      "sql 1\n",
      "index 4901\n",
      "1055748.86723\n",
      "11791.85\n",
      "tensor([1.1600], grad_fn=<SqueezeBackward1>)\n",
      "tensor([16.0892], grad_fn=<MulBackward0>)\n",
      "20\n",
      "sql 1\n",
      "index 4899\n",
      "779398.811827\n",
      "1000000\n",
      "tensor([1.8056], grad_fn=<SqueezeBackward1>)\n",
      "tensor([24.4949], grad_fn=<MulBackward0>)\n",
      "21\n",
      "sql 1\n",
      "index 4964\n",
      "621886.661384\n",
      "1000000\n",
      "tensor([1.9976], grad_fn=<SqueezeBackward1>)\n",
      "tensor([26.6491], grad_fn=<MulBackward0>)\n",
      "22\n",
      "sql 1\n",
      "index 4960\n",
      "600854.899195\n",
      "1000000\n",
      "tensor([1.9987], grad_fn=<SqueezeBackward1>)\n",
      "tensor([26.5946], grad_fn=<MulBackward0>)\n",
      "23\n",
      "sql 1\n",
      "index 4893\n",
      "573416.783898\n",
      "16647.096\n",
      "tensor([1.4131], grad_fn=<SqueezeBackward1>)\n",
      "tensor([18.7363], grad_fn=<MulBackward0>)\n",
      "24\n",
      "sql 1\n",
      "index 4877\n",
      "573414.656398\n",
      "15305.51\n",
      "tensor([1.4186], grad_fn=<SqueezeBackward1>)\n",
      "tensor([18.8093], grad_fn=<MulBackward0>)\n",
      "25\n",
      "sql 1\n",
      "index 4875\n",
      "570001.673044\n",
      "15897.027\n",
      "tensor([1.4299], grad_fn=<SqueezeBackward1>)\n",
      "tensor([18.9513], grad_fn=<MulBackward0>)\n",
      "26\n",
      "sql 1\n",
      "index 4873\n",
      "570012.298044\n",
      "1000000\n",
      "tensor([1.8731], grad_fn=<SqueezeBackward1>)\n",
      "tensor([24.8243], grad_fn=<MulBackward0>)\n",
      "27\n",
      "sql 1\n",
      "index 4891\n",
      "466083.917613\n",
      "12829.851\n",
      "tensor([1.3316], grad_fn=<SqueezeBackward1>)\n",
      "tensor([17.3796], grad_fn=<MulBackward0>)\n",
      "28\n",
      "sql 1\n",
      "index 4881\n",
      "462670.936758\n",
      "12667.446\n",
      "tensor([1.3346], grad_fn=<SqueezeBackward1>)\n",
      "tensor([17.4098], grad_fn=<MulBackward0>)\n",
      "29\n",
      "sql 1\n",
      "index 4942\n",
      "462670.936758\n",
      "13236.618\n",
      "tensor([1.3389], grad_fn=<SqueezeBackward1>)\n",
      "tensor([17.4660], grad_fn=<MulBackward0>)\n",
      "30\n",
      "sql 1\n",
      "index 4870\n",
      "466053.08525\n",
      "1000000\n",
      "tensor([1.9493], grad_fn=<SqueezeBackward1>)\n",
      "tensor([25.4428], grad_fn=<MulBackward0>)\n",
      "31\n",
      "sql 1\n",
      "index 4887\n",
      "466048.82525\n",
      "1000000\n",
      "tensor([1.9974], grad_fn=<SqueezeBackward1>)\n",
      "tensor([26.0702], grad_fn=<MulBackward0>)\n",
      "32\n",
      "sql 1\n",
      "index 4895\n",
      "462635.843145\n",
      "13347.73\n",
      "tensor([1.3417], grad_fn=<SqueezeBackward1>)\n",
      "tensor([17.5022], grad_fn=<MulBackward0>)\n",
      "33\n",
      "sql 1\n",
      "index 4885\n",
      "462640.089395\n",
      "1000000\n",
      "tensor([1.8173], grad_fn=<SqueezeBackward1>)\n",
      "tensor([23.7064], grad_fn=<MulBackward0>)\n",
      "34\n",
      "sql 1\n",
      "index 4889\n",
      "462637.961895\n",
      "1000000\n",
      "tensor([1.7148], grad_fn=<SqueezeBackward1>)\n",
      "tensor([22.3693], grad_fn=<MulBackward0>)\n",
      "35\n",
      "sql 1\n",
      "index 4879\n",
      "462628.396895\n",
      "12789.201\n",
      "tensor([1.3509], grad_fn=<SqueezeBackward1>)\n",
      "tensor([17.6227], grad_fn=<MulBackward0>)\n",
      "36\n",
      "sql 1\n",
      "index 4883\n",
      "462635.829395\n",
      "1000000\n",
      "tensor([1.7469], grad_fn=<SqueezeBackward1>)\n",
      "tensor([22.7876], grad_fn=<MulBackward0>)\n",
      "37\n",
      "sql 1\n",
      "index 4896\n",
      "433921.015159\n",
      "7762.574\n",
      "tensor([1.0500], grad_fn=<SqueezeBackward1>)\n",
      "tensor([13.6294], grad_fn=<MulBackward0>)\n",
      "38\n",
      "sql 1\n",
      "index 4977\n",
      "304848.827239\n",
      "1000000\n",
      "tensor([1.9955], grad_fn=<SqueezeBackward1>)\n",
      "tensor([25.1987], grad_fn=<MulBackward0>)\n",
      "39\n",
      "sql 1\n",
      "index 4928\n",
      "297387.611764\n",
      "1000000\n",
      "tensor([1.7290], grad_fn=<SqueezeBackward1>)\n",
      "tensor([21.7900], grad_fn=<MulBackward0>)\n",
      "40\n",
      "sql 1\n",
      "index 4904\n",
      "294076.567597\n",
      "1000000\n",
      "tensor([1.9978], grad_fn=<SqueezeBackward1>)\n",
      "tensor([25.1552], grad_fn=<MulBackward0>)\n",
      "41\n",
      "sql 1\n",
      "index 4938\n",
      "260181.358771\n",
      "5821.815\n",
      "tensor([0.5651], grad_fn=<SqueezeBackward1>)\n",
      "tensor([7.0464], grad_fn=<MulBackward0>)\n",
      "42\n",
      "sql 1\n",
      "index 4906\n",
      "293990.642597\n",
      "1000000\n",
      "tensor([1.6400], grad_fn=<SqueezeBackward1>)\n",
      "tensor([20.6492], grad_fn=<MulBackward0>)\n",
      "43\n",
      "sql 1\n",
      "index 4920\n",
      "260169.476271\n",
      "6043.965\n",
      "tensor([0.6044], grad_fn=<SqueezeBackward1>)\n",
      "tensor([7.5363], grad_fn=<MulBackward0>)\n",
      "44\n",
      "sql 1\n",
      "index 4894\n",
      "287785.615303\n",
      "23309.859\n",
      "tensor([1.5430], grad_fn=<SqueezeBackward1>)\n",
      "tensor([19.3959], grad_fn=<MulBackward0>)\n",
      "45\n",
      "sql 1\n",
      "index 4897\n",
      "259309.450077\n",
      "22682.823\n",
      "tensor([1.5955], grad_fn=<SqueezeBackward1>)\n",
      "tensor([19.8895], grad_fn=<MulBackward0>)\n",
      "46\n",
      "sql 1\n",
      "index 4981\n",
      "258922.752302\n",
      "22620.04\n",
      "tensor([1.5586], grad_fn=<SqueezeBackward1>)\n",
      "tensor([19.4264], grad_fn=<MulBackward0>)\n",
      "47\n",
      "sql 1\n",
      "index 4900\n",
      "258939.931052\n",
      "1000000\n",
      "tensor([1.9954], grad_fn=<SqueezeBackward1>)\n",
      "tensor([24.8716], grad_fn=<MulBackward0>)\n",
      "48\n",
      "sql 1\n",
      "index 4936\n",
      "239450.630378\n",
      "5732.29\n",
      "tensor([0.6099], grad_fn=<SqueezeBackward1>)\n",
      "tensor([7.5542], grad_fn=<MulBackward0>)\n",
      "49\n",
      "sql 1\n",
      "index 4922\n",
      "233979.30377\n",
      "5569.202\n",
      "tensor([0.4094], grad_fn=<SqueezeBackward1>)\n",
      "tensor([5.0612], grad_fn=<MulBackward0>)\n",
      "50\n",
      "sql 1\n",
      "index 4918\n",
      "233973.36627\n",
      "5662.132\n",
      "tensor([0.4310], grad_fn=<SqueezeBackward1>)\n",
      "tensor([5.3287], grad_fn=<MulBackward0>)\n",
      "51\n",
      "sql 1\n",
      "index 4934\n",
      "239219.694083\n",
      "1000000\n",
      "tensor([1.9988], grad_fn=<SqueezeBackward1>)\n",
      "tensor([24.7553], grad_fn=<MulBackward0>)\n",
      "52\n",
      "sql 1\n",
      "index 4932\n",
      "239195.924083\n",
      "1000000\n",
      "tensor([1.9993], grad_fn=<SqueezeBackward1>)\n",
      "tensor([24.7619], grad_fn=<MulBackward0>)\n",
      "53\n",
      "sql 1\n",
      "index 4916\n",
      "234032.76627\n",
      "1000000\n",
      "tensor([1.9038], grad_fn=<SqueezeBackward1>)\n",
      "tensor([23.5370], grad_fn=<MulBackward0>)\n",
      "54\n",
      "sql 1\n",
      "index 4892\n",
      "224454.288826\n",
      "6129.992\n",
      "tensor([0.6679], grad_fn=<SqueezeBackward1>)\n",
      "tensor([8.2294], grad_fn=<MulBackward0>)\n",
      "55\n",
      "sql 1\n",
      "index 4926\n",
      "213254.522876\n",
      "6052.737\n",
      "tensor([0.6228], grad_fn=<SqueezeBackward1>)\n",
      "tensor([7.6423], grad_fn=<MulBackward0>)\n",
      "56\n",
      "sql 1\n",
      "index 4940\n",
      "212999.815331\n",
      "5972.196\n",
      "tensor([0.6569], grad_fn=<SqueezeBackward1>)\n",
      "tensor([8.0590], grad_fn=<MulBackward0>)\n",
      "57\n",
      "sql 1\n",
      "index 4924\n",
      "212958.226581\n",
      "5569.438\n",
      "tensor([0.4175], grad_fn=<SqueezeBackward1>)\n",
      "tensor([5.1228], grad_fn=<MulBackward0>)\n",
      "58\n",
      "sql 1\n",
      "index 4930\n",
      "213023.571581\n",
      "1000000\n",
      "tensor([1.9992], grad_fn=<SqueezeBackward1>)\n",
      "tensor([24.5286], grad_fn=<MulBackward0>)\n",
      "59\n",
      "sql 1\n",
      "index 4912\n",
      "213011.689081\n",
      "1000000\n",
      "tensor([1.9965], grad_fn=<SqueezeBackward1>)\n",
      "tensor([24.4958], grad_fn=<MulBackward0>)\n",
      "60\n",
      "sql 1\n",
      "index 4908\n",
      "212999.801581\n",
      "1000000\n",
      "tensor([1.9995], grad_fn=<SqueezeBackward1>)\n",
      "tensor([24.5314], grad_fn=<MulBackward0>)\n",
      "61\n",
      "sql 1\n",
      "index 4969\n",
      "201225.687495\n",
      "6783.923\n",
      "tensor([1.0119], grad_fn=<SqueezeBackward1>)\n",
      "tensor([12.3580], grad_fn=<MulBackward0>)\n",
      "62\n",
      "sql 1\n",
      "index 4971\n",
      "179434.945116\n",
      "8684.005\n",
      "tensor([1.1870], grad_fn=<SqueezeBackward1>)\n",
      "tensor([14.3602], grad_fn=<MulBackward0>)\n",
      "63\n",
      "sql 1\n",
      "index 4890\n",
      "175027.632774\n",
      "8048.531\n",
      "tensor([1.1482], grad_fn=<SqueezeBackward1>)\n",
      "tensor([13.8614], grad_fn=<MulBackward0>)\n",
      "64\n",
      "sql 1\n",
      "index 4966\n",
      "179435.912616\n",
      "1000000\n",
      "tensor([1.9782], grad_fn=<SqueezeBackward1>)\n",
      "tensor([23.9312], grad_fn=<MulBackward0>)\n",
      "65\n",
      "sql 1\n",
      "index 4975\n",
      "158404.217533\n",
      "8271.014\n",
      "tensor([1.1828], grad_fn=<SqueezeBackward1>)\n",
      "tensor([14.1611], grad_fn=<MulBackward0>)\n",
      "66\n",
      "sql 1\n",
      "index 4958\n",
      "158404.217533\n",
      "8623.551\n",
      "tensor([1.2171], grad_fn=<SqueezeBackward1>)\n",
      "tensor([14.5724], grad_fn=<MulBackward0>)\n",
      "67\n",
      "sql 1\n",
      "index 4973\n",
      "158403.182927\n",
      "8359.986\n",
      "tensor([1.1697], grad_fn=<SqueezeBackward1>)\n",
      "tensor([14.0046], grad_fn=<MulBackward0>)\n",
      "68\n",
      "sql 1\n",
      "index 4954\n",
      "158393.052877\n",
      "9198.171\n",
      "tensor([1.3870], grad_fn=<SqueezeBackward1>)\n",
      "tensor([16.6068], grad_fn=<MulBackward0>)\n",
      "69\n",
      "sql 1\n",
      "index 4979\n",
      "158404.240427\n",
      "1000000\n",
      "tensor([1.7674], grad_fn=<SqueezeBackward1>)\n",
      "tensor([21.1613], grad_fn=<MulBackward0>)\n",
      "70\n",
      "sql 1\n",
      "index 4946\n",
      "158404.150427\n",
      "1000000\n",
      "tensor([1.9989], grad_fn=<SqueezeBackward1>)\n",
      "tensor([23.9322], grad_fn=<MulBackward0>)\n",
      "71\n",
      "sql 1\n",
      "index 4888\n",
      "136499.178976\n",
      "5202.106\n",
      "tensor([0.3188], grad_fn=<SqueezeBackward1>)\n",
      "tensor([3.7692], grad_fn=<MulBackward0>)\n",
      "72\n",
      "sql 1\n",
      "index 4886\n",
      "104779.180661\n",
      "5572.408\n",
      "tensor([0.5227], grad_fn=<SqueezeBackward1>)\n",
      "tensor([6.0427], grad_fn=<MulBackward0>)\n",
      "73\n",
      "sql 1\n",
      "index 4884\n",
      "72811.283794\n",
      "4377.449\n",
      "tensor([0.3601], grad_fn=<SqueezeBackward1>)\n",
      "tensor([4.0313], grad_fn=<MulBackward0>)\n",
      "74\n",
      "sql 1\n",
      "index 4882\n",
      "57319.645683\n",
      "1000000\n",
      "tensor([1.9953], grad_fn=<SqueezeBackward1>)\n",
      "tensor([21.8618], grad_fn=<MulBackward0>)\n",
      "75\n",
      "sql 1\n",
      "index 4952\n",
      "48720.713282\n",
      "8552.051\n",
      "tensor([1.3972], grad_fn=<SqueezeBackward1>)\n",
      "tensor([15.0812], grad_fn=<MulBackward0>)\n",
      "76\n",
      "sql 1\n",
      "index 4950\n",
      "48717.671519\n",
      "1000000\n",
      "tensor([1.9971], grad_fn=<SqueezeBackward1>)\n",
      "tensor([21.5565], grad_fn=<MulBackward0>)\n",
      "77\n",
      "sql 1\n",
      "index 4949\n",
      "48717.006519\n",
      "1000000\n",
      "tensor([1.9975], grad_fn=<SqueezeBackward1>)\n",
      "tensor([21.5604], grad_fn=<MulBackward0>)\n",
      "78\n",
      "sql 1\n",
      "index 4880\n",
      "44575.678933\n",
      "1000000\n",
      "tensor([1.9089], grad_fn=<SqueezeBackward1>)\n",
      "tensor([20.4345], grad_fn=<MulBackward0>)\n",
      "79\n",
      "sql 1\n",
      "index 4878\n",
      "35645.748149\n",
      "10119.084\n",
      "tensor([1.4985], grad_fn=<SqueezeBackward1>)\n",
      "tensor([15.7067], grad_fn=<MulBackward0>)\n",
      "80\n",
      "sql 1\n",
      "index 4962\n",
      "30859.851264\n",
      "8297.957\n",
      "tensor([1.4397], grad_fn=<SqueezeBackward1>)\n",
      "tensor([14.8827], grad_fn=<MulBackward0>)\n",
      "81\n",
      "sql 1\n",
      "index 4956\n",
      "30856.143251\n",
      "8573.461\n",
      "tensor([1.4078], grad_fn=<SqueezeBackward1>)\n",
      "tensor([14.5525], grad_fn=<MulBackward0>)\n",
      "82\n",
      "sql 1\n",
      "index 4876\n",
      "26712.759415\n",
      "2437.237\n",
      "tensor([0.0134], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1364], grad_fn=<MulBackward0>)\n",
      "83\n",
      "sql 1\n",
      "index 4948\n",
      "30856.794501\n",
      "1000000\n",
      "tensor([1.9992], grad_fn=<SqueezeBackward1>)\n",
      "tensor([20.6657], grad_fn=<MulBackward0>)\n",
      "84\n",
      "sql 1\n",
      "index 4947\n",
      "30856.129501\n",
      "1000000\n",
      "tensor([1.9994], grad_fn=<SqueezeBackward1>)\n",
      "tensor([20.6679], grad_fn=<MulBackward0>)\n",
      "85\n",
      "sql 1\n",
      "index 4874\n",
      "18519.854334\n",
      "2967.001\n",
      "tensor([0.0004], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.0035], grad_fn=<MulBackward0>)\n",
      "86\n",
      "sql 1\n",
      "index 4872\n",
      "14982.574269\n",
      "9561.547\n",
      "tensor([1.5683], grad_fn=<SqueezeBackward1>)\n",
      "tensor([15.0783], grad_fn=<MulBackward0>)\n",
      "87\n",
      "sql 1\n",
      "index 4982\n",
      "11910.351992\n",
      "5879.754\n",
      "tensor([1.0507], grad_fn=<SqueezeBackward1>)\n",
      "tensor([9.8614], grad_fn=<MulBackward0>)\n",
      "88\n",
      "sql 1\n",
      "index 4980\n",
      "11910.351992\n",
      "6511.832\n",
      "tensor([1.2269], grad_fn=<SqueezeBackward1>)\n",
      "tensor([11.5143], grad_fn=<MulBackward0>)\n",
      "89\n",
      "sql 1\n",
      "index 4963\n",
      "11910.343242\n",
      "6379.081\n",
      "tensor([1.1092], grad_fn=<SqueezeBackward1>)\n",
      "tensor([10.4104], grad_fn=<MulBackward0>)\n",
      "90\n",
      "sql 1\n",
      "index 4965\n",
      "11910.343242\n",
      "6952.162\n",
      "tensor([1.3057], grad_fn=<SqueezeBackward1>)\n",
      "tensor([12.2545], grad_fn=<MulBackward0>)\n",
      "91\n",
      "sql 1\n",
      "index 4978\n",
      "11910.343242\n",
      "6051.461\n",
      "tensor([1.1011], grad_fn=<SqueezeBackward1>)\n",
      "tensor([10.3339], grad_fn=<MulBackward0>)\n",
      "92\n",
      "sql 1\n",
      "index 4976\n",
      "11910.343242\n",
      "7027.906\n",
      "tensor([1.3701], grad_fn=<SqueezeBackward1>)\n",
      "tensor([12.8591], grad_fn=<MulBackward0>)\n",
      "93\n",
      "sql 1\n",
      "index 4968\n",
      "11910.340867\n",
      "6778.438\n",
      "tensor([1.2609], grad_fn=<SqueezeBackward1>)\n",
      "tensor([11.8336], grad_fn=<MulBackward0>)\n",
      "94\n",
      "sql 1\n",
      "index 4970\n",
      "11910.340867\n",
      "5884.444\n",
      "tensor([1.0155], grad_fn=<SqueezeBackward1>)\n",
      "tensor([9.5302], grad_fn=<MulBackward0>)\n",
      "95\n",
      "sql 1\n",
      "index 4967\n",
      "11910.338242\n",
      "5904.966\n",
      "tensor([1.0465], grad_fn=<SqueezeBackward1>)\n",
      "tensor([9.8214], grad_fn=<MulBackward0>)\n",
      "96\n",
      "sql 1\n",
      "index 4961\n",
      "11910.338242\n",
      "6293.472\n",
      "tensor([1.1259], grad_fn=<SqueezeBackward1>)\n",
      "tensor([10.5670], grad_fn=<MulBackward0>)\n",
      "97\n",
      "sql 1\n",
      "index 4972\n",
      "11910.338242\n",
      "6799.326\n",
      "tensor([1.3010], grad_fn=<SqueezeBackward1>)\n",
      "tensor([12.2100], grad_fn=<MulBackward0>)\n",
      "98\n",
      "sql 1\n",
      "index 4974\n",
      "11910.338242\n",
      "6853.583\n",
      "tensor([1.2648], grad_fn=<SqueezeBackward1>)\n",
      "tensor([11.8701], grad_fn=<MulBackward0>)\n",
      "99\n",
      "sql 1\n",
      "index 4955\n",
      "11909.367326\n",
      "3895.498\n",
      "tensor([0.2701], grad_fn=<SqueezeBackward1>)\n",
      "tensor([2.5345], grad_fn=<MulBackward0>)\n",
      "100\n",
      "sql 1\n",
      "index 4959\n",
      "11909.445919\n",
      "6468.939\n",
      "tensor([1.2139], grad_fn=<SqueezeBackward1>)\n",
      "tensor([11.3922], grad_fn=<MulBackward0>)\n",
      "101\n",
      "sql 1\n",
      "index 4957\n",
      "11909.445919\n",
      "6559.493\n",
      "tensor([1.2964], grad_fn=<SqueezeBackward1>)\n",
      "tensor([12.1668], grad_fn=<MulBackward0>)\n",
      "102\n",
      "sql 1\n",
      "index 4951\n",
      "11909.354826\n",
      "3811.163\n",
      "tensor([0.1726], grad_fn=<SqueezeBackward1>)\n",
      "tensor([1.6201], grad_fn=<MulBackward0>)\n",
      "103\n",
      "sql 1\n",
      "index 4953\n",
      "11909.349826\n",
      "3990.1\n",
      "tensor([0.3344], grad_fn=<SqueezeBackward1>)\n",
      "tensor([3.1386], grad_fn=<MulBackward0>)\n",
      "104\n",
      "sql 1\n",
      "index 4943\n",
      "11897.674826\n",
      "3835.318\n",
      "tensor([0.2651], grad_fn=<SqueezeBackward1>)\n",
      "tensor([2.4880], grad_fn=<MulBackward0>)\n",
      "105\n",
      "sql 1\n",
      "index 4945\n",
      "11897.674826\n",
      "4113.829\n",
      "tensor([0.3554], grad_fn=<SqueezeBackward1>)\n",
      "tensor([3.3348], grad_fn=<MulBackward0>)\n",
      "106\n",
      "sql 1\n",
      "index 4941\n",
      "11897.656076\n",
      "3750.353\n",
      "tensor([0.2709], grad_fn=<SqueezeBackward1>)\n",
      "tensor([2.5424], grad_fn=<MulBackward0>)\n",
      "107\n",
      "sql 1\n",
      "index 4935\n",
      "11897.647326\n",
      "3627.171\n",
      "tensor([0.0594], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.5573], grad_fn=<MulBackward0>)\n",
      "108\n",
      "sql 1\n",
      "index 4939\n",
      "11897.647326\n",
      "3600.831\n",
      "tensor([0.0841], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.7891], grad_fn=<MulBackward0>)\n",
      "109\n",
      "sql 1\n",
      "index 4937\n",
      "11897.644951\n",
      "3672.792\n",
      "tensor([0.2179], grad_fn=<SqueezeBackward1>)\n",
      "tensor([2.0446], grad_fn=<MulBackward0>)\n",
      "110\n",
      "sql 1\n",
      "index 4927\n",
      "11897.642326\n",
      "3670.809\n",
      "tensor([0.1694], grad_fn=<SqueezeBackward1>)\n",
      "tensor([1.5892], grad_fn=<MulBackward0>)\n",
      "111\n",
      "sql 1\n",
      "index 4929\n",
      "11897.642326\n",
      "4044.042\n",
      "tensor([0.4450], grad_fn=<SqueezeBackward1>)\n",
      "tensor([4.1756], grad_fn=<MulBackward0>)\n",
      "112\n",
      "sql 1\n",
      "index 4931\n",
      "11897.642326\n",
      "3256.99\n",
      "tensor([0.1685], grad_fn=<SqueezeBackward1>)\n",
      "tensor([1.5808], grad_fn=<MulBackward0>)\n",
      "113\n",
      "sql 1\n",
      "index 4933\n",
      "11897.642326\n",
      "3726.143\n",
      "tensor([0.1626], grad_fn=<SqueezeBackward1>)\n",
      "tensor([1.5256], grad_fn=<MulBackward0>)\n",
      "114\n",
      "sql 2\n",
      "index 6842\n",
      "11891.898793\n",
      "406.146\n",
      "tensor([0.0876], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.8224], grad_fn=<MulBackward0>)\n",
      "115\n",
      "sql 2\n",
      "index 6895\n",
      "20745259997.028522\n",
      "1000000\n",
      "tensor([1.4396], grad_fn=<SqueezeBackward1>)\n",
      "tensor([34.1996], grad_fn=<MulBackward0>)\n",
      "116\n",
      "sql 2\n",
      "index 6893\n",
      "6310283520.32325\n",
      "1000000\n",
      "tensor([1.9509], grad_fn=<SqueezeBackward1>)\n",
      "tensor([44.0233], grad_fn=<MulBackward0>)\n",
      "117\n",
      "sql 2\n",
      "index 6892\n",
      "145222058.288461\n",
      "1000000\n",
      "tensor([1.6585], grad_fn=<SqueezeBackward1>)\n",
      "tensor([31.1693], grad_fn=<MulBackward0>)\n",
      "118\n",
      "sql 2\n",
      "index 6889\n",
      "113300723.556191\n",
      "1000000\n",
      "tensor([1.5326], grad_fn=<SqueezeBackward1>)\n",
      "tensor([28.4232], grad_fn=<MulBackward0>)\n",
      "119\n",
      "sql 2\n",
      "index 6885\n",
      "113279280.339002\n",
      "1000000\n",
      "tensor([1.6867], grad_fn=<SqueezeBackward1>)\n",
      "tensor([31.2805], grad_fn=<MulBackward0>)\n",
      "120\n",
      "sql 2\n",
      "index 6890\n",
      "81871539.181389\n",
      "1000000\n",
      "tensor([1.9993], grad_fn=<SqueezeBackward1>)\n",
      "tensor([36.4290], grad_fn=<MulBackward0>)\n",
      "121\n",
      "sql 2\n",
      "index 6888\n",
      "15033273.742474\n",
      "1000000\n",
      "tensor([1.2886], grad_fn=<SqueezeBackward1>)\n",
      "tensor([21.2950], grad_fn=<MulBackward0>)\n",
      "122\n",
      "sql 2\n",
      "index 6886\n",
      "8630277.786997\n",
      "1000000\n",
      "tensor([1.5746], grad_fn=<SqueezeBackward1>)\n",
      "tensor([25.1469], grad_fn=<MulBackward0>)\n",
      "123\n",
      "sql 2\n",
      "index 6884\n",
      "5334153.87339\n",
      "1000000\n",
      "tensor([1.8474], grad_fn=<SqueezeBackward1>)\n",
      "tensor([28.6163], grad_fn=<MulBackward0>)\n",
      "124\n",
      "sql 2\n",
      "index 6882\n",
      "3933706.72792\n",
      "1000000\n",
      "tensor([1.4121], grad_fn=<SqueezeBackward1>)\n",
      "tensor([21.4423], grad_fn=<MulBackward0>)\n",
      "125\n",
      "sql 2\n",
      "index 6880\n",
      "2896401.502997\n",
      "1000000\n",
      "tensor([1.9130], grad_fn=<SqueezeBackward1>)\n",
      "tensor([28.4638], grad_fn=<MulBackward0>)\n",
      "126\n",
      "sql 2\n",
      "index 6878\n",
      "1336541.565071\n",
      "12495.357\n",
      "tensor([1.1264], grad_fn=<SqueezeBackward1>)\n",
      "tensor([15.8889], grad_fn=<MulBackward0>)\n",
      "127\n",
      "sql 2\n",
      "index 6876\n",
      "934738.355006\n",
      "8583.557\n",
      "tensor([1.5464], grad_fn=<SqueezeBackward1>)\n",
      "tensor([21.2602], grad_fn=<MulBackward0>)\n",
      "128\n",
      "sql 2\n",
      "index 6940\n",
      "628156.162071\n",
      "1000000\n",
      "tensor([1.9986], grad_fn=<SqueezeBackward1>)\n",
      "tensor([26.6826], grad_fn=<MulBackward0>)\n",
      "129\n",
      "sql 2\n",
      "index 6874\n",
      "606705.389882\n",
      "1000000\n",
      "tensor([1.9987], grad_fn=<SqueezeBackward1>)\n",
      "tensor([26.6144], grad_fn=<MulBackward0>)\n",
      "130\n",
      "sql 2\n",
      "index 6894\n",
      "458548.899911\n",
      "2247.636\n",
      "tensor([0.3787], grad_fn=<SqueezeBackward1>)\n",
      "tensor([4.9370], grad_fn=<MulBackward0>)\n",
      "131\n",
      "sql 2\n",
      "index 6912\n",
      "458572.667411\n",
      "2711.742\n",
      "tensor([0.5591], grad_fn=<SqueezeBackward1>)\n",
      "tensor([7.2889], grad_fn=<MulBackward0>)\n",
      "132\n",
      "sql 2\n",
      "index 6908\n",
      "437248.287722\n",
      "2970.048\n",
      "tensor([0.9762], grad_fn=<SqueezeBackward1>)\n",
      "tensor([12.6793], grad_fn=<MulBackward0>)\n",
      "133\n",
      "sql 2\n",
      "index 6910\n",
      "437757.687813\n",
      "3949.008\n",
      "tensor([0.6924], grad_fn=<SqueezeBackward1>)\n",
      "tensor([8.9942], grad_fn=<MulBackward0>)\n",
      "134\n",
      "sql 2\n",
      "index 6891\n",
      "432466.418573\n",
      "3174.019\n",
      "tensor([0.3997], grad_fn=<SqueezeBackward1>)\n",
      "tensor([5.1871], grad_fn=<MulBackward0>)\n",
      "135\n",
      "sql 2\n",
      "index 6896\n",
      "432359.473573\n",
      "2954.648\n",
      "tensor([0.2916], grad_fn=<SqueezeBackward1>)\n",
      "tensor([3.7841], grad_fn=<MulBackward0>)\n",
      "136\n",
      "sql 2\n",
      "index 6872\n",
      "432347.593573\n",
      "2248.244\n",
      "tensor([0.2792], grad_fn=<SqueezeBackward1>)\n",
      "tensor([3.6234], grad_fn=<MulBackward0>)\n",
      "137\n",
      "sql 2\n",
      "index 6900\n",
      "411556.383975\n",
      "2788.351\n",
      "tensor([0.3774], grad_fn=<SqueezeBackward1>)\n",
      "tensor([4.8791], grad_fn=<MulBackward0>)\n",
      "138\n",
      "sql 2\n",
      "index 6904\n",
      "411046.968884\n",
      "2815.016\n",
      "tensor([0.5294], grad_fn=<SqueezeBackward1>)\n",
      "tensor([6.8426], grad_fn=<MulBackward0>)\n",
      "139\n",
      "sql 2\n",
      "index 6906\n",
      "437200.747722\n",
      "1000000\n",
      "tensor([1.9106], grad_fn=<SqueezeBackward1>)\n",
      "tensor([24.8149], grad_fn=<MulBackward0>)\n",
      "140\n",
      "sql 2\n",
      "index 6887\n",
      "411023.201384\n",
      "3296.747\n",
      "tensor([0.7338], grad_fn=<SqueezeBackward1>)\n",
      "tensor([9.4856], grad_fn=<MulBackward0>)\n",
      "141\n",
      "sql 2\n",
      "index 6914\n",
      "410999.442634\n",
      "3039.561\n",
      "tensor([0.4590], grad_fn=<SqueezeBackward1>)\n",
      "tensor([5.9335], grad_fn=<MulBackward0>)\n",
      "142\n",
      "sql 2\n",
      "index 6898\n",
      "410916.256384\n",
      "3077.783\n",
      "tensor([0.4313], grad_fn=<SqueezeBackward1>)\n",
      "tensor([5.5745], grad_fn=<MulBackward0>)\n",
      "143\n",
      "sql 2\n",
      "index 6946\n",
      "345634.918753\n",
      "1492.819\n",
      "tensor([0.3648], grad_fn=<SqueezeBackward1>)\n",
      "tensor([4.6522], grad_fn=<MulBackward0>)\n",
      "144\n",
      "sql 2\n",
      "index 6883\n",
      "410999.428884\n",
      "1000000\n",
      "tensor([1.7549], grad_fn=<SqueezeBackward1>)\n",
      "tensor([22.6849], grad_fn=<MulBackward0>)\n",
      "145\n",
      "sql 2\n",
      "index 6870\n",
      "324184.536564\n",
      "2227.903\n",
      "tensor([1.0147], grad_fn=<SqueezeBackward1>)\n",
      "tensor([12.8751], grad_fn=<MulBackward0>)\n",
      "146\n",
      "sql 2\n",
      "index 6942\n",
      "319431.682813\n",
      "1748.762\n",
      "tensor([0.6664], grad_fn=<SqueezeBackward1>)\n",
      "tensor([8.4458], grad_fn=<MulBackward0>)\n",
      "147\n",
      "sql 2\n",
      "index 6944\n",
      "319431.370313\n",
      "1475.266\n",
      "tensor([0.2158], grad_fn=<SqueezeBackward1>)\n",
      "tensor([2.7354], grad_fn=<MulBackward0>)\n",
      "148\n",
      "sql 2\n",
      "index 6948\n",
      "319431.399063\n",
      "1866.942\n",
      "tensor([0.3316], grad_fn=<SqueezeBackward1>)\n",
      "tensor([4.2025], grad_fn=<MulBackward0>)\n",
      "149\n",
      "sql 2\n",
      "index 6936\n",
      "297981.307534\n",
      "1624.613\n",
      "tensor([0.4423], grad_fn=<SqueezeBackward1>)\n",
      "tensor([5.5749], grad_fn=<MulBackward0>)\n",
      "150\n",
      "sql 2\n",
      "index 6952\n",
      "297981.307534\n",
      "1463.225\n",
      "tensor([0.6268], grad_fn=<SqueezeBackward1>)\n",
      "tensor([7.9004], grad_fn=<MulBackward0>)\n",
      "151\n",
      "sql 2\n",
      "index 6956\n",
      "297980.975624\n",
      "1467.586\n",
      "tensor([0.8076], grad_fn=<SqueezeBackward1>)\n",
      "tensor([10.1796], grad_fn=<MulBackward0>)\n",
      "152\n",
      "sql 2\n",
      "index 6920\n",
      "297980.910624\n",
      "1591.299\n",
      "tensor([0.8432], grad_fn=<SqueezeBackward1>)\n",
      "tensor([10.6287], grad_fn=<MulBackward0>)\n",
      "153\n",
      "sql 2\n",
      "index 6950\n",
      "297980.626874\n",
      "1702.563\n",
      "tensor([0.7012], grad_fn=<SqueezeBackward1>)\n",
      "tensor([8.8387], grad_fn=<MulBackward0>)\n",
      "154\n",
      "sql 2\n",
      "index 6954\n",
      "297980.840624\n",
      "1000000\n",
      "tensor([1.9808], grad_fn=<SqueezeBackward1>)\n",
      "tensor([24.9669], grad_fn=<MulBackward0>)\n",
      "155\n",
      "sql 2\n",
      "index 6851\n",
      "204083.314894\n",
      "2800.095\n",
      "tensor([0.9640], grad_fn=<SqueezeBackward1>)\n",
      "tensor([11.7864], grad_fn=<MulBackward0>)\n",
      "156\n",
      "sql 2\n",
      "index 6867\n",
      "204083.314894\n",
      "2278.161\n",
      "tensor([0.9891], grad_fn=<SqueezeBackward1>)\n",
      "tensor([12.0935], grad_fn=<MulBackward0>)\n",
      "157\n",
      "sql 2\n",
      "index 6868\n",
      "252398.395032\n",
      "1000000\n",
      "tensor([1.2880], grad_fn=<SqueezeBackward1>)\n",
      "tensor([16.0206], grad_fn=<MulBackward0>)\n",
      "158\n",
      "sql 2\n",
      "index 6849\n",
      "199975.895232\n",
      "2643.046\n",
      "tensor([0.9396], grad_fn=<SqueezeBackward1>)\n",
      "tensor([11.4689], grad_fn=<MulBackward0>)\n",
      "159\n",
      "sql 2\n",
      "index 6847\n",
      "199975.882732\n",
      "2852.569\n",
      "tensor([1.2846], grad_fn=<SqueezeBackward1>)\n",
      "tensor([15.6794], grad_fn=<MulBackward0>)\n",
      "160\n",
      "sql 2\n",
      "index 6866\n",
      "197676.614101\n",
      "5055.901\n",
      "tensor([1.2301], grad_fn=<SqueezeBackward1>)\n",
      "tensor([15.0006], grad_fn=<MulBackward0>)\n",
      "161\n",
      "sql 2\n",
      "index 6865\n",
      "161792.458512\n",
      "1317.002\n",
      "tensor([0.6310], grad_fn=<SqueezeBackward1>)\n",
      "tensor([7.5683], grad_fn=<MulBackward0>)\n",
      "162\n",
      "sql 2\n",
      "index 6843\n",
      "161792.446012\n",
      "1440.031\n",
      "tensor([0.9355], grad_fn=<SqueezeBackward1>)\n",
      "tensor([11.2206], grad_fn=<MulBackward0>)\n",
      "163\n",
      "sql 2\n",
      "index 6845\n",
      "199975.877732\n",
      "1000000\n",
      "tensor([1.7468], grad_fn=<SqueezeBackward1>)\n",
      "tensor([21.3212], grad_fn=<MulBackward0>)\n",
      "164\n",
      "sql 2\n",
      "index 6855\n",
      "157685.041351\n",
      "1527.402\n",
      "tensor([0.3236], grad_fn=<SqueezeBackward1>)\n",
      "tensor([3.8724], grad_fn=<MulBackward0>)\n",
      "165\n",
      "sql 2\n",
      "index 6916\n",
      "157685.041351\n",
      "1615.32\n",
      "tensor([0.6075], grad_fn=<SqueezeBackward1>)\n",
      "tensor([7.2703], grad_fn=<MulBackward0>)\n",
      "166\n",
      "sql 2\n",
      "index 6853\n",
      "157685.022601\n",
      "1721.667\n",
      "tensor([0.6708], grad_fn=<SqueezeBackward1>)\n",
      "tensor([8.0278], grad_fn=<MulBackward0>)\n",
      "167\n",
      "sql 2\n",
      "index 6869\n",
      "157685.022601\n",
      "1569.864\n",
      "tensor([0.4016], grad_fn=<SqueezeBackward1>)\n",
      "tensor([4.8068], grad_fn=<MulBackward0>)\n",
      "168\n",
      "sql 2\n",
      "index 6859\n",
      "157685.013851\n",
      "1459.646\n",
      "tensor([0.6402], grad_fn=<SqueezeBackward1>)\n",
      "tensor([7.6615], grad_fn=<MulBackward0>)\n",
      "169\n",
      "sql 2\n",
      "index 6863\n",
      "157685.013851\n",
      "1509.89\n",
      "tensor([0.9865], grad_fn=<SqueezeBackward1>)\n",
      "tensor([11.8068], grad_fn=<MulBackward0>)\n",
      "170\n",
      "sql 2\n",
      "index 6864\n",
      "155213.369689\n",
      "2034.447\n",
      "tensor([1.3831], grad_fn=<SqueezeBackward1>)\n",
      "tensor([16.5319], grad_fn=<MulBackward0>)\n",
      "171\n",
      "sql 2\n",
      "index 6861\n",
      "161792.441012\n",
      "1000000\n",
      "tensor([1.8448], grad_fn=<SqueezeBackward1>)\n",
      "tensor([22.1266], grad_fn=<MulBackward0>)\n",
      "172\n",
      "sql 2\n",
      "index 6857\n",
      "157685.008851\n",
      "1000000\n",
      "tensor([1.9682], grad_fn=<SqueezeBackward1>)\n",
      "tensor([23.5557], grad_fn=<MulBackward0>)\n",
      "173\n",
      "sql 2\n",
      "index 6918\n",
      "157685.008851\n",
      "1000000\n",
      "tensor([1.4499], grad_fn=<SqueezeBackward1>)\n",
      "tensor([17.3527], grad_fn=<MulBackward0>)\n",
      "174\n",
      "sql 2\n",
      "index 6932\n",
      "134643.44934\n",
      "1985.47\n",
      "tensor([0.8643], grad_fn=<SqueezeBackward1>)\n",
      "tensor([10.2079], grad_fn=<MulBackward0>)\n",
      "175\n",
      "sql 2\n",
      "index 6862\n",
      "122171.5765\n",
      "1000000\n",
      "tensor([1.9988], grad_fn=<SqueezeBackward1>)\n",
      "tensor([23.4123], grad_fn=<MulBackward0>)\n",
      "176\n",
      "sql 2\n",
      "index 6902\n",
      "88143.985709\n",
      "2926.35\n",
      "tensor([0.9753], grad_fn=<SqueezeBackward1>)\n",
      "tensor([11.1050], grad_fn=<MulBackward0>)\n",
      "177\n",
      "sql 2\n",
      "index 6860\n",
      "96447.524818\n",
      "1000000\n",
      "tensor([1.9997], grad_fn=<SqueezeBackward1>)\n",
      "tensor([22.9505], grad_fn=<MulBackward0>)\n",
      "178\n",
      "sql 2\n",
      "index 6881\n",
      "84071.837684\n",
      "3848.775\n",
      "tensor([0.7799], grad_fn=<SqueezeBackward1>)\n",
      "tensor([8.8440], grad_fn=<MulBackward0>)\n",
      "179\n",
      "sql 2\n",
      "index 6879\n",
      "84071.825184\n",
      "4495.97\n",
      "tensor([0.9988], grad_fn=<SqueezeBackward1>)\n",
      "tensor([11.3263], grad_fn=<MulBackward0>)\n",
      "180\n",
      "sql 2\n",
      "index 6858\n",
      "76662.858886\n",
      "1116.951\n",
      "tensor([0.3527], grad_fn=<SqueezeBackward1>)\n",
      "tensor([3.9673], grad_fn=<MulBackward0>)\n",
      "181\n",
      "sql 2\n",
      "index 6877\n",
      "84071.820184\n",
      "1000000\n",
      "tensor([1.5007], grad_fn=<SqueezeBackward1>)\n",
      "tensor([17.0176], grad_fn=<MulBackward0>)\n",
      "182\n",
      "sql 2\n",
      "index 6856\n",
      "61310.888273\n",
      "1000000\n",
      "tensor([1.9997], grad_fn=<SqueezeBackward1>)\n",
      "tensor([22.0438], grad_fn=<MulBackward0>)\n",
      "183\n",
      "sql 2\n",
      "index 6958\n",
      "48935.197389\n",
      "3350.336\n",
      "tensor([0.6464], grad_fn=<SqueezeBackward1>)\n",
      "tensor([6.9800], grad_fn=<MulBackward0>)\n",
      "184\n",
      "sql 2\n",
      "index 6871\n",
      "48935.216139\n",
      "3700.739\n",
      "tensor([0.7005], grad_fn=<SqueezeBackward1>)\n",
      "tensor([7.5637], grad_fn=<MulBackward0>)\n",
      "185\n",
      "sql 2\n",
      "index 6875\n",
      "48935.188639\n",
      "4014.619\n",
      "tensor([0.8943], grad_fn=<SqueezeBackward1>)\n",
      "tensor([9.6570], grad_fn=<MulBackward0>)\n",
      "186\n",
      "sql 2\n",
      "index 6930\n",
      "48248.087067\n",
      "1877.156\n",
      "tensor([0.6658], grad_fn=<SqueezeBackward1>)\n",
      "tensor([7.1804], grad_fn=<MulBackward0>)\n",
      "187\n",
      "sql 2\n",
      "index 6928\n",
      "48248.074567\n",
      "1907.462\n",
      "tensor([0.8091], grad_fn=<SqueezeBackward1>)\n",
      "tensor([8.7251], grad_fn=<MulBackward0>)\n",
      "188\n",
      "sql 2\n",
      "index 6938\n",
      "38826.187285\n",
      "1716.748\n",
      "tensor([1.1429], grad_fn=<SqueezeBackward1>)\n",
      "tensor([12.0772], grad_fn=<MulBackward0>)\n",
      "189\n",
      "sql 2\n",
      "index 6873\n",
      "48935.183639\n",
      "1000000\n",
      "tensor([1.7007], grad_fn=<SqueezeBackward1>)\n",
      "tensor([18.3644], grad_fn=<MulBackward0>)\n",
      "190\n",
      "sql 2\n",
      "index 6934\n",
      "38826.168535\n",
      "1916.021\n",
      "tensor([1.1883], grad_fn=<SqueezeBackward1>)\n",
      "tensor([12.5568], grad_fn=<MulBackward0>)\n",
      "191\n",
      "sql 2\n",
      "index 6924\n",
      "38826.159785\n",
      "1968.384\n",
      "tensor([1.1610], grad_fn=<SqueezeBackward1>)\n",
      "tensor([12.2682], grad_fn=<MulBackward0>)\n",
      "192\n",
      "sql 2\n",
      "index 6852\n",
      "36017.52626\n",
      "520.394\n",
      "tensor([0.0958], grad_fn=<SqueezeBackward1>)\n",
      "tensor([1.0054], grad_fn=<MulBackward0>)\n",
      "193\n",
      "sql 2\n",
      "index 6854\n",
      "45691.129868\n",
      "10379.118\n",
      "tensor([1.6800], grad_fn=<SqueezeBackward1>)\n",
      "tensor([18.0256], grad_fn=<MulBackward0>)\n",
      "194\n",
      "sql 2\n",
      "index 6926\n",
      "48248.069567\n",
      "1000000\n",
      "tensor([1.9993], grad_fn=<SqueezeBackward1>)\n",
      "tensor([21.5602], grad_fn=<MulBackward0>)\n",
      "195\n",
      "sql 2\n",
      "index 6922\n",
      "38826.154785\n",
      "1000000\n",
      "tensor([1.9995], grad_fn=<SqueezeBackward1>)\n",
      "tensor([21.1284], grad_fn=<MulBackward0>)\n",
      "196\n",
      "sql 2\n",
      "index 6850\n",
      "27497.554925\n",
      "374.321\n",
      "tensor([0.3450], grad_fn=<SqueezeBackward1>)\n",
      "tensor([3.5266], grad_fn=<MulBackward0>)\n",
      "197\n",
      "sql 2\n",
      "index 6848\n",
      "21679.120589\n",
      "308.29\n",
      "tensor([0.7119], grad_fn=<SqueezeBackward1>)\n",
      "tensor([7.1079], grad_fn=<MulBackward0>)\n",
      "198\n",
      "sql 2\n",
      "index 6846\n",
      "14949.171166\n",
      "624.394\n",
      "tensor([0.1363], grad_fn=<SqueezeBackward1>)\n",
      "tensor([1.3103], grad_fn=<MulBackward0>)\n",
      "199\n",
      "sql 2\n",
      "index 6953\n",
      "11891.931293\n",
      "470.489\n",
      "tensor([0.0309], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2899], grad_fn=<MulBackward0>)\n",
      "200\n",
      "sql 2\n",
      "index 6955\n",
      "11891.931293\n",
      "561.271\n",
      "tensor([0.0494], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4640], grad_fn=<MulBackward0>)\n",
      "201\n",
      "sql 2\n",
      "index 6957\n",
      "11891.931293\n",
      "499.104\n",
      "tensor([0.1043], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.9786], grad_fn=<MulBackward0>)\n",
      "202\n",
      "sql 2\n",
      "index 6959\n",
      "11891.931293\n",
      "604.393\n",
      "tensor([0.0346], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3247], grad_fn=<MulBackward0>)\n",
      "203\n",
      "sql 2\n",
      "index 6949\n",
      "11891.921293\n",
      "635.496\n",
      "tensor([0.0543], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.5099], grad_fn=<MulBackward0>)\n",
      "204\n",
      "sql 2\n",
      "index 6951\n",
      "11891.921293\n",
      "470.003\n",
      "tensor([0.0022], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.0206], grad_fn=<MulBackward0>)\n",
      "205\n",
      "sql 2\n",
      "index 6941\n",
      "11891.912543\n",
      "559.67\n",
      "tensor([0.0732], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.6868], grad_fn=<MulBackward0>)\n",
      "206\n",
      "sql 2\n",
      "index 6943\n",
      "11891.912543\n",
      "484.743\n",
      "tensor([0.0818], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.7671], grad_fn=<MulBackward0>)\n",
      "207\n",
      "sql 2\n",
      "index 6945\n",
      "11891.908793\n",
      "570.545\n",
      "tensor([0.0614], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.5760], grad_fn=<MulBackward0>)\n",
      "208\n",
      "sql 2\n",
      "index 6947\n",
      "11891.912543\n",
      "624.452\n",
      "tensor([0.0092], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.0859], grad_fn=<MulBackward0>)\n",
      "209\n",
      "sql 2\n",
      "index 6939\n",
      "11891.906293\n",
      "549.246\n",
      "tensor([0.0017], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.0164], grad_fn=<MulBackward0>)\n",
      "210\n",
      "sql 2\n",
      "index 6907\n",
      "11891.903793\n",
      "450.146\n",
      "tensor([0.0308], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.2892], grad_fn=<MulBackward0>)\n",
      "211\n",
      "sql 2\n",
      "index 6911\n",
      "11891.903793\n",
      "578.304\n",
      "tensor([0.0370], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3467], grad_fn=<MulBackward0>)\n",
      "212\n",
      "sql 2\n",
      "index 6923\n",
      "11891.903793\n",
      "459.484\n",
      "tensor([0.0069], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.0647], grad_fn=<MulBackward0>)\n",
      "213\n",
      "sql 2\n",
      "index 6915\n",
      "11891.903793\n",
      "560.49\n",
      "tensor([0.1198], grad_fn=<SqueezeBackward1>)\n",
      "tensor([1.1244], grad_fn=<MulBackward0>)\n",
      "214\n",
      "sql 2\n",
      "index 6925\n",
      "11891.903793\n",
      "613.352\n",
      "tensor([0.0887], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.8328], grad_fn=<MulBackward0>)\n",
      "215\n",
      "sql 2\n",
      "index 6931\n",
      "11891.903793\n",
      "463.191\n",
      "tensor([0.0893], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.8379], grad_fn=<MulBackward0>)\n",
      "216\n",
      "sql 2\n",
      "index 6933\n",
      "11891.903793\n",
      "582.633\n",
      "tensor([0.0403], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3785], grad_fn=<MulBackward0>)\n",
      "217\n",
      "sql 2\n",
      "index 6903\n",
      "11891.901418\n",
      "584.225\n",
      "tensor([0.0197], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1844], grad_fn=<MulBackward0>)\n",
      "218\n",
      "sql 2\n",
      "index 6917\n",
      "11891.901418\n",
      "525.978\n",
      "tensor([0.0004], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.0037], grad_fn=<MulBackward0>)\n",
      "219\n",
      "sql 2\n",
      "index 6919\n",
      "11891.901418\n",
      "602.327\n",
      "tensor([0.0031], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.0294], grad_fn=<MulBackward0>)\n",
      "220\n",
      "sql 2\n",
      "index 6935\n",
      "11891.901418\n",
      "467.809\n",
      "tensor([0.0442], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.4152], grad_fn=<MulBackward0>)\n",
      "221\n",
      "sql 2\n",
      "index 6905\n",
      "11891.898793\n",
      "467.877\n",
      "tensor([0.0025], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.0237], grad_fn=<MulBackward0>)\n",
      "222\n",
      "sql 2\n",
      "index 6909\n",
      "11891.898793\n",
      "550.254\n",
      "tensor([0.0126], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.1180], grad_fn=<MulBackward0>)\n",
      "223\n",
      "sql 2\n",
      "index 6913\n",
      "11891.898793\n",
      "608.857\n",
      "tensor([0.0004], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.0035], grad_fn=<MulBackward0>)\n",
      "224\n",
      "sql 2\n",
      "index 6927\n",
      "11891.898793\n",
      "432.26\n",
      "tensor([0.0638], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.5991], grad_fn=<MulBackward0>)\n",
      "225\n",
      "sql 2\n",
      "index 6921\n",
      "11891.898793\n",
      "610.755\n",
      "tensor([0.0846], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.7938], grad_fn=<MulBackward0>)\n",
      "226\n",
      "sql 2\n",
      "index 6929\n",
      "11891.898793\n",
      "528.783\n",
      "tensor([0.1119], grad_fn=<SqueezeBackward1>)\n",
      "tensor([1.0497], grad_fn=<MulBackward0>)\n",
      "227\n",
      "sql 2\n",
      "index 6937\n",
      "11891.898793\n",
      "612.908\n",
      "tensor([0.0960], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.9010], grad_fn=<MulBackward0>)\n",
      "228\n",
      "sql 2\n",
      "index 6901\n",
      "11891.006471\n",
      "646.152\n",
      "tensor([0.0028], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.0266], grad_fn=<MulBackward0>)\n",
      "229\n",
      "sql 2\n",
      "index 6899\n",
      "11890.987275\n",
      "589.58\n",
      "tensor([0.0018], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.0164], grad_fn=<MulBackward0>)\n",
      "230\n",
      "sql 2\n",
      "index 6897\n",
      "11889.656691\n",
      "631.379\n",
      "tensor([0.0537], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.5041], grad_fn=<MulBackward0>)\n",
      "231\n",
      "sql 2\n",
      "index 6844\n",
      "11889.656311\n",
      "462.613\n",
      "tensor([0.0395], grad_fn=<SqueezeBackward1>)\n",
      "tensor([0.3706], grad_fn=<MulBackward0>)\n",
      "232\n",
      "sql 3\n",
      "index 7188\n",
      "11911.616933\n",
      "2753.549\n",
      "tensor([0.6717], grad_fn=<SqueezeBackward1>)\n",
      "tensor([6.3039], grad_fn=<MulBackward0>)\n",
      "233\n",
      "sql 3\n",
      "index 7245\n",
      "16196505835.82554\n",
      "1000000\n",
      "tensor([1.6305], grad_fn=<SqueezeBackward1>)\n",
      "tensor([38.3302], grad_fn=<MulBackward0>)\n",
      "234\n",
      "sql 3\n",
      "index 7243\n",
      "6313240797.667583\n",
      "1000000\n",
      "tensor([1.9981], grad_fn=<SqueezeBackward1>)\n",
      "tensor([45.0889], grad_fn=<MulBackward0>)\n",
      "235\n",
      "sql 3\n",
      "index 7241\n",
      "3399948557.826493\n",
      "1000000\n",
      "tensor([1.9911], grad_fn=<SqueezeBackward1>)\n",
      "tensor([43.6984], grad_fn=<MulBackward0>)\n",
      "236\n",
      "sql 3\n",
      "index 7239\n",
      "148904143.165226\n",
      "1000000\n",
      "tensor([1.9959], grad_fn=<SqueezeBackward1>)\n",
      "tensor([37.5608], grad_fn=<MulBackward0>)\n",
      "237\n",
      "sql 3\n",
      "index 7235\n",
      "113590033.473636\n",
      "1000000\n",
      "tensor([1.9795], grad_fn=<SqueezeBackward1>)\n",
      "tensor([36.7169], grad_fn=<MulBackward0>)\n",
      "238\n",
      "sql 3\n",
      "index 7231\n",
      "113568590.256447\n",
      "1000000\n",
      "tensor([1.9718], grad_fn=<SqueezeBackward1>)\n",
      "tensor([36.5722], grad_fn=<MulBackward0>)\n",
      "239\n",
      "sql 3\n",
      "index 7237\n",
      "81547773.546921\n",
      "1000000\n",
      "tensor([1.9990], grad_fn=<SqueezeBackward1>)\n",
      "tensor([36.4146], grad_fn=<MulBackward0>)\n",
      "240\n",
      "sql 3\n",
      "index 7223\n",
      "46017834.924937\n",
      "1000000\n",
      "tensor([1.9830], grad_fn=<SqueezeBackward1>)\n",
      "tensor([34.9892], grad_fn=<MulBackward0>)\n",
      "241\n",
      "sql 3\n",
      "index 7219\n",
      "45982698.288392\n",
      "1000000\n",
      "tensor([1.9838], grad_fn=<SqueezeBackward1>)\n",
      "tensor([35.0019], grad_fn=<MulBackward0>)\n",
      "242\n",
      "sql 3\n",
      "index 7234\n",
      "15033279.308506\n",
      "1000000\n",
      "tensor([1.5576], grad_fn=<SqueezeBackward1>)\n",
      "tensor([25.7404], grad_fn=<MulBackward0>)\n",
      "243\n",
      "sql 3\n",
      "index 7232\n",
      "10831473.591189\n",
      "1000000\n",
      "tensor([1.9979], grad_fn=<SqueezeBackward1>)\n",
      "tensor([32.3616], grad_fn=<MulBackward0>)\n",
      "244\n",
      "sql 3\n",
      "index 7230\n",
      "6704134.429012\n",
      "1000000\n",
      "tensor([1.9991], grad_fn=<SqueezeBackward1>)\n",
      "tensor([31.4227], grad_fn=<MulBackward0>)\n",
      "245\n",
      "sql 3\n",
      "index 7228\n",
      "4486185.816086\n",
      "11164.637\n",
      "tensor([1.2477], grad_fn=<SqueezeBackward1>)\n",
      "tensor([19.1109], grad_fn=<MulBackward0>)\n",
      "246\n",
      "sql 3\n",
      "index 7226\n",
      "3304274.935426\n",
      "1000000\n",
      "tensor([1.9858], grad_fn=<SqueezeBackward1>)\n",
      "tensor([29.8078], grad_fn=<MulBackward0>)\n",
      "247\n",
      "sql 3\n",
      "index 7191\n",
      "2387379.010043\n",
      "1000000\n",
      "tensor([1.9900], grad_fn=<SqueezeBackward1>)\n",
      "tensor([29.2249], grad_fn=<MulBackward0>)\n",
      "248\n",
      "sql 3\n",
      "index 7264\n",
      "2275863.43095\n",
      "1000000\n",
      "tensor([1.9862], grad_fn=<SqueezeBackward1>)\n",
      "tensor([29.0742], grad_fn=<MulBackward0>)\n",
      "249\n",
      "sql 3\n",
      "index 7224\n",
      "1954817.819911\n",
      "1000000\n",
      "tensor([1.9983], grad_fn=<SqueezeBackward1>)\n",
      "tensor([28.9465], grad_fn=<MulBackward0>)\n",
      "250\n",
      "sql 3\n",
      "index 7222\n",
      "1336547.131103\n",
      "11323.127\n",
      "tensor([1.3348], grad_fn=<SqueezeBackward1>)\n",
      "tensor([18.8275], grad_fn=<MulBackward0>)\n",
      "251\n",
      "sql 3\n",
      "index 7220\n",
      "872009.861623\n",
      "1000000\n",
      "tensor([1.9981], grad_fn=<SqueezeBackward1>)\n",
      "tensor([27.3306], grad_fn=<MulBackward0>)\n",
      "252\n",
      "sql 3\n",
      "index 7284\n",
      "629183.311205\n",
      "1000000\n",
      "tensor([1.9994], grad_fn=<SqueezeBackward1>)\n",
      "tensor([26.6960], grad_fn=<MulBackward0>)\n",
      "253\n",
      "sql 3\n",
      "index 7218\n",
      "607732.539016\n",
      "1000000\n",
      "tensor([1.9993], grad_fn=<SqueezeBackward1>)\n",
      "tensor([26.6253], grad_fn=<MulBackward0>)\n",
      "254\n",
      "sql 3\n",
      "index 7197\n",
      "481234.508743\n",
      "7791.975\n",
      "tensor([1.3504], grad_fn=<SqueezeBackward1>)\n",
      "tensor([17.6682], grad_fn=<MulBackward0>)\n",
      "255\n",
      "sql 3\n",
      "index 7213\n",
      "481234.911243\n",
      "8887.919\n",
      "tensor([1.3546], grad_fn=<SqueezeBackward1>)\n",
      "tensor([17.7240], grad_fn=<MulBackward0>)\n",
      "256\n",
      "sql 3\n",
      "index 7195\n",
      "477127.089082\n",
      "7844.879\n",
      "tensor([1.4048], grad_fn=<SqueezeBackward1>)\n",
      "tensor([18.3684], grad_fn=<MulBackward0>)\n",
      "257\n",
      "sql 3\n",
      "index 7193\n",
      "477129.089082\n",
      "1000000\n",
      "tensor([1.7259], grad_fn=<SqueezeBackward1>)\n",
      "tensor([22.5671], grad_fn=<MulBackward0>)\n",
      "258\n",
      "sql 3\n",
      "index 7258\n",
      "458597.599243\n",
      "4037.528\n",
      "tensor([0.8015], grad_fn=<SqueezeBackward1>)\n",
      "tensor([10.4487], grad_fn=<MulBackward0>)\n",
      "259\n",
      "sql 3\n",
      "index 7240\n",
      "458573.831743\n",
      "4102.103\n",
      "tensor([0.8775], grad_fn=<SqueezeBackward1>)\n",
      "tensor([11.4396], grad_fn=<MulBackward0>)\n",
      "260\n",
      "sql 3\n",
      "index 7256\n",
      "437782.619645\n",
      "4345.717\n",
      "tensor([0.9711], grad_fn=<SqueezeBackward1>)\n",
      "tensor([12.6140], grad_fn=<MulBackward0>)\n",
      "261\n",
      "sql 3\n",
      "index 7242\n",
      "432389.901625\n",
      "4015.303\n",
      "tensor([0.5307], grad_fn=<SqueezeBackward1>)\n",
      "tensor([6.8866], grad_fn=<MulBackward0>)\n",
      "262\n",
      "sql 3\n",
      "index 7238\n",
      "432378.021625\n",
      "4086.757\n",
      "tensor([0.5714], grad_fn=<SqueezeBackward1>)\n",
      "tensor([7.4150], grad_fn=<MulBackward0>)\n",
      "263\n",
      "sql 3\n",
      "index 7254\n",
      "437273.219554\n",
      "20391.521\n",
      "tensor([1.7863], grad_fn=<SqueezeBackward1>)\n",
      "tensor([23.2007], grad_fn=<MulBackward0>)\n",
      "264\n",
      "sql 3\n",
      "index 7236\n",
      "432496.846625\n",
      "21764.88\n",
      "tensor([1.5245], grad_fn=<SqueezeBackward1>)\n",
      "tensor([19.7840], grad_fn=<MulBackward0>)\n",
      "265\n",
      "sql 3\n",
      "index 7252\n",
      "437225.679554\n",
      "1000000\n",
      "tensor([1.9980], grad_fn=<SqueezeBackward1>)\n",
      "tensor([25.9500], grad_fn=<MulBackward0>)\n",
      "266\n",
      "sql 3\n",
      "index 7246\n",
      "411586.812027\n",
      "4604.175\n",
      "tensor([0.7990], grad_fn=<SqueezeBackward1>)\n",
      "tensor([10.3299], grad_fn=<MulBackward0>)\n",
      "267\n",
      "sql 3\n",
      "index 7260\n",
      "411029.870686\n",
      "4658.098\n",
      "tensor([0.8815], grad_fn=<SqueezeBackward1>)\n",
      "tensor([11.3946], grad_fn=<MulBackward0>)\n",
      "268\n",
      "sql 3\n",
      "index 7244\n",
      "410946.684436\n",
      "3847.27\n",
      "tensor([0.8944], grad_fn=<SqueezeBackward1>)\n",
      "tensor([11.5608], grad_fn=<MulBackward0>)\n",
      "269\n",
      "sql 3\n",
      "index 7250\n",
      "411077.396936\n",
      "20739.865\n",
      "tensor([1.7725], grad_fn=<SqueezeBackward1>)\n",
      "tensor([22.9119], grad_fn=<MulBackward0>)\n",
      "270\n",
      "sql 3\n",
      "index 7233\n",
      "411053.629436\n",
      "19758.306\n",
      "tensor([1.5218], grad_fn=<SqueezeBackward1>)\n",
      "tensor([19.6721], grad_fn=<MulBackward0>)\n",
      "271\n",
      "sql 3\n",
      "index 7229\n",
      "411029.856936\n",
      "1000000\n",
      "tensor([1.9971], grad_fn=<SqueezeBackward1>)\n",
      "tensor([25.8156], grad_fn=<MulBackward0>)\n",
      "272\n",
      "sql 3\n",
      "index 7211\n",
      "369725.277429\n",
      "5628.384\n",
      "tensor([1.2740], grad_fn=<SqueezeBackward1>)\n",
      "tensor([16.3335], grad_fn=<MulBackward0>)\n",
      "273\n",
      "sql 3\n",
      "index 7201\n",
      "365617.860268\n",
      "5976.263\n",
      "tensor([1.2963], grad_fn=<SqueezeBackward1>)\n",
      "tensor([16.6053], grad_fn=<MulBackward0>)\n",
      "274\n",
      "sql 3\n",
      "index 7262\n",
      "365617.860268\n",
      "6257.456\n",
      "tensor([1.2780], grad_fn=<SqueezeBackward1>)\n",
      "tensor([16.3702], grad_fn=<MulBackward0>)\n",
      "275\n",
      "sql 3\n",
      "index 7216\n",
      "374158.246768\n",
      "1000000\n",
      "tensor([1.9928], grad_fn=<SqueezeBackward1>)\n",
      "tensor([25.5729], grad_fn=<MulBackward0>)\n",
      "276\n",
      "sql 3\n",
      "index 7189\n",
      "369721.344651\n",
      "1000000\n",
      "tensor([1.6393], grad_fn=<SqueezeBackward1>)\n",
      "tensor([21.0160], grad_fn=<MulBackward0>)\n",
      "277\n",
      "sql 3\n",
      "index 7207\n",
      "369720.534651\n",
      "1000000\n",
      "tensor([1.9923], grad_fn=<SqueezeBackward1>)\n",
      "tensor([25.5419], grad_fn=<MulBackward0>)\n",
      "278\n",
      "sql 3\n",
      "index 7215\n",
      "365613.11624\n",
      "5683.223\n",
      "tensor([1.3234], grad_fn=<SqueezeBackward1>)\n",
      "tensor([16.9522], grad_fn=<MulBackward0>)\n",
      "279\n",
      "sql 3\n",
      "index 7199\n",
      "365611.70749\n",
      "6545.288\n",
      "tensor([1.2952], grad_fn=<SqueezeBackward1>)\n",
      "tensor([16.5913], grad_fn=<MulBackward0>)\n",
      "280\n",
      "sql 3\n",
      "index 7205\n",
      "365613.91249\n",
      "1000000\n",
      "tensor([1.6219], grad_fn=<SqueezeBackward1>)\n",
      "tensor([20.7752], grad_fn=<MulBackward0>)\n",
      "281\n",
      "sql 3\n",
      "index 7289\n",
      "345667.465094\n",
      "4673.05\n",
      "tensor([0.8691], grad_fn=<SqueezeBackward1>)\n",
      "tensor([11.0833], grad_fn=<MulBackward0>)\n",
      "282\n",
      "sql 3\n",
      "index 7209\n",
      "365613.50999\n",
      "1000000\n",
      "tensor([1.6230], grad_fn=<SqueezeBackward1>)\n",
      "tensor([20.7891], grad_fn=<MulBackward0>)\n",
      "283\n",
      "sql 3\n",
      "index 7203\n",
      "365613.10249\n",
      "1000000\n",
      "tensor([1.9716], grad_fn=<SqueezeBackward1>)\n",
      "tensor([25.2555], grad_fn=<MulBackward0>)\n",
      "284\n",
      "sql 3\n",
      "index 7291\n",
      "319469.441623\n",
      "4902.392\n",
      "tensor([0.8396], grad_fn=<SqueezeBackward1>)\n",
      "tensor([10.6418], grad_fn=<MulBackward0>)\n",
      "285\n",
      "sql 3\n",
      "index 7287\n",
      "319469.412873\n",
      "4757.221\n",
      "tensor([0.6196], grad_fn=<SqueezeBackward1>)\n",
      "tensor([7.8529], grad_fn=<MulBackward0>)\n",
      "286\n",
      "sql 3\n",
      "index 7285\n",
      "319469.725373\n",
      "10580.965\n",
      "tensor([1.9347], grad_fn=<SqueezeBackward1>)\n",
      "tensor([24.5216], grad_fn=<MulBackward0>)\n",
      "287\n",
      "sql 3\n",
      "index 7280\n",
      "298019.350094\n",
      "4667.078\n",
      "tensor([1.0318], grad_fn=<SqueezeBackward1>)\n",
      "tensor([13.0057], grad_fn=<MulBackward0>)\n",
      "288\n",
      "sql 3\n",
      "index 7295\n",
      "298019.350094\n",
      "4956.971\n",
      "tensor([1.0208], grad_fn=<SqueezeBackward1>)\n",
      "tensor([12.8667], grad_fn=<MulBackward0>)\n",
      "289\n",
      "sql 3\n",
      "index 7293\n",
      "298018.669434\n",
      "4277.538\n",
      "tensor([1.0676], grad_fn=<SqueezeBackward1>)\n",
      "tensor([13.4571], grad_fn=<MulBackward0>)\n",
      "290\n",
      "sql 3\n",
      "index 7298\n",
      "298019.018184\n",
      "11591.588\n",
      "tensor([1.6242], grad_fn=<SqueezeBackward1>)\n",
      "tensor([20.4728], grad_fn=<MulBackward0>)\n",
      "291\n",
      "sql 3\n",
      "index 7266\n",
      "298018.953184\n",
      "11548.322\n",
      "tensor([1.9337], grad_fn=<SqueezeBackward1>)\n",
      "tensor([24.3736], grad_fn=<MulBackward0>)\n",
      "292\n",
      "sql 3\n",
      "index 7297\n",
      "298018.883184\n",
      "1000000\n",
      "tensor([1.9418], grad_fn=<SqueezeBackward1>)\n",
      "tensor([24.4765], grad_fn=<MulBackward0>)\n",
      "293\n",
      "sql 3\n",
      "index 7212\n",
      "225004.206134\n",
      "5028.686\n",
      "tensor([0.9031], grad_fn=<SqueezeBackward1>)\n",
      "tensor([11.1297], grad_fn=<MulBackward0>)\n",
      "294\n",
      "sql 3\n",
      "index 7214\n",
      "287913.8553\n",
      "1000000\n",
      "tensor([1.9849], grad_fn=<SqueezeBackward1>)\n",
      "tensor([24.9507], grad_fn=<MulBackward0>)\n",
      "295\n",
      "sql 3\n",
      "index 7248\n",
      "203811.501878\n",
      "12351.51\n",
      "tensor([1.2967], grad_fn=<SqueezeBackward1>)\n",
      "tensor([15.8523], grad_fn=<MulBackward0>)\n",
      "296\n",
      "sql 3\n",
      "index 7227\n",
      "199739.353854\n",
      "12809.497\n",
      "tensor([1.3684], grad_fn=<SqueezeBackward1>)\n",
      "tensor([16.7012], grad_fn=<MulBackward0>)\n",
      "297\n",
      "sql 3\n",
      "index 7225\n",
      "199785.616354\n",
      "1000000\n",
      "tensor([1.8393], grad_fn=<SqueezeBackward1>)\n",
      "tensor([22.4481], grad_fn=<MulBackward0>)\n",
      "298\n",
      "sql 3\n",
      "index 7210\n",
      "176682.703127\n",
      "4298.313\n",
      "tensor([1.4669], grad_fn=<SqueezeBackward1>)\n",
      "tensor([17.7236], grad_fn=<MulBackward0>)\n",
      "299\n",
      "sql 3\n",
      "index 7276\n",
      "163402.658439\n",
      "5649.488\n",
      "tensor([1.3062], grad_fn=<SqueezeBackward1>)\n",
      "tensor([15.6797], grad_fn=<MulBackward0>)\n",
      "300\n",
      "sql 3\n",
      "index 7217\n",
      "164831.460484\n",
      "14461.894\n",
      "tensor([1.3651], grad_fn=<SqueezeBackward1>)\n",
      "tensor([16.3984], grad_fn=<MulBackward0>)\n",
      "301\n",
      "sql 3\n",
      "index 7300\n",
      "164639.733559\n",
      "14239.795\n",
      "tensor([1.3546], grad_fn=<SqueezeBackward1>)\n",
      "tensor([16.2708], grad_fn=<MulBackward0>)\n",
      "302\n",
      "sql 3\n",
      "index 7221\n",
      "164648.979809\n",
      "1000000\n",
      "tensor([1.9569], grad_fn=<SqueezeBackward1>)\n",
      "tensor([23.5055], grad_fn=<MulBackward0>)\n",
      "303\n",
      "sql 3\n",
      "index 7208\n",
      "136616.102991\n",
      "6141.496\n",
      "tensor([1.3295], grad_fn=<SqueezeBackward1>)\n",
      "tensor([15.7214], grad_fn=<MulBackward0>)\n",
      "304\n",
      "sql 3\n",
      "index 7204\n",
      "83978.990047\n",
      "5048.484\n",
      "tensor([0.5401], grad_fn=<SqueezeBackward1>)\n",
      "tensor([6.1242], grad_fn=<MulBackward0>)\n",
      "305\n",
      "sql 3\n",
      "index 7202\n",
      "62243.76443\n",
      "3282.645\n",
      "tensor([0.7030], grad_fn=<SqueezeBackward1>)\n",
      "tensor([7.7604], grad_fn=<MulBackward0>)\n",
      "306\n",
      "sql 3\n",
      "index 7206\n",
      "107427.255594\n",
      "1000000\n",
      "tensor([1.1886], grad_fn=<SqueezeBackward1>)\n",
      "tensor([13.7697], grad_fn=<MulBackward0>)\n",
      "307\n",
      "sql 3\n",
      "index 7274\n",
      "50412.04445\n",
      "5811.599\n",
      "tensor([1.3037], grad_fn=<SqueezeBackward1>)\n",
      "tensor([14.1167], grad_fn=<MulBackward0>)\n",
      "308\n",
      "sql 3\n",
      "index 7200\n",
      "47160.913883\n",
      "6560.496\n",
      "tensor([0.8878], grad_fn=<SqueezeBackward1>)\n",
      "tensor([9.5540], grad_fn=<MulBackward0>)\n",
      "309\n",
      "sql 3\n",
      "index 7283\n",
      "40990.144668\n",
      "5110.415\n",
      "tensor([1.4094], grad_fn=<SqueezeBackward1>)\n",
      "tensor([14.9691], grad_fn=<MulBackward0>)\n",
      "310\n",
      "sql 3\n",
      "index 7272\n",
      "50410.710777\n",
      "11991.623\n",
      "tensor([1.6068], grad_fn=<SqueezeBackward1>)\n",
      "tensor([17.3981], grad_fn=<MulBackward0>)\n",
      "311\n",
      "sql 3\n",
      "index 7278\n",
      "40988.449745\n",
      "4969.883\n",
      "tensor([1.3892], grad_fn=<SqueezeBackward1>)\n",
      "tensor([14.7548], grad_fn=<MulBackward0>)\n",
      "312\n",
      "sql 3\n",
      "index 7198\n",
      "37732.223497\n",
      "1302.969\n",
      "tensor([0.2742], grad_fn=<SqueezeBackward1>)\n",
      "tensor([2.8901], grad_fn=<MulBackward0>)\n",
      "313\n",
      "sql 3\n",
      "index 7269\n",
      "40988.795995\n",
      "11634.915\n",
      "tensor([1.9955], grad_fn=<SqueezeBackward1>)\n",
      "tensor([21.1943], grad_fn=<MulBackward0>)\n",
      "314\n",
      "sql 3\n",
      "index 7196\n",
      "30564.602559\n",
      "776.347\n",
      "tensor([0.5050], grad_fn=<SqueezeBackward1>)\n",
      "tensor([5.2153], grad_fn=<MulBackward0>)\n",
      "315\n",
      "sql 3\n",
      "index 7270\n",
      "50410.350777\n",
      "1000000\n",
      "tensor([1.9929], grad_fn=<SqueezeBackward1>)\n",
      "tensor([21.5787], grad_fn=<MulBackward0>)\n",
      "316\n",
      "sql 3\n",
      "index 7194\n",
      "23795.43823\n",
      "3332.147\n",
      "tensor([0.9673], grad_fn=<SqueezeBackward1>)\n",
      "tensor([9.7477], grad_fn=<MulBackward0>)\n",
      "317\n",
      "sql 3\n",
      "index 7192\n",
      "14979.599218\n",
      "3610.033\n",
      "tensor([0.7130], grad_fn=<SqueezeBackward1>)\n",
      "tensor([6.8556], grad_fn=<MulBackward0>)\n",
      "318\n",
      "sql 3\n",
      "index 7299\n",
      "11911.616933\n",
      "2673.504\n",
      "tensor([0.9779], grad_fn=<SqueezeBackward1>)\n",
      "tensor([9.1783], grad_fn=<MulBackward0>)\n",
      "319\n",
      "sql 3\n",
      "index 7301\n",
      "11911.614558\n",
      "2407.506\n",
      "tensor([0.5378], grad_fn=<SqueezeBackward1>)\n",
      "tensor([5.0471], grad_fn=<MulBackward0>)\n",
      "320\n",
      "sql 3\n",
      "index 7292\n",
      "11909.414115\n",
      "1766.981\n",
      "tensor([0.8346], grad_fn=<SqueezeBackward1>)\n",
      "tensor([7.8324], grad_fn=<MulBackward0>)\n",
      "321\n",
      "sql 3\n",
      "index 7296\n",
      "11910.719611\n",
      "2478.958\n",
      "tensor([1.0068], grad_fn=<SqueezeBackward1>)\n",
      "tensor([9.4486], grad_fn=<MulBackward0>)\n",
      "322\n",
      "sql 3\n",
      "index 7294\n",
      "11909.414115\n",
      "1722.754\n",
      "tensor([1.1801], grad_fn=<SqueezeBackward1>)\n",
      "tensor([11.0757], grad_fn=<MulBackward0>)\n",
      "323\n",
      "sql 3\n",
      "index 7268\n",
      "40988.435995\n",
      "1000000\n",
      "tensor([1.9995], grad_fn=<SqueezeBackward1>)\n",
      "tensor([21.2369], grad_fn=<MulBackward0>)\n",
      "324\n",
      "sql 3\n",
      "index 7290\n",
      "11909.189826\n",
      "3628.807\n",
      "tensor([0.5686], grad_fn=<SqueezeBackward1>)\n",
      "tensor([5.3368], grad_fn=<MulBackward0>)\n",
      "325\n",
      "sql 3\n",
      "index 7286\n",
      "11909.177326\n",
      "4149.833\n",
      "tensor([0.7288], grad_fn=<SqueezeBackward1>)\n",
      "tensor([6.8403], grad_fn=<MulBackward0>)\n",
      "326\n",
      "sql 3\n",
      "index 7288\n",
      "11909.172326\n",
      "3851.071\n",
      "tensor([0.8756], grad_fn=<SqueezeBackward1>)\n",
      "tensor([8.2174], grad_fn=<MulBackward0>)\n",
      "327\n",
      "sql 3\n",
      "index 7281\n",
      "11898.279115\n",
      "1835.975\n",
      "tensor([0.7493], grad_fn=<SqueezeBackward1>)\n",
      "tensor([7.0316], grad_fn=<MulBackward0>)\n",
      "328\n",
      "sql 3\n",
      "index 7282\n",
      "11898.279115\n",
      "1719.173\n",
      "tensor([0.6981], grad_fn=<SqueezeBackward1>)\n",
      "tensor([6.5507], grad_fn=<MulBackward0>)\n",
      "329\n",
      "sql 3\n",
      "index 7279\n",
      "11898.266615\n",
      "1752.78\n",
      "tensor([0.7698], grad_fn=<SqueezeBackward1>)\n",
      "tensor([7.2235], grad_fn=<MulBackward0>)\n",
      "330\n",
      "sql 3\n",
      "index 7275\n",
      "11898.264115\n",
      "1709.618\n",
      "tensor([1.0817], grad_fn=<SqueezeBackward1>)\n",
      "tensor([10.1509], grad_fn=<MulBackward0>)\n",
      "331\n",
      "sql 3\n",
      "index 7273\n",
      "11898.261615\n",
      "1865.604\n",
      "tensor([0.5954], grad_fn=<SqueezeBackward1>)\n",
      "tensor([5.5870], grad_fn=<MulBackward0>)\n",
      "332\n",
      "sql 3\n",
      "index 7277\n",
      "11898.25924\n",
      "1732.199\n",
      "tensor([0.5890], grad_fn=<SqueezeBackward1>)\n",
      "tensor([5.5274], grad_fn=<MulBackward0>)\n",
      "333\n",
      "sql 3\n",
      "index 7271\n",
      "11898.256615\n",
      "1522.932\n",
      "tensor([0.8665], grad_fn=<SqueezeBackward1>)\n",
      "tensor([8.1315], grad_fn=<MulBackward0>)\n",
      "334\n",
      "sql 3\n",
      "index 7265\n",
      "11897.497326\n",
      "3604.241\n",
      "tensor([0.8500], grad_fn=<SqueezeBackward1>)\n",
      "tensor([7.9764], grad_fn=<MulBackward0>)\n",
      "335\n",
      "sql 3\n",
      "index 7267\n",
      "11897.497326\n",
      "3016.586\n",
      "tensor([0.8543], grad_fn=<SqueezeBackward1>)\n",
      "tensor([8.0167], grad_fn=<MulBackward0>)\n",
      "336\n",
      "sql 3\n",
      "index 7263\n",
      "11897.478576\n",
      "3782.488\n",
      "tensor([0.6653], grad_fn=<SqueezeBackward1>)\n",
      "tensor([6.2432], grad_fn=<MulBackward0>)\n",
      "337\n",
      "sql 3\n",
      "index 7255\n",
      "11897.469826\n",
      "4027.189\n",
      "tensor([0.6680], grad_fn=<SqueezeBackward1>)\n",
      "tensor([6.2687], grad_fn=<MulBackward0>)\n",
      "338\n",
      "sql 3\n",
      "index 7257\n",
      "11897.469826\n",
      "3490.613\n",
      "tensor([0.5890], grad_fn=<SqueezeBackward1>)\n",
      "tensor([5.5275], grad_fn=<MulBackward0>)\n",
      "339\n",
      "sql 3\n",
      "index 7259\n",
      "11897.467451\n",
      "4162.664\n",
      "tensor([0.7088], grad_fn=<SqueezeBackward1>)\n",
      "tensor([6.6516], grad_fn=<MulBackward0>)\n",
      "340\n",
      "sql 3\n",
      "index 7249\n",
      "11897.464826\n",
      "3366.356\n",
      "tensor([1.0448], grad_fn=<SqueezeBackward1>)\n",
      "tensor([9.8042], grad_fn=<MulBackward0>)\n",
      "341\n",
      "sql 3\n",
      "index 7251\n",
      "11897.464826\n",
      "3916.518\n",
      "tensor([0.8522], grad_fn=<SqueezeBackward1>)\n",
      "tensor([7.9970], grad_fn=<MulBackward0>)\n",
      "342\n",
      "sql 3\n",
      "index 7253\n",
      "11897.464826\n",
      "3928.889\n",
      "tensor([0.6464], grad_fn=<SqueezeBackward1>)\n",
      "tensor([6.0658], grad_fn=<MulBackward0>)\n",
      "343\n",
      "sql 3\n",
      "index 7247\n",
      "11897.345096\n",
      "1673.568\n",
      "tensor([1.0250], grad_fn=<SqueezeBackward1>)\n",
      "tensor([9.6182], grad_fn=<MulBackward0>)\n",
      "344\n",
      "sql 3\n",
      "index 7261\n",
      "11897.464826\n",
      "4235.844\n",
      "tensor([0.8099], grad_fn=<SqueezeBackward1>)\n",
      "tensor([7.6006], grad_fn=<MulBackward0>)\n",
      "345\n",
      "sql 3\n",
      "index 7190\n",
      "11895.222723\n",
      "3805.057\n",
      "tensor([0.6834], grad_fn=<SqueezeBackward1>)\n",
      "tensor([6.4127], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "num = 0\n",
    "dict1 = dict()\n",
    "# for i, plan in enumerate(exp['k,lt,mk,ml,t1,t2']): # 32b\n",
    "# for i, plan in enumerate(exp['an1,ci,cn,mc,n1,rt,t']): # 8d\n",
    "for i, plan in enumerate(exp['cc,cct1,cct2,ci,it1,it2,k,mi,mi_idx,mk,n,t']): # 10c\n",
    "\n",
    "    node = plan[0]\n",
    "    if node.info['sql_str'] not in dict1.keys():\n",
    "        num += 1\n",
    "        dict1[node.info['sql_str']] = num\n",
    "    # if dict1[node.info['sql_str']] == 2:\n",
    "    print(i)\n",
    "    # print(node.info['sql_str'])\n",
    "    print(\"sql\", dict1[node.info['sql_str']])\n",
    "    print(\"index\", node.info['index'])\n",
    "    print(node.cost)\n",
    "    hint_node = plans_lib.FilterScansOrJoins(node.Copy())\n",
    "    # print(hint_node.hint_str())\n",
    "    # print(node)\n",
    "    # print(node.info['query_feature'])\n",
    "    print(node.info['latency'])\n",
    "        ####\n",
    "    model.eval()\n",
    "    null_node = plans_lib.Binarize(node)\n",
    "    trees, indexes = encoding.TreeConvFeaturize(nodeFeaturizer, [null_node], 200)\n",
    "    cali = torch.tanh(model(node.info['query_feature'].unsqueeze(0), trees, indexes)).add(1).squeeze(1)\n",
    "    print(cali)\n",
    "    print(cali * torch.log(torch.tensor([node.cost])))\n",
    "\n",
    "# for j,i in enumerate(dict1.keys()):\n",
    "#     print(j+1, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5080.347275\n",
      "1 5080.314775\n",
      "2 5079.609497\n",
      "3 5080.319775\n",
      "4 199003.346644\n",
      "5 199002.641366\n",
      "6 199003.351644\n",
      "7 199003.364144\n",
      "8 199014.516644\n",
      "9 5080.3174\n",
      "10 5080.347275\n",
      "11 5080.314775\n",
      "12 5080.319775\n",
      "13 5091.482275\n",
      "14 5091.487275\n",
      "15 5091.499775\n",
      "16 199014.519144\n",
      "17 5080.328525\n",
      "18 5080.344775\n",
      "19 5080.312275\n",
      "20 5078.06981\n",
      "21 5080.317275\n",
      "22 1112142.885839\n",
      "23 1112140.643374\n",
      "24 1112142.890839\n",
      "25 1112142.903339\n",
      "26 1112154.595839\n",
      "27 5080.3149\n",
      "28 5080.344775\n",
      "29 5080.312275\n",
      "30 5080.317275\n",
      "31 5092.019775\n",
      "32 5092.024775\n",
      "33 5092.037275\n",
      "34 1112154.598339\n",
      "35 5080.326025\n",
      "36 5080.344775\n",
      "37 5080.312275\n",
      "38 5078.069839\n",
      "39 5080.317275\n",
      "40 68595.999112\n",
      "41 68593.756676\n",
      "42 68596.004112\n",
      "43 68596.016612\n",
      "44 68607.709112\n",
      "45 5080.3149\n",
      "46 5080.344775\n",
      "47 5080.312275\n",
      "48 5080.317275\n",
      "49 5092.019775\n",
      "50 5092.024775\n",
      "51 5092.037275\n",
      "52 68607.711612\n",
      "53 5080.326025\n",
      "54 31888.114087\n",
      "55 31888.091587\n",
      "56 29262.396865\n",
      "57 31888.101587\n",
      "58 282197.203131\n",
      "59 279571.50841\n",
      "60 282197.213131\n",
      "61 282197.210631\n",
      "62 284385.861192\n",
      "63 31888.094212\n",
      "64 31888.114087\n",
      "65 61150.033173\n",
      "66 31888.099087\n",
      "67 63338.698734\n",
      "68 34076.764647\n",
      "69 34076.764647\n",
      "70 284385.863692\n",
      "71 31888.096587\n",
      "72 34302.775257\n",
      "73 1965570.752063\n",
      "74 34301.388117\n",
      "75 2192822.890294\n",
      "76 261553.526348\n",
      "77 261552.713848\n",
      "78 284165.556662\n",
      "79 34300.654367\n",
      "80 34302.775257\n",
      "81 34301.218117\n",
      "82 34301.553117\n",
      "83 56914.07343\n",
      "84 56914.40843\n",
      "85 56915.61557\n",
      "86 284165.721662\n",
      "87 56914.08718\n",
      "88 34301.231867\n",
      "89 91644.865246\n",
      "90 162766.788445\n",
      "91 91644.69723\n",
      "92 203550.775626\n",
      "93 132428.68441\n",
      "94 132428.52191\n",
      "95 158814.851911\n",
      "96 91644.54848\n",
      "97 91644.865246\n",
      "98 91644.65723\n",
      "99 91644.73223\n",
      "100 118030.99973\n",
      "101 118031.07473\n",
      "102 118031.192747\n",
      "103 158814.886911\n",
      "104 91644.67098\n",
      "105 31500.679629\n",
      "106 16923766.898079\n",
      "107 31339.239312\n",
      "108 16946379.753392\n",
      "109 53952.094626\n",
      "110 53910.519626\n",
      "111 140441.030243\n",
      "112 53914.674626\n",
      "113 31301.819312\n",
      "114 31500.679629\n",
      "115 31330.916812\n",
      "116 31347.556812\n",
      "117 117861.43993\n",
      "118 117878.07993\n",
      "119 118031.187747\n",
      "120 140449.347743\n",
      "121 31330.930562\n",
      "122 500905.752849\n",
      "123 30849680.805421\n",
      "124 500590.414549\n",
      "125 31485289.474459\n",
      "126 1136199.083587\n",
      "127 1135746.081682\n",
      "128 1162135.394285\n",
      "129 1136131.828587\n",
      "130 500523.159549\n",
      "131 500905.752849\n",
      "132 500575.462049\n",
      "133 500605.362049\n",
      "134 526964.787152\n",
      "135 526994.687152\n",
      "136 527295.062952\n",
      "137 1162150.336785\n",
      "138 500575.545799\n",
      "139 43652.298567\n",
      "140 43651.42692\n",
      "141 43651.64192\n",
      "142 130184.192502\n",
      "143 130184.407502\n",
      "144 130185.049149\n",
      "145 152808.937815\n",
      "146 43651.44067\n",
      "147 43652.298567\n",
      "148 256718.186553\n",
      "149 43651.53692\n",
      "150 279343.241866\n",
      "151 66276.592233\n",
      "152 66276.079733\n",
      "153 152808.832815\n",
      "154 66276.128483\n",
      "155 43651.07317\n",
      "{'QueryId': '43651.06067', 'Plan': {'Node Type': 'HashJoin', 'Node Type ID': '181', 'Relation IDs': 'k mk t mi_idx it2 mi it1 kt', 'Join Cond': 'it1.id = mi.info_type_id, it2.id = mi_idx.info_type_id, k.id = mk.keyword_id, kt.id = t.kind_id, mi.movie_id = mi_idx.movie_id, mk.movie_id = mi.movie_id, mk.movie_id = mi_idx.movie_id, t.id = mi.movie_id, t.id = mi_idx.movie_id, t.id = mk.movie_id', 'Path Target': 't.title, mi_idx.info', 'Startup Cost': 5075.890586, 'Total Cost': 43651.07317, 'Plan Rows': 1.0, 'Plan Width': 23, 'Plans': [{'Node Type': 'NestLoop', 'Node Type ID': '179', 'Relation IDs': 'mi_idx it2 mi it1', 'Join Cond': 'it1.id = mi.info_type_id, it2.id = mi_idx.info_type_id, mi.movie_id = mi_idx.movie_id', 'Path Target': 'mi_idx.info, mi_idx.movie_id, mi.movie_id', 'Startup Cost': 2.86, 'Total Cost': 38577.871333, 'Plan Rows': 43.0, 'Plan Width': 14, 'Plans': [{'Node Type': 'SeqScan', 'Node Type ID': '169', 'Relation IDs': 'it1', 'Base Restrict Info': \"((it1.info)::text = 'countries'::text)\", 'Path Target': 'it1.id', 'Startup Cost': 0.0, 'Total Cost': 2.4125, 'Plan Rows': 1.0, 'Plan Width': 4}, {'Node Type': 'NestLoop', 'Node Type ID': '179', 'Relation IDs': 'mi_idx it2 mi', 'Join Cond': 'it2.id = mi_idx.info_type_id, mi.movie_id = mi_idx.movie_id', 'Path Target': 'mi_idx.info, mi_idx.movie_id, mi.info_type_id, mi.movie_id', 'Startup Cost': 2.86, 'Total Cost': 38514.471333, 'Plan Rows': 4879.0, 'Plan Width': 18, 'Plans': [{'Node Type': 'HashJoin', 'Node Type ID': '181', 'Relation IDs': 'mi_idx it2', 'Join Cond': 'it2.id = mi_idx.info_type_id', 'Path Target': 'mi_idx.info, mi_idx.movie_id', 'Startup Cost': 2.425, 'Total Cost': 26211.939, 'Plan Rows': 3328.0, 'Plan Width': 10, 'Plans': [{'Node Type': 'SeqScan', 'Node Type ID': '169', 'Relation IDs': 'mi_idx', 'Base Restrict Info': \"((mi_idx.info)::text > '6.0'::text)\", 'Path Target': 'mi_idx.info, mi_idx.info_type_id, mi_idx.movie_id', 'Startup Cost': 0.0, 'Total Cost': 25185.4375, 'Plan Rows': 376020.0, 'Plan Width': 14}, {'Node Type': 'SeqScan', 'Node Type ID': '169', 'Relation IDs': 'it2', 'Base Restrict Info': \"((it2.info)::text = 'rating'::text)\", 'Path Target': 'it2.id', 'Startup Cost': 0.0, 'Total Cost': 2.4125, 'Plan Rows': 1.0, 'Plan Width': 4}]}, {'Node Type': 'IndexScan', 'Node Type ID': '170', 'Relation IDs': 'mi', 'Base Restrict Info': \"((mi.info)::text = ANY ('{Sweden,Norway,Germany,Denmark,Swedish,Denish,Norwegian,German,USA,American}'::text[]))\", 'Required Outer': 'mi_idx', 'Path Target': 'mi.info_type_id, mi.movie_id', 'Startup Cost': 0.435, 'Total Cost': 3.676674, 'Plan Rows': 2.0, 'Plan Width': 8}]}]}, {'Node Type': 'NestLoop', 'Node Type ID': '179', 'Relation IDs': 'k mk t kt', 'Join Cond': 'k.id = mk.keyword_id, kt.id = t.kind_id, t.id = mk.movie_id', 'Path Target': 'mk.movie_id, t.title, t.id', 'Startup Cost': 0.8625, 'Total Cost': 5073.018086, 'Plan Rows': 1.0, 'Plan Width': 25, 'Plans': [{'Node Type': 'NestLoop', 'Node Type ID': '179', 'Relation IDs': 'k mk t', 'Join Cond': 'k.id = mk.keyword_id, t.id = mk.movie_id', 'Path Target': 'mk.movie_id, t.title, t.kind_id, t.id', 'Startup Cost': 0.8625, 'Total Cost': 5071.918086, 'Plan Rows': 1.0, 'Plan Width': 29, 'Plans': [{'Node Type': 'NestLoop', 'Node Type ID': '179', 'Relation IDs': 'k mk', 'Join Cond': 'k.id = mk.keyword_id', 'Path Target': 'mk.movie_id', 'Startup Cost': 0.4325, 'Total Cost': 5038.721012, 'Plan Rows': 67.0, 'Plan Width': 4, 'Plans': [{'Node Type': 'SeqScan', 'Node Type ID': '169', 'Relation IDs': 'k', 'Base Restrict Info': \"((k.keyword)::text = ANY ('{murder,murder-in-title}'::text[]))\", 'Path Target': 'k.id', 'Startup Cost': 0.0, 'Total Cost': 2626.125, 'Plan Rows': 2.0, 'Plan Width': 4}, {'Node Type': 'IndexScan', 'Node Type ID': '170', 'Relation IDs': 'mk', 'Required Outer': 'k', 'Path Target': 'mk.keyword_id, mk.movie_id', 'Startup Cost': 0.4325, 'Total Cost': 1203.278006, 'Plan Rows': 302.0, 'Plan Width': 8}]}, {'Node Type': 'IndexScan', 'Node Type ID': '170', 'Relation IDs': 't', 'Base Restrict Info': \"(t.production_year > 2010), (((t.title)::text ~~ '%murder%'::text) OR ((t.title)::text ~~ '%Murder%'::text) OR ((t.title)::text ~~ '%Mord%'::text))\", 'Required Outer': 'mk', 'Path Target': 't.title, t.kind_id, t.id', 'Startup Cost': 0.43, 'Total Cost': 0.495461, 'Plan Rows': 1.0, 'Plan Width': 25}]}, {'Node Type': 'SeqScan', 'Node Type ID': '169', 'Relation IDs': 'kt', 'Base Restrict Info': \"((kt.kind)::text = 'movie'::text)\", 'Path Target': 'kt.id', 'Startup Cost': 0.0, 'Total Cost': 1.0875, 'Plan Rows': 1.0, 'Plan Width': 4}]}]}}\n",
      "156 94294.940931\n",
      "157 94294.908431\n",
      "158 94294.913431\n",
      "159 120683.493396\n",
      "160 120683.498396\n",
      "161 120683.510896\n",
      "162 161467.498077\n",
      "163 94294.922181\n",
      "164 94294.940931\n",
      "165 94294.908431\n",
      "166 94294.913431\n",
      "167 135078.908112\n",
      "168 135078.913112\n",
      "169 135078.925612\n",
      "170 161467.498077\n",
      "171 94294.922181\n",
      "172 34428.018066\n",
      "173 34427.985566\n",
      "174 34427.990566\n",
      "175 261680.461298\n",
      "176 261680.466298\n",
      "177 261680.478798\n",
      "178 284293.321611\n",
      "179 34427.999316\n",
      "180 34428.018066\n",
      "181 34427.985566\n",
      "182 34427.990566\n",
      "183 57040.84088\n",
      "184 57040.84588\n",
      "185 57040.85838\n",
      "186 284293.321611\n",
      "187 57040.85463\n",
      "188 34427.999316\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./error.pkl', 'rb') as f:\n",
    "    message = pickle.load(f)\n",
    "for j,i in enumerate(message):\n",
    "    # if float(i['Plan']['Total Cost']) == 84058.53:\n",
    "    #     print(\"yes\")\n",
    "    print(j,float(i['Plan']['Total Cost']))\n",
    "    if j== 155:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT mi.info,\n",
      "       mi_idx.info,\n",
      "       n.name,\n",
      "       t.title\n",
      "FROM info_type AS it2,\n",
      "     keyword AS k,\n",
      "     movie_keyword AS mk,\n",
      "     movie_info_idx AS mi_idx,\n",
      "     complete_cast AS cc,\n",
      "     comp_cast_type AS cct1,\n",
      "     comp_cast_type AS cct2,\n",
      "     cast_info AS ci,\n",
      "     movie_info AS mi,\n",
      "     info_type AS it1,\n",
      "     name AS n,\n",
      "     title AS t\n",
      "WHERE cct1.id = cc.subject_id\n",
      "  AND cct2.id = cc.status_id\n",
      "  AND ci.movie_id = cc.movie_id\n",
      "  AND ci.movie_id = mi.movie_id\n",
      "  AND ci.movie_id = mi_idx.movie_id\n",
      "  AND ci.movie_id = mk.movie_id\n",
      "  AND it1.id = mi.info_type_id\n",
      "  AND it2.id = mi_idx.info_type_id\n",
      "  AND k.id = mk.keyword_id\n",
      "  AND mi.movie_id = cc.movie_id\n",
      "  AND mi.movie_id = mi_idx.movie_id\n",
      "  AND mi.movie_id = mk.movie_id\n",
      "  AND mi_idx.movie_id = cc.movie_id\n",
      "  AND mi_idx.movie_id = mk.movie_id\n",
      "  AND mk.movie_id = cc.movie_id\n",
      "  AND n.id = ci.person_id\n",
      "  AND t.id = cc.movie_id\n",
      "  AND t.id = ci.movie_id\n",
      "  AND t.id = mi.movie_id\n",
      "  AND t.id = mi_idx.movie_id\n",
      "  AND t.id = mk.movie_id\n",
      "  AND ((cct1.kind)::text = ANY ('{cast,crew}'::text[]))\n",
      "  AND ((cct2.kind)::text = 'complete+verified'::text)\n",
      "  AND ((ci.note)::text = ANY ('{(writer),(head writer),(written by),(story),(story editor)}'::text[]))\n",
      "  AND ((it1.info)::text = 'genres'::text)\n",
      "  AND ((it2.info)::text = 'votes'::text)\n",
      "  AND ((k.keyword)::text = ANY ('{murder,violence,blood,gore ,death,female-nudity,hospital}'::text[]))\n",
      "  AND ((mi.info)::text = ANY ('{Horror,Thriller}'::text[]))\n",
      "  AND ((n.gender)::text = 'm'::text)\n",
      "  AND (t.production_year > 2000);\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "sql = \"SELECT mi.info,mi_idx.info,n.name,t.title FROM   info_type AS it2, keyword AS k, movie_keyword AS mk, movie_info_idx AS mi_idx, complete_cast AS cc, comp_cast_type AS cct1, comp_cast_type AS cct2, cast_info AS ci, movie_info AS mi, info_type AS it1, name AS n, title AS t  WHERE cct1.id = cc.subject_id AND cct2.id = cc.status_id AND ci.movie_id = cc.movie_id AND ci.movie_id = mi.movie_id AND ci.movie_id = mi_idx.movie_id AND ci.movie_id = mk.movie_id AND it1.id = mi.info_type_id AND it2.id = mi_idx.info_type_id AND k.id = mk.keyword_id AND mi.movie_id = cc.movie_id AND mi.movie_id = mi_idx.movie_id AND mi.movie_id = mk.movie_id AND mi_idx.movie_id = cc.movie_id AND mi_idx.movie_id = mk.movie_id AND mk.movie_id = cc.movie_id AND n.id = ci.person_id AND t.id = cc.movie_id AND t.id = ci.movie_id AND t.id = mi.movie_id AND t.id = mi_idx.movie_id AND t.id = mk.movie_id AND ((cct1.kind)::text = ANY ('{cast,crew}'::text[])) AND ((cct2.kind)::text = 'complete+verified'::text) AND ((ci.note)::text = ANY ('{(writer),(head writer),(written by),(story),(story editor)}'::text[])) AND ((it1.info)::text = 'genres'::text) AND ((it2.info)::text = 'votes'::text) AND ((k.keyword)::text = ANY ('{murder,violence,blood,gore ,death,female-nudity,hospital}'::text[])) AND ((mi.info)::text = ANY ('{Horror,Thriller}'::text[])) AND ((n.gender)::text = 'm'::text) AND (t.production_year > 2000);\"\n",
    "sql = sqlparse.format(sql, reindent=True, keyword_case=\"upper\")\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT mi.info,\n",
      "       mi_idx.info,\n",
      "       n.name,\n",
      "       t.title\n",
      "FROM comp_cast_type AS cct2,\n",
      "     info_type AS it2,\n",
      "     keyword AS k,\n",
      "     movie_keyword AS mk,\n",
      "     movie_info_idx AS mi_idx,\n",
      "     complete_cast AS cc,\n",
      "     comp_cast_type AS cct1,\n",
      "     cast_info AS ci,\n",
      "     movie_info AS mi,\n",
      "     info_type AS it1,\n",
      "     name AS n,\n",
      "     title AS t\n",
      "WHERE cct1.id = cc.subject_id\n",
      "  AND cct2.id = cc.status_id\n",
      "  AND ci.movie_id = cc.movie_id\n",
      "  AND ci.movie_id = mi.movie_id\n",
      "  AND ci.movie_id = mi_idx.movie_id\n",
      "  AND ci.movie_id = mk.movie_id\n",
      "  AND it1.id = mi.info_type_id\n",
      "  AND it2.id = mi_idx.info_type_id\n",
      "  AND k.id = mk.keyword_id\n",
      "  AND mi.movie_id = cc.movie_id\n",
      "  AND mi.movie_id = mi_idx.movie_id\n",
      "  AND mi.movie_id = mk.movie_id\n",
      "  AND mi_idx.movie_id = cc.movie_id\n",
      "  AND mi_idx.movie_id = mk.movie_id\n",
      "  AND mk.movie_id = cc.movie_id\n",
      "  AND n.id = ci.person_id\n",
      "  AND t.id = cc.movie_id\n",
      "  AND t.id = ci.movie_id\n",
      "  AND t.id = mi.movie_id\n",
      "  AND t.id = mi_idx.movie_id\n",
      "  AND t.id = mk.movie_id\n",
      "  AND ((cct1.kind)::text = ANY ('{cast,crew}'::text[]))\n",
      "  AND ((cct2.kind)::text = 'complete+verified'::text)\n",
      "  AND ((ci.note)::text = ANY ('{(writer),(head writer),(written by),(story),(story editor)}'::text[]))\n",
      "  AND ((it1.info)::text = 'genres'::text)\n",
      "  AND ((it2.info)::text = 'votes'::text)\n",
      "  AND ((k.keyword)::text = ANY ('{murder,violence,blood,gore,death,female-nudity,hospital}'::text[]))\n",
      "  AND ((mi.info)::text = ANY ('{Horror,Thriller}'::text[]))\n",
      "  AND ((n.gender)::text = 'm'::text)\n",
      "  AND (t.production_year > 2000);\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "sql = \"SELECT mi.info,mi_idx.info,n.name,t.title   FROM   comp_cast_type AS cct2, info_type AS it2, keyword AS k, movie_keyword AS mk, movie_info_idx AS mi_idx, complete_cast AS cc, comp_cast_type AS cct1, cast_info AS ci, movie_info AS mi, info_type AS it1, name AS n, title AS t  WHERE cct1.id = cc.subject_id AND cct2.id = cc.status_id AND ci.movie_id = cc.movie_id AND ci.movie_id = mi.movie_id AND ci.movie_id = mi_idx.movie_id AND ci.movie_id = mk.movie_id AND it1.id = mi.info_type_id AND it2.id = mi_idx.info_type_id AND k.id = mk.keyword_id AND mi.movie_id = cc.movie_id AND mi.movie_id = mi_idx.movie_id AND mi.movie_id = mk.movie_id AND mi_idx.movie_id = cc.movie_id AND mi_idx.movie_id = mk.movie_id AND mk.movie_id = cc.movie_id AND n.id = ci.person_id AND t.id = cc.movie_id AND t.id = ci.movie_id AND t.id = mi.movie_id AND t.id = mi_idx.movie_id AND t.id = mk.movie_id AND ((cct1.kind)::text = ANY ('{cast,crew}'::text[])) AND ((cct2.kind)::text = 'complete+verified'::text) AND ((ci.note)::text = ANY ('{(writer),(head writer),(written by),(story),(story editor)}'::text[])) AND ((it1.info)::text = 'genres'::text) AND ((it2.info)::text = 'votes'::text) AND ((k.keyword)::text = ANY ('{murder,violence,blood,gore,death,female-nudity,hospital}'::text[])) AND ((mi.info)::text = ANY ('{Horror,Thriller}'::text[])) AND ((n.gender)::text = 'm'::text) AND (t.production_year > 2000);\"\n",
    "sql = sqlparse.format(sql, reindent=True, keyword_case=\"upper\")\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "# 假设 exp1[key] 是一个列表\n",
    "exp1 = {'key': [1, 2, 3]}\n",
    "values = [4, 5, 6]\n",
    "\n",
    "# 使用 extend 方法将 values 中的元素添加到 exp1[key] 列表的末尾\n",
    "exp1['key'].extend(values)\n",
    "\n",
    "# 输出修改后的 exp1[key]\n",
    "print(exp1['key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入尺寸: torch.Size([3, 54, 50])\n",
      "输出尺寸: torch.Size([3, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from util import treeconv\n",
    "\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, input_channels, num_channels,\n",
    "                 use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = treeconv.TreeConv1d(input_channels, num_channels,\n",
    "                                         kernel_size=3, padding=1, stride=strides)\n",
    "        self.conv2 = treeconv.TreeConv1d(num_channels, num_channels,\n",
    "                                         kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = treeconv.TreeConv1d(input_channels, num_channels,\n",
    "                                         kernel_size=1, stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = treeconv.TreeStandardize()\n",
    "        self.bn2 = treeconv.TreeStandardize()\n",
    "        self.relu1 = treeconv.TreeAct(nn.LeakyReLU())\n",
    "        self.relu2 = treeconv.TreeAct(nn.LeakyReLU())\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = self.relu1(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return self.relu2(Y)\n",
    "    \n",
    "def resnet_block(input_channels, num_channels, num_residuals,\n",
    "                 first_block=False):\n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(input_channels, num_channels,\n",
    "                                use_1x1conv=True, strides=2))\n",
    "        else:\n",
    "            blk.append(Residual(num_channels, num_channels))\n",
    "    return blk\n",
    "\n",
    "\n",
    "\n",
    "input_size = 50\n",
    "data = torch.randn(3, 54, input_size)\n",
    "indexes = torch.randint(0, 5, size=(3, input_size, 1))  # 修正为在 data 尺寸范围内的索引值\n",
    "\n",
    "b1 = nn.Sequential(treeconv.TreeConv1d(input_size, 64,\n",
    "                                         kernel_size=3, padding=1, stride=1),\n",
    "                   treeconv.TreeStandardize(),treeconv.TreeAct(nn.LeakyReLU()),\n",
    "                   treeconv.TreeMaxPool_With_Kernel_Stride())\n",
    "b2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True))\n",
    "b3 = nn.Sequential(*resnet_block(64, 128, 2))\n",
    "b4 = nn.Sequential(*resnet_block(128, 256, 2))\n",
    "\n",
    "# 实例化 TreeConv1d\n",
    "# tree_conv1d = treeconv.TreeConv1d(in_dims=54, out_dims=128)\n",
    "net = nn.Sequential(b1, b2, b3, b4, treeconv.TreeAvgPool())\n",
    "# ,\n",
    "# net =Residual(54, 128)\n",
    "# 前向传播\n",
    "output_feats = net((data, indexes))\n",
    "# for layer in net:\n",
    "#     (data, indexes) = layer((data, indexes))\n",
    "#     print(layer.__class__.__name__,'output shape:\\t', (data, indexes).shape)\n",
    "\n",
    "# 打印尺寸\n",
    "print(\"输入尺寸:\", data.size())\n",
    "print(\"输出尺寸:\", output_feats.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: torch.Size([2, 3, 4])\n",
      "Output size: torch.Size([2, 3])\n",
      "Output values: tensor([[1.5330, 2.2045, 1.5099],\n",
      "        [1.3790, 0.0403, 1.3384]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 示例输入\n",
    "trees = torch.randn(2, 3, 4)  # 2个样本，每个样本有3个特征，4个节点\n",
    "\n",
    "# 计算每个样本每个特征在节点上的平均值\n",
    "mean_values = trees.max(dim=2).values\n",
    "\n",
    "print(\"Input size:\", trees.size())\n",
    "print(\"Output size:\", mean_values.size())\n",
    "print(\"Output values:\", mean_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.0\n"
     ]
    }
   ],
   "source": [
    "plan = 24.5\n",
    "def find_actual_total_time(json_dict, tolerance=0.02):\n",
    "    if 'Total Cost' in json_dict and 'Actual Total Time' in json_dict:\n",
    "        target_value = round(plan * 100) / 100\n",
    "        if abs(json_dict['Total Cost'] - target_value) < tolerance:\n",
    "            return json_dict['Actual Total Time']\n",
    "    \n",
    "    if 'Plans' in json_dict:\n",
    "        for sub_plan in json_dict['Plans']:\n",
    "            result = find_actual_total_time(sub_plan, tolerance)\n",
    "            if result is not None:\n",
    "                return result\n",
    "    \n",
    "    return None\n",
    "\n",
    "# 示例用法\n",
    "your_json_dict = {\n",
    "    'Total Cost': 42.0,\n",
    "    'Actual Total Time': 10.5,\n",
    "    'Plans': [ {\n",
    "        'Total Cost': 42.0, \n",
    "        'Actual Total Time': 10.0,\n",
    "        'Plans': [{\n",
    "        'Total Cost': 2323, \n",
    "        'Actual Total Time': 15.0,\n",
    "        }]\n",
    "        },\n",
    "        {\n",
    "        'Total Cost': 42.0, \n",
    "        'Actual Total Time': 10.0,\n",
    "        'Plans': [{\n",
    "        'Total Cost': 24.5, \n",
    "        'Actual Total Time': 15.0,\n",
    "        }]\n",
    "    }]\n",
    "}\n",
    "\n",
    "result = find_actual_total_time(your_json_dict)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unlearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
