{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/wyz/miniconda3/envs/leon/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-12-25 14:01:51,684\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"

     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "import os\n",
    "from util.postgres import getPlans\n",
    "def load_sql(query_path):\n",
    "    \"\"\"\n",
    "    :param file_list: list of query file in str\n",
    "    :return: list of sql query string\n",
    "    \"\"\"\n",
    "    sqls = []\n",
    "    with open(query_path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            arr = line.strip().split(\"#####\")\n",
    "            sqls.append((arr[0], arr[1]))\n",
    "    print(\"Read\", len(sqls), \"test queries.\")\n",
    "    return sqls\n",
    "\n",
    "sqls = load_sql('./train/training_query/job.txt')\n",
    "for i,sql in enumerate(sqls):\n",
    "    print(i)\n",
    "    getPlans(sql[1], None,check_hint_used=False,ENABLE_LEON=True, curr_file=sql[0])"
=======
    "import sys\n",
    "sys.path.append('../')\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "import lightning.pytorch.callbacks as plc\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import sys\n",
    "import pytorch_lightning.loggers as pl_loggers\n",
    "import pickle\n",
    "import math\n",
    "import json\n",
    "from test_case import SeqFormer\n",
    "from test_case import get_plan_encoding, configs, load_json, get_op_name_to_one_hot, plan_parameters, add_numerical_scalers\n",
    "from leon_experience import Experience\n",
    "import numpy as np\n",
    "import ray\n",
    "import time\n",
    "from argparse import ArgumentParser\n",
    "import copy\n",
    "import wandb\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "import pickle\n",
    "DEVICE = 'cuda:2' if torch.cuda.is_available() else 'cpu'"
>>>>>>> 182531d921 (1226)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
=======
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
>>>>>>> 182531d921 (1226)
    "with open('./log/exp_v2.pkl', 'rb') as f:\n",
    "    exp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 3,
>>>>>>> 182531d921 (1226)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Length of exp: 93\n",
      "length of sqls: 17\n",
      "********************\n",
      "3240.864\n",
      "25147.540669\n",
      "********************\n",
      "4348.969\n",
      "25852.404174\n",
      "********************\n",
      "4401.098\n",
      "26991.798643\n",
      "********************\n",
      "3691.521\n",
      "25148.532544\n",
      "********************\n",
      "4074.796\n",
      "25956.899662\n",
      "********************\n",
      "3914.095\n",
      "25159.229489\n",
      "********************\n",
      "3915.618\n",
      "25808.932294\n",
      "********************\n",
      "3983.113\n",
      "25162.961169\n",
      "********************\n",
      "4390.488\n",
      "25844.696643\n",
      "********************\n",
      "3646.769\n",
      "25163.910669\n",
      "********************\n",
      "7709.49\n",
      "1050359.307327\n",
      "********************\n",
      "4353.71\n",
      "25178.344669\n",
      "********************\n",
      "7627.494\n",
      "1049324.408346\n",
      "********************\n",
      "4201.248\n",
      "25185.462444\n",
      "********************\n",
      "7505.775\n",
      "1049176.440978\n",
      "********************\n",
      "4120.389\n",
      "25185.462444\n",
      "********************\n",
      "1297.377\n",
      "27160.907165\n",
      "********************\n",
      "1000000\n",
      "27738.136112\n",
      "********************\n",
      "1215.168\n",
      "27113.582004\n",
      "********************\n",
      "1000000\n",
      "30754.921771\n",
      "********************\n",
      "1255.355\n",
      "27117.281379\n",
      "********************\n",
      "1000000\n",
      "28055.086073\n",
      "********************\n",
      "1000000\n",
      "27595.783399\n",
      "********************\n",
      "1323.411\n",
      "27173.649504\n",
      "********************\n",
      "1000000\n",
      "27766.489628\n",
      "********************\n",
      "1272.758\n",
      "27177.402003\n",
      "********************\n",
      "1000000\n",
      "1151543.166484\n",
      "********************\n",
      "1393.011\n",
      "27233.654004\n",
      "********************\n",
      "1000000\n",
      "1148843.330787\n",
      "********************\n",
      "1396.414\n",
      "27262.994504\n",
      "********************\n",
      "1000000\n",
      "1148384.028113\n",
      "********************\n",
      "1406.069\n",
      "27274.144504\n",
      "********************\n",
      "4193.326\n",
      "29545.193602\n",
      "********************\n",
      "Q36\n",
      "20259.63\n",
      "27688.210017\n",
      "********************\n",
      "Q36\n",
      "15437.93\n",
      "26587.910045\n",
      "********************\n",
      "Q36\n",
      "21553.802\n",
      "30995.224449\n",
      "********************\n",
      "Q36\n",
      "17561.689\n",
      "26591.257795\n",
      "********************\n",
      "Q36\n",
      "18580.631\n",
      "27971.085442\n",
      "********************\n",
      "Q36\n",
      "18821.812\n",
      "26630.882197\n",
      "********************\n",
      "Q36\n",
      "18833.9\n",
      "27535.604321\n",
      "********************\n",
      "Q36\n",
      "18263.161\n",
      "26642.525045\n",
      "********************\n",
      "Q36\n",
      "21675.326\n",
      "27679.647783\n",
      "********************\n",
      "Q36\n",
      "15617.028\n",
      "26645.955045\n",
      "********************\n",
      "Q36\n",
      "25821.644\n",
      "1312512.676864\n",
      "********************\n",
      "Q36\n",
      "20848.638\n",
      "26697.110045\n",
      "********************\n",
      "Q36\n",
      "23142.61\n",
      "1309488.537856\n",
      "********************\n",
      "Q36\n",
      "22666.71\n",
      "26723.785045\n",
      "********************\n",
      "Q36\n",
      "23436.923\n",
      "1309053.056735\n",
      "********************\n",
      "Q36\n",
      "22978.364\n",
      "26734.935045\n",
      "********************\n",
      "Q36\n",
      "1121.679\n",
      "26550.964841\n",
      "********************\n",
      "1525.215\n",
      "27597.373993\n",
      "********************\n",
      "1659.409\n",
      "30753.597386\n",
      "********************\n",
      "1301.805\n",
      "26554.153091\n",
      "********************\n",
      "1465.448\n",
      "27868.275234\n",
      "********************\n",
      "1533.107\n",
      "26591.928982\n",
      "********************\n",
      "1497.23\n",
      "27452.799745\n",
      "********************\n",
      "1472.977\n",
      "26603.072841\n",
      "********************\n",
      "1716.931\n",
      "27590.233219\n",
      "********************\n",
      "1228.178\n",
      "26606.359841\n",
      "********************\n",
      "5049.401\n",
      "1021963.57005\n",
      "********************\n",
      "1541.17\n",
      "26655.148841\n",
      "********************\n",
      "4863.514\n",
      "1019078.247898\n",
      "********************\n",
      "1566.477\n",
      "26680.622841\n",
      "********************\n",
      "196.604\n",
      "25661.486916\n",
      "********************\n",
      "487.648\n",
      "25953.276874\n",
      "********************\n",
      "517.455\n",
      "27417.399081\n",
      "********************\n",
      "224.922\n",
      "25682.21883\n",
      "********************\n",
      "453.437\n",
      "26113.347578\n",
      "********************\n",
      "208.977\n",
      "25688.691291\n",
      "********************\n",
      "481.107\n",
      "25892.041039\n",
      "********************\n",
      "178.317\n",
      "25717.675791\n",
      "********************\n",
      "483.342\n",
      "25974.444795\n",
      "********************\n",
      "194.163\n",
      "25731.836291\n",
      "********************\n",
      "2661.671\n",
      "624710.75801\n",
      "********************\n",
      "192.21\n",
      "25736.630746\n",
      "********************\n",
      "2631.232\n",
      "623406.706506\n",
      "********************\n",
      "214.329\n",
      "25736.630746\n",
      "********************\n",
      "99.248\n",
      "27391.826298\n",
      "********************\n",
      "95.997\n",
      "26387.313047\n",
      "********************\n",
      "102.246\n",
      "30290.35448\n",
      "********************\n",
      "108.92\n",
      "26397.706797\n",
      "********************\n",
      "112.655\n",
      "27637.834801\n",
      "********************\n",
      "110.743\n",
      "26433.170927\n",
      "********************\n",
      "113.105\n",
      "27257.211861\n",
      "********************\n",
      "95.224\n",
      "26439.383046\n",
      "********************\n",
      "122.169\n",
      "27386.38323\n",
      "********************\n",
      "104.736\n",
      "26443.685297\n",
      "********************\n",
      "1000000\n",
      "1185442.68273\n",
      "********************\n",
      "98.313\n",
      "26492.626797\n",
      "********************\n",
      "1000000\n",
      "1182790.163051\n",
      "********************\n",
      "122.82\n",
      "26516.580297\n",
      "********************\n",
      "1000000\n",
      "1182409.540111\n",
      "********************\n",
      "103.09\n",
      "26527.730297\n"
=======
      "PostgreSQL config:\n"
>>>>>>> 182531d921 (1226)
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "sqls = []\n",
    "print(\"Length of exp:\", len(exp['cc,cct1,cct2,cn,ct,it1,it2,k,kt,mc,mi,mi_idx,mk,t']))\n",
    "for item in exp['cc,cct1,cct2,cn,ct,it1,it2,k,kt,mc,mi,mi_idx,mk,t']:\n",
    "    # print(\"*\"*20)\n",
    "    node, encoding, attn = item\n",
    "    # print(node.info['latency'])\n",
    "    # print(node.cost)\n",
    "    # print(node.info['sql_str'])\n",
    "    sqls.append(node.info['sql_str'])\n",
    "\n",
    "\n",
    "q36 = list(set(sqls))[1]\n",
    "print(\"length of sqls:\", len([i for i in sqls if i == q36]))\n",
    "for item in exp['cc,cct1,cct2,cn,ct,it1,it2,k,kt,mc,mi,mi_idx,mk,t']:\n",
    "    print(\"*\"*20)\n",
    "    if (\"cn.country_code)::text <> '[de]'::text)\" in node.info['sql_str']):\n",
    "        print(\"Q36\")\n",
    "    node, encoding, attn = item\n",
    "    print(node.info['latency'])\n",
    "    print(node.cost)\n",
    "    # print(node.info['sql_str'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"SELECT cn.name,mi_idx.info,t.title   FROM   info_type AS it1, complete_cast AS cc, comp_cast_type AS cct1, comp_cast_type AS cct2, movie_info_idx AS mi_idx, info_type AS it2, title AS t, movie_info AS mi, movie_companies AS mc, company_name AS cn, company_type AS ct, movie_keyword AS mk, keyword AS k, kind_type AS kt  WHERE kt.id = t.kind_id AND t.id = mi.movie_id AND t.id = mk.movie_id AND t.id = mi_idx.movie_id AND t.id = mc.movie_id AND t.id = cc.movie_id AND mk.movie_id = mi.movie_id AND mk.movie_id = mi_idx.movie_id AND mk.movie_id = mc.movie_id AND mk.movie_id = cc.movie_id AND mi.movie_id = mi_idx.movie_id AND mi.movie_id = mc.movie_id AND mi.movie_id = cc.movie_id AND mc.movie_id = mi_idx.movie_id AND mc.movie_id = cc.movie_id AND mi_idx.movie_id = cc.movie_id AND k.id = mk.keyword_id AND it1.id = mi.info_type_id AND it2.id = mi_idx.info_type_id AND ct.id = mc.company_type_id AND cn.id = mc.company_id AND cct1.id = cc.subject_id AND cct2.id = cc.status_id AND ((it1.info)::text = 'LD official retail price'::text) AND ((cct1.kind)::text = 'cast'::text) AND ((cct2.kind)::text <> 'cast'::text) AND ((mi_idx.info)::text > '1001011002'::text) AND ((it2.info)::text = 'votes'::text) AND (t.production_year > 1976) AND ((mi.info)::text <> ALL ('{USA,Color,Germany,USA,Romance,Mono,War,PFM:35 mm,UK:5 November 2003}'::text[])) AND ((mc.note)::text !~~ '%dia) (%'::text) AND ((cn.country_code)::text <> '[jp]'::text) AND ((kt.kind)::text = ANY ('{video movie,tv mini series,tv series,video movie,episode,tv movie,video movie,tv series,video game,tv series}'::text[]));\",\n",
       " \"SELECT cn.name,mi_idx.info,t.title   FROM   info_type AS it1, complete_cast AS cc, comp_cast_type AS cct1, comp_cast_type AS cct2, movie_info_idx AS mi_idx, info_type AS it2, title AS t, movie_info AS mi, movie_companies AS mc, company_name AS cn, company_type AS ct, movie_keyword AS mk, keyword AS k, kind_type AS kt  WHERE kt.id = t.kind_id AND t.id = mi.movie_id AND t.id = mk.movie_id AND t.id = mi_idx.movie_id AND t.id = mc.movie_id AND t.id = cc.movie_id AND mk.movie_id = mi.movie_id AND mk.movie_id = mi_idx.movie_id AND mk.movie_id = mc.movie_id AND mk.movie_id = cc.movie_id AND mi.movie_id = mi_idx.movie_id AND mi.movie_id = mc.movie_id AND mi.movie_id = cc.movie_id AND mc.movie_id = mi_idx.movie_id AND mc.movie_id = cc.movie_id AND mi_idx.movie_id = cc.movie_id AND k.id = mk.keyword_id AND it1.id = mi.info_type_id AND it2.id = mi_idx.info_type_id AND ct.id = mc.company_type_id AND cn.id = mc.company_id AND cct1.id = cc.subject_id AND cct2.id = cc.status_id AND ((it1.info)::text = 'LD video standard'::text) AND ((cct1.kind)::text = 'crew'::text) AND ((cct2.kind)::text <> 'crew'::text) AND ((mi_idx.info)::text > '16'::text) AND ((it2.info)::text = 'rating'::text) AND (t.production_year > 1933) AND ((mi.info)::text <> ALL ('{Mono,USA,Netherlands:12,Documentary}'::text[])) AND ((mc.note)::text !~~ '%05) (worldwide%'::text) AND ((cn.country_code)::text <> '[de]'::text) AND ((kt.kind)::text = ANY ('{movie,tv mini series,movie,tv movie,video movie,video game,tv mini series,movie}'::text[]));\",\n",
       " \"SELECT cn.name,mi_idx.info,t.title   FROM   info_type AS it1, complete_cast AS cc, comp_cast_type AS cct1, comp_cast_type AS cct2, movie_info_idx AS mi_idx, info_type AS it2, title AS t, movie_info AS mi, movie_companies AS mc, company_name AS cn, company_type AS ct, movie_keyword AS mk, keyword AS k, kind_type AS kt  WHERE kt.id = t.kind_id AND t.id = mi.movie_id AND t.id = mk.movie_id AND t.id = mi_idx.movie_id AND t.id = mc.movie_id AND t.id = cc.movie_id AND mk.movie_id = mi.movie_id AND mk.movie_id = mi_idx.movie_id AND mk.movie_id = mc.movie_id AND mk.movie_id = cc.movie_id AND mi.movie_id = mi_idx.movie_id AND mi.movie_id = mc.movie_id AND mi.movie_id = cc.movie_id AND mc.movie_id = mi_idx.movie_id AND mc.movie_id = cc.movie_id AND mi_idx.movie_id = cc.movie_id AND k.id = mk.keyword_id AND it1.id = mi.info_type_id AND it2.id = mi_idx.info_type_id AND ct.id = mc.company_type_id AND cn.id = mc.company_id AND cct1.id = cc.subject_id AND cct2.id = cc.status_id AND ((it1.info)::text = 'production process protocol'::text) AND ((cct1.kind)::text = 'cast'::text) AND ((cct2.kind)::text <> 'crew'::text) AND ((mi_idx.info)::text > '2......312'::text) AND ((it2.info)::text = 'rating'::text) AND (t.production_year > 1988) AND ((mi.info)::text <> ALL ('{MET:,UK,Color,Black and White}'::text[])) AND ((mc.note)::text !~~ '%ed%'::text) AND ((cn.country_code)::text <> '[us]'::text) AND ((kt.kind)::text = ANY ('{movie,movie,episode,tv series}'::text[]));\",\n",
       " \"SELECT cn.name,mi_idx.info,t.title   FROM   info_type AS it1, complete_cast AS cc, comp_cast_type AS cct1, comp_cast_type AS cct2, movie_info_idx AS mi_idx, info_type AS it2, title AS t, movie_info AS mi, movie_companies AS mc, company_name AS cn, company_type AS ct, movie_keyword AS mk, keyword AS k, kind_type AS kt  WHERE kt.id = t.kind_id AND t.id = mi.movie_id AND t.id = mk.movie_id AND t.id = mi_idx.movie_id AND t.id = mc.movie_id AND t.id = cc.movie_id AND mk.movie_id = mi.movie_id AND mk.movie_id = mi_idx.movie_id AND mk.movie_id = mc.movie_id AND mk.movie_id = cc.movie_id AND mi.movie_id = mi_idx.movie_id AND mi.movie_id = mc.movie_id AND mi.movie_id = cc.movie_id AND mc.movie_id = mi_idx.movie_id AND mc.movie_id = cc.movie_id AND mi_idx.movie_id = cc.movie_id AND k.id = mk.keyword_id AND it1.id = mi.info_type_id AND it2.id = mi_idx.info_type_id AND ct.id = mc.company_type_id AND cn.id = mc.company_id AND cct1.id = cc.subject_id AND cct2.id = cc.status_id AND ((it1.info)::text = 'production dates'::text) AND ((cct1.kind)::text = 'cast'::text) AND ((cct2.kind)::text <> 'complete'::text) AND ((mi_idx.info)::text > '....111212'::text) AND ((it2.info)::text = 'rating'::text) AND (t.production_year > 2006) AND ((mi.info)::text <> ALL ('{English,Bulgaria,Color,RAT:1.78 : 1}'::text[])) AND ((mc.note)::text !~~ '% (Lebanon) (all m%'::text) AND ((cn.country_code)::text <> '[tw]'::text) AND ((kt.kind)::text = ANY ('{tv series,tv movie,video movie,tv mini series,episode,tv mini series,tv series,video movie,video movie,tv movie}'::text[]));\",\n",
       " \"SELECT cn.name,mi_idx.info,t.title   FROM   info_type AS it1, complete_cast AS cc, comp_cast_type AS cct1, comp_cast_type AS cct2, movie_info_idx AS mi_idx, info_type AS it2, title AS t, movie_info AS mi, movie_companies AS mc, company_name AS cn, company_type AS ct, movie_keyword AS mk, keyword AS k, kind_type AS kt  WHERE kt.id = t.kind_id AND t.id = mi.movie_id AND t.id = mk.movie_id AND t.id = mi_idx.movie_id AND t.id = mc.movie_id AND t.id = cc.movie_id AND mk.movie_id = mi.movie_id AND mk.movie_id = mi_idx.movie_id AND mk.movie_id = mc.movie_id AND mk.movie_id = cc.movie_id AND mi.movie_id = mi_idx.movie_id AND mi.movie_id = mc.movie_id AND mi.movie_id = cc.movie_id AND mc.movie_id = mi_idx.movie_id AND mc.movie_id = cc.movie_id AND mi_idx.movie_id = cc.movie_id AND k.id = mk.keyword_id AND it1.id = mi.info_type_id AND it2.id = mi_idx.info_type_id AND ct.id = mc.company_type_id AND cn.id = mc.company_id AND cct1.id = cc.subject_id AND cct2.id = cc.status_id AND ((it1.info)::text = 'adaption'::text) AND ((cct1.kind)::text = 'crew'::text) AND ((cct2.kind)::text <> 'crew'::text) AND ((mi_idx.info)::text > '101'::text) AND ((it2.info)::text = 'rating'::text) AND (t.production_year > 1991) AND ((mi.info)::text <> ALL ('{Canada:91,Color,Czechoslovakia,CAM:Red One Camera}'::text[])) AND ((mc.note)::text !~~ '%tralia) (video) (%'::text) AND ((cn.country_code)::text <> '[rs]'::text) AND ((kt.kind)::text = ANY ('{movie,video movie,tv movie,tv series,tv movie,tv movie,video game,tv mini series}'::text[]));\",\n",
       " \"SELECT cn.name,mi_idx.info,t.title   FROM   info_type AS it1, complete_cast AS cc, comp_cast_type AS cct1, comp_cast_type AS cct2, movie_info_idx AS mi_idx, info_type AS it2, title AS t, movie_info AS mi, movie_companies AS mc, company_name AS cn, company_type AS ct, movie_keyword AS mk, keyword AS k, kind_type AS kt  WHERE kt.id = t.kind_id AND t.id = mi.movie_id AND t.id = mk.movie_id AND t.id = mi_idx.movie_id AND t.id = mc.movie_id AND t.id = cc.movie_id AND mk.movie_id = mi.movie_id AND mk.movie_id = mi_idx.movie_id AND mk.movie_id = mc.movie_id AND mk.movie_id = cc.movie_id AND mi.movie_id = mi_idx.movie_id AND mi.movie_id = mc.movie_id AND mi.movie_id = cc.movie_id AND mc.movie_id = mi_idx.movie_id AND mc.movie_id = cc.movie_id AND mi_idx.movie_id = cc.movie_id AND k.id = mk.keyword_id AND it1.id = mi.info_type_id AND it2.id = mi_idx.info_type_id AND ct.id = mc.company_type_id AND cn.id = mc.company_id AND cct1.id = cc.subject_id AND cct2.id = cc.status_id AND ((it1.info)::text = 'locations'::text) AND ((cct1.kind)::text = 'crew'::text) AND ((cct2.kind)::text <> 'complete'::text) AND ((mi_idx.info)::text > '14'::text) AND ((it2.info)::text = 'votes distribution'::text) AND (t.production_year > 1971) AND ((mi.info)::text <> ALL ('{France,Color,Italian,Italy}'::text[])) AND ((mc.note)::text !~~ '%(Spa%'::text) AND ((cn.country_code)::text <> '[ca]'::text) AND ((kt.kind)::text = ANY ('{tv mini series,tv movie,movie,movie,tv series}'::text[]));\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(sqls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/chenxu/miniconda3/envs/leon/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-12-26 20:36:29,274\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL config:\n",
      "(666,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Tree Transformer Block\n",
    "\"\"\"\n",
    "import util.postgres as postgres\n",
    "from util import envs\n",
    "from util import plans_lib\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# load workload and queryFeaturizer\n",
    "if not os.path.exists('./log/workload_job_training.pkl'):\n",
    "    workload = envs.JoinOrderBenchmark_Train(envs.JoinOrderBenchmark_Train.Params())\n",
    "    workload.workload_info.table_num_rows = postgres.GetAllTableNumRows(workload.workload_info.rel_names)\n",
    "    workload.workload_info.alias_to_names = postgres.GetAllAliasToNames(workload.workload_info.rel_ids)\n",
    "    print(workload.workload_info)\n",
    "    # dump queryFeaturizer and workload\n",
    "    with open('./log/workload_job_training.pkl', 'wb') as f:\n",
    "        pickle.dump(workload, f)\n",
    "else:\n",
    "    \n",
    "    with open('./log/workload_job_training.pkl', 'rb') as f:\n",
    "        workload = pickle.load(f)\n",
    "queryFeaturizer = plans_lib.QueryFeaturizer(workload.workload_info)\n",
    "\n",
    "for item in exp['cc,cct1,cct2,cn,ct,it1,it2,k,kt,mc,mi,mi_idx,mk,t']:\n",
    "    # print(\"*\"*20)\n",
    "    node, encoding, attn = item\n",
    "    plans_lib.GatherUnaryFiltersInfo(node)\n",
    "    postgres.EstimateFilterRows(node)  \n",
    "    print(queryFeaturizer(node).shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/chenxu/miniconda3/envs/leon/lib/python3.8/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "from util.postgres import getPlans\n",
    "from util.dataset import *\n",
    "from util.model import *\n",
    "from leon_pl import load_callbacks\n",
    "from test_case import *\n",
    "import pytorch_lightning.loggers as pl_loggers\n",
    "import os\n",
    "from leon_experience import TIME_OUT\n",
    "\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "Transformer_model = SeqFormer(\n",
    "                        input_dim=configs['node_length'],\n",
    "                        hidden_dim=256,\n",
    "                        output_dim=1,\n",
    "                        mlp_activation=\"ReLU\",\n",
    "                        transformer_activation=\"gelu\",\n",
    "                        mlp_dropout=0.1,\n",
    "                        transformer_dropout=0.1,\n",
    "                        query_dim=666,\n",
    "                        node_embedding_dim=30,\n",
    "                        padding_size=40\n",
    "                    )\n",
    "\n",
    "def Getpair(exp, key=None):\n",
    "    pairs = []\n",
    "    if key:\n",
    "        for j in exp[key]:\n",
    "            for k in exp[key]:\n",
    "                ############################NEW\n",
    "                if j[0].info['sql_str'] != k[0].info['sql_str']:\n",
    "                    continue    \n",
    "\n",
    "                if (j[0].info['sql_str'] == k[0].info['sql_str']) and (j[0].hint_str() == k[0].hint_str()): # sql 和 hint 都相同\n",
    "                    continue\n",
    "\n",
    "                if j[0].info['sql_str'] != k[0].info['sql_str'] and (j[0].info['latency'] == TIME_OUT or k[0].info['latency'] == TIME_OUT):\n",
    "                        continue\n",
    "                # if (j[0].info['latency'] == k[0].info['latency']): # latency 相同 1s之内不把他train_pair\n",
    "                if max(j[0].info['latency'],k[0].info['latency']) / min(j[0].info['latency'],k[0].info['latency']) < 1.2:\n",
    "                    continue\n",
    "                # if j[0].info['latency'] == 90000 or k[0].info['latency'] == 90000:\n",
    "                #     continue\n",
    "                tem = [j, k]\n",
    "                pairs.append(tem)\n",
    "    else:          \n",
    "        for eq in exp.keys():\n",
    "            for j in exp[eq]:\n",
    "                for k in exp[eq]:\n",
    "                    if j[0].info['sql_str'] != k[0].info['sql_str']:\n",
    "                        continue    \n",
    "\n",
    "                    if (j[0].info['sql_str'] == k[0].info['sql_str']) and (j[0].hint_str() == k[0].hint_str()): # sql 和 hint 都相同\n",
    "                        continue\n",
    "                    if j[0].info['sql_str'] != k[0].info['sql_str'] and (j[0].info['latency'] == TIME_OUT or k[0].info['latency'] == TIME_OUT):\n",
    "                        continue\n",
    "                    # if (j[0].info['latency'] == k[0].info['latency']): # latency 相同 1s之内不把他train_pair\n",
    "                    if max(j[0].info['latency'],k[0].info['latency']) / min(j[0].info['latency'],k[0].info['latency']) < 1.2:\n",
    "                        continue\n",
    "                    # if j[0].info['latency'] == 90000 or k[0].info['latency'] == 90000:\n",
    "                    #     continue\n",
    "                    tem = [j, k]\n",
    "                    pairs.append(tem)\n",
    "    return pairs\n",
    "\n",
    "prev_optimizer_state_dict = None\n",
    "model = Transformer_model\n",
    "model = PL_Leon(model, prev_optimizer_state_dict)"
=======
    "import sys\n",
    "from util import pg_executor\n",
    "from util.postgres import *\n",
    "def GetCostFromPg(sql, hint, verbose=False, check_hint_used=False):\n",
    "    with pg_executor.Cursor() as cursor:\n",
    "        # GEQO must be disabled for hinting larger joins to work.\n",
    "        node0 = SqlToPlanNode(sql, comment=hint, verbose=verbose,\n",
    "                              cursor=cursor)[0]\n",
    "        # This copies top-level node's cost (e.g., Aggregate) to the new top level\n",
    "        # node (a Join).\n",
    "        node = plans_lib.FilterScansOrJoins(node0)\n",
    "\n",
    "    if check_hint_used:\n",
    "        expected = hint\n",
    "        actual = node.hint_str(with_physical_hints=ContainsPhysicalHints(hint))\n",
    "        assert expected == actual, 'Expected={}\\nActual={}, actual node:\\n{}\\nSQL=\\n{}'.format(\n",
    "            expected, actual, node, sql)\n",
    "\n",
    "    return node.cost\n"
>>>>>>> 182531d921 (1226)
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "\n",
    "# key = 'cc,cct1,cct2,cn,ct,it1,it2,k,kt,mc,mi,mi_idx,mk,t'\n",
    "\n",
    "# new_exp = {key:[]}\n",
    "# for item in exp['cc,cct1,cct2,cn,ct,it1,it2,k,kt,mc,mi,mi_idx,mk,t']:\n",
    "#     node, encoding, attn = item\n",
    "#     if (\"cn.country_code)::text <> '[de]'::text)\" in node.info['sql_str']):\n",
    "#         # print(\"Q36\")\n",
    "#         continue\n",
    "#     new_exp[key].append(item)\n",
    "\n",
    "# print(len(new_exp[key]))\n",
    "\n",
    "logger = pl_loggers.WandbLogger(save_dir=os.getcwd() + '/logs', name=\"test\", project='leon3')\n",
    "\n",
    "key = None\n",
    "train_pairs = Getpair(exp, key=key)\n",
    "leon_dataset = prepare_dataset(train_pairs, queryFeaturizer=queryFeaturizer)\n",
    "dataloader_train = DataLoader(leon_dataset, batch_size=512, shuffle=True, num_workers=0)\n",
    "# dataloader_val = DataLoader(leon_dataset, batch_size=512, shuffle=False, num_workers=0)\n",
    "dataset_val = BucketDataset(exp, keys=key)\n",
    "batch_sampler = BucketBatchSampler(dataset_val.buckets, batch_size=1)\n",
    "dataloader_val = DataLoader(dataset_val, batch_sampler=batch_sampler)\n"
=======
    "def Getpair(exp):\n",
    "    pairs = []\n",
    "    # for eq in exp.keys():\n",
    "    eq = 'cn,ct,it1,it2,k,kt,mc,mi,mi_idx,mk,t'\n",
    "    for i, j in enumerate(exp[eq]):\n",
    "        for k_index in range(i + 1, len(exp[eq])):\n",
    "            k = exp[eq][k_index]\n",
    "            if (j[0].info['sql_str'] == k[0].info['sql_str']) and (j[0].hint_str() == k[0].hint_str()): # sql 和 hint 都相同\n",
    "                continue\n",
    "            if j[0].info['sql_str'] != k[0].info['sql_str'] and (j[0].info['latency'] == 90000 or k[0].info['latency'] == 90000):\n",
    "                continue\n",
    "            # if (j[0].info['latency'] == k[0].info['latency']): # latency 相同 1s之内不把他train_pair\n",
    "            if max(j[0].info['latency'],k[0].info['latency']) / min(j[0].info['latency'],k[0].info['latency']) < 1.2:\n",
    "                continue\n",
    "            if max(j[0].cost,k[0].cost) / min(j[0].cost,k[0].cost) < 1.2:\n",
    "                continue\n",
    "            # if j[0].info['latency'] == 90000 or k[0].info['latency'] == 90000:\n",
    "            #     continue\n",
    "            tem = [j, k]\n",
    "            pairs.append(tem)\n",
    "    return pairs"
>>>>>>> 182531d921 (1226)
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/chenxu/miniconda3/envs/leon/lib/python3.8/site-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
=======
      "/data1/wyz/miniconda3/envs/leon/lib/python3.8/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwyz12234\u001b[0m (\u001b[33mleon1\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
>>>>>>> 182531d921 (1226)
     ]
    },
    {
     "data": {
      "text/html": [
<<<<<<< HEAD
       "Tracking run with wandb version 0.16.1"
=======
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
>>>>>>> 182531d921 (1226)
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
<<<<<<< HEAD
       "Run data is saved locally in <code>/data1/chenxu/projects/LEONForPostgres__1/logs/wandb/run-20231226_203822-izq1j0s1</code>"
=======
       "Tracking run with wandb version 0.16.0"
>>>>>>> 182531d921 (1226)
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
<<<<<<< HEAD
       "Syncing run <strong><a href='https://wandb.ai/leon1/leon3/runs/izq1j0s1' target=\"_blank\">test</a></strong> to <a href='https://wandb.ai/leon1/leon3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
=======
       "Run data is saved locally in <code>/data1/wyz/online/LEONForPostgres/logs/wandb/run-20231225_140301-0msyb8tp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leon1/leon3/runs/0msyb8tp' target=\"_blank\">exp_pair</a></strong> to <a href='https://wandb.ai/leon1/leon3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
>>>>>>> 182531d921 (1226)
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/leon1/leon3' target=\"_blank\">https://wandb.ai/leon1/leon3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
<<<<<<< HEAD
       " View run at <a href='https://wandb.ai/leon1/leon3/runs/izq1j0s1' target=\"_blank\">https://wandb.ai/leon1/leon3/runs/izq1j0s1</a>"
=======
       " View run at <a href='https://wandb.ai/leon1/leon3/runs/0msyb8tp' target=\"_blank\">https://wandb.ai/leon1/leon3/runs/0msyb8tp</a>"
>>>>>>> 182531d921 (1226)
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name  | Type      | Params\n",
      "------------------------------------\n",
<<<<<<< HEAD
      "0 | model | SeqFormer | 196 K \n",
      "------------------------------------\n",
      "196 K     Trainable params\n",
      "0         Non-trainable params\n",
      "196 K     Total params\n",
      "0.785     Total estimated model params size (MB)\n",
      "/data1/chenxu/miniconda3/envs/leon/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n",
      "/data1/chenxu/miniconda3/envs/leon/lib/python3.8/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (20) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
=======
      "0 | model | SeqFormer | 48.8 K\n",
      "------------------------------------\n",
      "48.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "48.8 K    Total params\n",
      "0.195     Total estimated model params size (MB)\n"
>>>>>>> 182531d921 (1226)
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Epoch 499: 100%|██████████| 20/20 [00:00<00:00, 26.74it/s, v_num=j0s1]"
=======
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
>>>>>>> 182531d921 (1226)
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n"
=======
      "/data1/wyz/miniconda3/envs/leon/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
>>>>>>> 182531d921 (1226)
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Epoch 499: 100%|██████████| 20/20 [00:00<00:00, 26.01it/s, v_num=j0s1]\n",
      "********************\n",
      "Current Accuracy For Each EqSet:  {}\n",
=======
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/wyz/miniconda3/envs/leon/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n",
      "/data1/wyz/miniconda3/envs/leon/lib/python3.8/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (23) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 23/23 [00:06<00:00,  3.50it/s, v_num=b8tp]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=40` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 23/23 [00:06<00:00,  3.49it/s, v_num=b8tp]\n",
      "********************\n",
      "Current Accuracy For Each EqSet:  {'cn,ct,it1,it2,k,kt,mc,mi,mi_idx,mk,t': (0.6680664916885389, 5715)}\n",
>>>>>>> 182531d921 (1226)
      "********************\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "trainer = pl.Trainer(accelerator=\"gpu\",\n",
    "                        devices=[0],\n",
    "                        max_epochs=500,\n",
    "                        callbacks=None,\n",
    "                        logger=logger)\n",
    "\n",
    "# trainer.fit(model, dataloader_train, dataloader_val)\n",
    "trainer.fit(model, dataloader_train)\n",
    "prev_optimizer_state_dict = trainer.optimizers[0].state_dict()\n",
    "\n",
=======
    "from util.dataset import *\n",
    "from util.model import *\n",
    "DEVICE = 'cuda:2' if torch.cuda.is_available() else 'cpu'\n",
    "Transformer_model = SeqFormer(\n",
    "                        input_dim=configs['node_length'],\n",
    "                        hidden_dim=256,\n",
    "                        output_dim=1,\n",
    "                        mlp_activation=\"ReLU\",\n",
    "                        transformer_activation=\"gelu\",\n",
    "                        mlp_dropout=0.1,\n",
    "                        transformer_dropout=0.1,\n",
    "                    )\n",
    "prev_optimizer_state_dict = None\n",
    "model = Transformer_model.to(DEVICE)\n",
    "model = PL_Leon(model, prev_optimizer_state_dict)\n",
    "train_pairs = Getpair(exp)\n",
    "leon_dataset = prepare_dataset(train_pairs)\n",
    "dataloader_train = DataLoader(leon_dataset, batch_size=256, shuffle=True, num_workers=0)\n",
    "# dataloader_val = DataLoader(leon_dataset, batch_size=256, shuffle=False, num_workers=0)\n",
    "# dataset_val = BucketDataset(exp, keys=exp.keys())\n",
    "dataset_val = BucketDataset(exp, keys=['cn,ct,it1,it2,k,kt,mc,mi,mi_idx,mk,t'])\n",
    "batch_sampler = BucketBatchSampler(dataset_val.buckets, batch_size=1)\n",
    "dataloader_val = DataLoader(dataset_val, batch_sampler=batch_sampler)\n",
    "# model = load_model(model_path, prev_optimizer_state_dict).to(DEVICE)\n",
    "model.optimizer_state_dict = prev_optimizer_state_dict\n",
    "\n",
    "logger =  pl_loggers.WandbLogger(save_dir=os.getcwd() + '/logs', name=\"exp_pair\", project='leon3')\n",
    "trainer = pl.Trainer(accelerator=\"gpu\",\n",
    "                    devices=[2],\n",
    "                    max_epochs=40,\n",
    "                    logger=logger)\n",
    "trainer.fit(model, dataloader_train, dataloader_val)\n",
    "prev_optimizer_state_dict = trainer.optimizers[0].state_dict()\n",
>>>>>>> 182531d921 (1226)
    "print(\"*\"*20)\n",
    "print(\"Current Accuracy For Each EqSet: \", model.eq_summary)\n",
    "print(\"*\"*20)"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3个sql\n",
    "********************\n",
    "Current Accuracy For Each EqSet:  {'cc,cct1,cct2,cn,ct,it1,it2,k,kt,mc,mi,mi_idx,mk,t': (0.8683127572016461, 243)}\n",
    "********************\n",
    "\n",
    "2个sql 不要q36\n",
    "********************\n",
    "Current Accuracy For Each EqSet:  {'cc,cct1,cct2,cn,ct,it1,it2,k,kt,mc,mi,mi_idx,mk,t': (0.7298444130127298, 707)}\n",
    "********************\n",
    "\n",
    "3个sql overfit train 500 epoch\n",
    "********************\n",
    "Current Accuracy For Each EqSet:  {'cc,cct1,cct2,cn,ct,it1,it2,k,kt,mc,mi,mi_idx,mk,t': (0.7086280056577087, 707)}\n",
    "********************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
=======
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "885.456\n",
      "7812.802374\n",
      "1 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1127.468\n",
      "7815.719374\n",
      "2 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "4157.456\n",
      "7811.130512\n",
      "3 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1191.24\n",
      "7815.696874\n",
      "4 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "4155.634\n",
      "7811.155495\n",
      "5 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1171.577\n",
      "7814.750227\n",
      "6 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "905.366\n",
      "7811.86688\n",
      "7 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1147.623\n",
      "7815.706874\n",
      "8 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "874.279\n",
      "7812.789874\n",
      "9 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "201973.011669\n",
      "10 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "201972.065022\n",
      "11 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "862.676\n",
      "7812.804999\n",
      "12 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "201973.021669\n",
      "13 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "949.07\n",
      "7812.802374\n",
      "14 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "201973.019169\n",
      "15 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "913.511\n",
      "7812.814874\n",
      "16 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "201984.171669\n",
      "17 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "929.346\n",
      "7812.822374\n",
      "18 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1113.066\n",
      "7815.699499\n",
      "19 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "878.29\n",
      "7812.839874\n",
      "20 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1118.297\n",
      "7815.719374\n",
      "21 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "844.443\n",
      "7812.839874\n",
      "22 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1160.47\n",
      "15630.281248\n",
      "23 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "4090.177\n",
      "7813.215709\n",
      "24 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1151.722\n",
      "7815.704374\n",
      "25 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "4121.875\n",
      "7813.222959\n",
      "26 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1146.519\n",
      "15641.448748\n",
      "27 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "4814.263\n",
      "7813.230459\n",
      "28 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1147.499\n",
      "7826.871874\n",
      "29 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "4088.228\n",
      "7813.232959\n",
      "30 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1091.362\n",
      "7826.871874\n",
      "31 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "4069.875\n",
      "7813.237959\n",
      "32 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "201984.174169\n",
      "33 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "4095.646\n",
      "7813.245459\n",
      "34 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1094.215\n",
      "7815.701874\n",
      "35 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "4036.581\n",
      "7813.245459\n",
      "36 *\n",
      "tensor([1.9996], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "42156.421651\n",
      "37 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "608.721\n",
      "7813.459049\n",
      "38 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "485.723\n",
      "7805.866708\n",
      "39 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "617.855\n",
      "7813.436549\n",
      "40 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "602.42\n",
      "7807.987489\n",
      "41 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "558.884\n",
      "7812.489913\n",
      "42 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "521.877\n",
      "7808.109172\n",
      "43 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "604.647\n",
      "7813.446549\n",
      "44 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "454.653\n",
      "7808.114172\n",
      "45 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "196727.129027\n",
      "46 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "471.196\n",
      "7808.111797\n",
      "47 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "196726.182391\n",
      "48 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "490.04\n",
      "7808.109172\n",
      "49 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "196727.139027\n",
      "50 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "501.345\n",
      "7808.114172\n",
      "51 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "196727.136527\n",
      "52 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "536.852\n",
      "7808.109172\n",
      "53 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "196738.289027\n",
      "54 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "467.37\n",
      "7808.122922\n",
      "55 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "639.93\n",
      "7813.439174\n",
      "56 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "479.857\n",
      "7808.141672\n",
      "57 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "576.033\n",
      "7813.459049\n",
      "58 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "475.103\n",
      "7808.141672\n",
      "59 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "556.034\n",
      "15625.760598\n",
      "60 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "506.256\n",
      "7809.032053\n",
      "61 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "599.629\n",
      "7813.444049\n",
      "62 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "478.385\n",
      "7809.044553\n",
      "63 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "598.191\n",
      "15636.928098\n",
      "64 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "535.891\n",
      "7809.044553\n",
      "65 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "575.848\n",
      "7824.611549\n",
      "66 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "466.918\n",
      "7809.047178\n",
      "67 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "605.677\n",
      "7824.611549\n",
      "68 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "476.693\n",
      "7809.057053\n",
      "69 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "196738.291527\n",
      "70 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "502.064\n",
      "7809.064553\n",
      "71 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "617.836\n",
      "7813.441549\n",
      "72 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "506.684\n",
      "7809.082053\n",
      "73 *\n",
      "tensor([0.0010], grad_fn=<SelectBackward0>)\n",
      "1976.23\n",
      "38488.163206\n",
      "74 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "494.885\n",
      "7809.082053\n",
      "75 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1510.082\n",
      "7806.568127\n",
      "76 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1477.647\n",
      "7803.356695\n",
      "77 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1507.003\n",
      "7806.545627\n",
      "78 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1512.266\n",
      "7805.598981\n",
      "79 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1554.249\n",
      "7805.598981\n",
      "80 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1506.44\n",
      "7806.555627\n",
      "81 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1513.272\n",
      "7805.603981\n",
      "82 *\n",
      "tensor([1.0133e-06], grad_fn=<SelectBackward0>)\n",
      "1614.046\n",
      "33910.345785\n",
      "83 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1459.103\n",
      "7805.601606\n",
      "84 *\n",
      "tensor([1.0729e-06], grad_fn=<SelectBackward0>)\n",
      "1662.748\n",
      "33909.399138\n",
      "85 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1478.206\n",
      "7805.598981\n",
      "86 *\n",
      "tensor([1.0133e-06], grad_fn=<SelectBackward0>)\n",
      "1652.084\n",
      "33910.355785\n",
      "87 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1501.824\n",
      "7805.603981\n",
      "88 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "201962.27171\n",
      "89 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1522.435\n",
      "7805.610246\n",
      "90 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "201961.325063\n",
      "91 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1462.255\n",
      "7805.612731\n",
      "92 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "201962.28171\n",
      "93 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1383.438\n",
      "7805.631481\n",
      "94 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "201962.27921\n",
      "95 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1386.087\n",
      "7805.631481\n",
      "96 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "201973.43171\n",
      "97 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1480.854\n",
      "7806.533127\n",
      "98 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1532.664\n",
      "7806.548252\n",
      "99 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1544.135\n",
      "7806.568127\n",
      "100 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1512.261\n",
      "15611.978755\n",
      "101 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1523.27\n",
      "7806.550627\n",
      "102 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1508.895\n",
      "7806.553127\n",
      "103 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1457.363\n",
      "7806.545627\n",
      "104 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1541.789\n",
      "15623.146255\n",
      "105 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1447.047\n",
      "7806.548252\n",
      "106 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1508.549\n",
      "7817.720627\n",
      "107 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1440.901\n",
      "7806.545627\n",
      "108 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "1504.1\n",
      "7817.720627\n",
      "109 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "5482.479\n",
      "7814.582945\n",
      "110 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "4296.429\n",
      "7812.189084\n",
      "111 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "5453.792\n",
      "7814.560445\n",
      "112 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "5048.357\n",
      "7813.496167\n",
      "113 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "7813.613793\n",
      "114 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "5524.539\n",
      "7814.570445\n",
      "115 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "4719.763\n",
      "7814.419049\n",
      "116 *\n",
      "tensor([1.9999], grad_fn=<SelectBackward0>)\n",
      "5118.396\n",
      "37453.957884\n",
      "117 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "4777.105\n",
      "7814.431549\n",
      "118 *\n",
      "tensor([1.9999], grad_fn=<SelectBackward0>)\n",
      "5075.681\n",
      "37453.011232\n",
      "119 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "4911.505\n",
      "7814.436549\n",
      "120 *\n",
      "tensor([1.9999], grad_fn=<SelectBackward0>)\n",
      "5098.504\n",
      "37453.967884\n",
      "121 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "4256.492\n",
      "7814.434174\n",
      "122 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "207356.169027\n",
      "123 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "4431.642\n",
      "7814.431549\n",
      "124 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "207355.222375\n",
      "125 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "4301.987\n",
      "7814.436549\n",
      "126 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "207356.179027\n",
      "127 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "4828.667\n",
      "7814.431549\n",
      "128 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "207356.176527\n",
      "129 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "4747.564\n",
      "7814.434174\n",
      "130 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "207367.329027\n",
      "131 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "4973.683\n",
      "7814.431549\n",
      "132 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "5338.766\n",
      "7814.56307\n",
      "133 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "4348.86\n",
      "7814.445299\n",
      "134 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "5450.014\n",
      "7814.582945\n",
      "135 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "4867.397\n",
      "7814.444049\n",
      "136 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "5407.069\n",
      "15628.008389\n",
      "137 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "4901.323\n",
      "7814.451549\n",
      "138 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "5417.153\n",
      "7814.567945\n",
      "139 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "4519.073\n",
      "7814.464049\n",
      "140 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "5552.269\n",
      "15639.175889\n",
      "141 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "4396.744\n",
      "7814.464049\n",
      "142 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "5562.365\n",
      "7825.735445\n",
      "143 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "4784.616\n",
      "7814.469049\n",
      "144 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "5285.895\n",
      "7825.735445\n",
      "145 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "4715.86\n",
      "7814.469049\n",
      "146 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "207367.331527\n",
      "147 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2074.362\n",
      "7810.594402\n",
      "148 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2564.909\n",
      "7814.414049\n",
      "149 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2584.632\n",
      "7814.391549\n",
      "150 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2346.313\n",
      "7811.901484\n",
      "151 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2560.24\n",
      "7813.444902\n",
      "152 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2350.868\n",
      "7812.824366\n",
      "153 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2527.295\n",
      "7814.401549\n",
      "154 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2321.035\n",
      "7812.836866\n",
      "155 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "201970.284027\n",
      "156 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2271.056\n",
      "7812.841866\n",
      "157 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "201969.33738\n",
      "158 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2037.443\n",
      "7812.839491\n",
      "159 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "201970.294027\n",
      "160 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2089.547\n",
      "7812.836866\n",
      "161 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "201970.291527\n",
      "162 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2105.877\n",
      "7812.841866\n",
      "163 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "201981.444027\n",
      "164 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2289.643\n",
      "7812.836866\n",
      "165 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2435.199\n",
      "7814.394174\n",
      "166 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2228.948\n",
      "7812.839491\n",
      "167 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2449.944\n",
      "7814.414049\n",
      "168 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2481.792\n",
      "7812.836866\n",
      "169 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2582.519\n",
      "15627.670598\n",
      "170 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2116.628\n",
      "7812.850616\n",
      "171 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2584.037\n",
      "7814.399049\n",
      "172 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2360.766\n",
      "7812.849366\n",
      "173 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2476.44\n",
      "15638.838098\n",
      "174 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2260.158\n",
      "7812.856866\n",
      "175 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2585.107\n",
      "7825.566549\n",
      "176 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2132.04\n",
      "7812.869366\n",
      "177 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2569.85\n",
      "7825.566549\n",
      "178 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2127.521\n",
      "7812.869366\n",
      "179 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "201981.446527\n",
      "180 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2357.741\n",
      "7812.874366\n",
      "181 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2551.523\n",
      "7814.396549\n",
      "182 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2347.459\n",
      "7812.874366\n",
      "183 *\n",
      "tensor([1.9990], grad_fn=<SelectBackward0>)\n",
      "6053.937\n",
      "40375.598051\n",
      "184 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "255.778\n",
      "7805.483165\n",
      "185 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "370.726\n",
      "7813.459049\n",
      "186 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "366.148\n",
      "7813.436549\n",
      "187 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "278.754\n",
      "7806.092597\n",
      "188 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "350.873\n",
      "7812.48992\n",
      "189 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "263.351\n",
      "7806.790247\n",
      "190 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "348.124\n",
      "7813.446549\n",
      "191 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "261.943\n",
      "7807.713128\n",
      "192 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "194845.739027\n",
      "193 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "282.724\n",
      "7807.725628\n",
      "194 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "194844.792398\n",
      "195 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "287.957\n",
      "7807.725628\n",
      "196 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "194845.749027\n",
      "197 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "280.541\n",
      "7807.725628\n",
      "198 *\n",
      "tensor([1.9999], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "194845.746527\n",
      "199 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "294.677\n",
      "7807.725628\n",
      "200 *\n",
      "tensor([1.9999], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "194856.899027\n",
      "201 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "285.963\n",
      "7807.730628\n",
      "202 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "374.122\n",
      "7813.439174\n",
      "203 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "286.532\n",
      "7807.728253\n",
      "204 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "365.872\n",
      "7813.459049\n",
      "205 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "286.876\n",
      "7807.730628\n",
      "206 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "383.929\n",
      "15625.760598\n",
      "207 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "283.342\n",
      "7807.728253\n",
      "208 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "369.719\n",
      "7813.444049\n",
      "209 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "280.267\n",
      "7807.739378\n",
      "210 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "349.828\n",
      "15636.928098\n",
      "211 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "263.17\n",
      "7807.738128\n",
      "212 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "349.149\n",
      "7824.611549\n",
      "213 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "259.888\n",
      "7807.745628\n",
      "214 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "350.62\n",
      "7824.611549\n",
      "215 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "262.197\n",
      "7807.758128\n",
      "216 *\n",
      "tensor([1.9999], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "194856.901527\n",
      "217 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "285.035\n",
      "7807.758128\n",
      "218 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "368.486\n",
      "7813.441549\n",
      "219 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "286.658\n",
      "7807.763128\n",
      "220 *\n",
      "tensor([0.0008], grad_fn=<SelectBackward0>)\n",
      "1392.207\n",
      "38309.104056\n",
      "221 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "279.644\n",
      "7807.763128\n",
      "222 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2530.916\n",
      "7814.414049\n",
      "223 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2218.583\n",
      "7810.594402\n",
      "224 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2546.002\n",
      "7814.391549\n",
      "225 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2454.281\n",
      "7811.901484\n",
      "226 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2521.141\n",
      "7813.444902\n",
      "227 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2402.884\n",
      "7812.824366\n",
      "228 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2485.363\n",
      "7814.401549\n",
      "229 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2460.457\n",
      "7812.836866\n",
      "230 *\n",
      "tensor([1.9999], grad_fn=<SelectBackward0>)\n",
      "2656.334\n",
      "37453.788989\n",
      "231 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2484.651\n",
      "7812.841866\n",
      "232 *\n",
      "tensor([1.9999], grad_fn=<SelectBackward0>)\n",
      "2616.922\n",
      "37452.842342\n",
      "233 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2175.573\n",
      "7812.839491\n",
      "234 *\n",
      "tensor([1.9999], grad_fn=<SelectBackward0>)\n",
      "2608.774\n",
      "37453.798989\n",
      "235 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2119.064\n",
      "7812.836866\n",
      "236 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "201970.284027\n",
      "237 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2148.577\n",
      "7812.841866\n",
      "238 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "201969.33738\n",
      "239 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2373.648\n",
      "7812.836866\n",
      "240 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "201970.294027\n",
      "241 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2392.483\n",
      "7812.839491\n",
      "242 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "201970.291527\n",
      "243 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2385.022\n",
      "7812.836866\n",
      "244 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "201981.444027\n",
      "245 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2149.832\n",
      "7812.850616\n",
      "246 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2474.902\n",
      "7814.394174\n",
      "247 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2382.877\n",
      "7812.849366\n",
      "248 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2578.424\n",
      "7814.414049\n",
      "249 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2460.178\n",
      "7812.856866\n",
      "250 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2495.396\n",
      "15627.670598\n",
      "251 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2139.431\n",
      "7812.869366\n",
      "252 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2562.886\n",
      "7814.399049\n",
      "253 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2160.146\n",
      "7812.869366\n",
      "254 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2479.497\n",
      "15638.838098\n",
      "255 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2362.906\n",
      "7812.874366\n",
      "256 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2477.828\n",
      "7825.566549\n",
      "257 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2334.53\n",
      "7812.874366\n",
      "258 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2456.998\n",
      "7825.566549\n",
      "259 *\n",
      "tensor([2.0000], grad_fn=<SelectBackward0>)\n",
      "90000\n",
      "201981.446527\n",
      "260 *\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "2208.006\n",
      "7814.245581\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from util.plans_lib import FilterScansOrJoins\n",
    "cost = []\n",
    "latency = []\n",
    "cail_cost_list = []\n",
    "for j, i in enumerate(exp['cn,ct,it1,it2,k,kt,mc,mi,mi_idx,mk,t']): # cn,ct,it1,it2,k,kt,mc,mi,mi_idx,mk,t cn,ct,it,it2,kt,mc,mi,miidx,t cn,ct,it2,k,kt,mc,mi,mi_idx,mk,t\n",
    "    print(j,\"*\")\n",
    "    model.model.to('cpu')\n",
    "    model.model.eval()\n",
    "    print(model.model(i[1],i[2])[:, 0])\n",
    "    cail_cost = torch.log(torch.tensor(i[0].cost)) * model.model(i[1],i[2])[:, 0]\n",
    "    cail_cost_list.append(cail_cost.detach().numpy())\n",
    "    # print(i[0].info['latency'])\n",
    "    latency.append(i[0].info['latency'])\n",
    "    cost.append(i[0].cost)\n",
    "    print(i[0].info['latency'])\n",
    "    \n",
    "    print(i[0].cost)\n",
    "\n",
    "    # print(i[0].info['sql_str'])\n",
    "    # print(i[0])\n",
    "    \n",
    "    hint_node = FilterScansOrJoins(i[0].Copy())\n",
    "    GetCostFromPg(i[0].info['sql_str'], hint_node.hint_str(), verbose=False, check_hint_used=True)\n",
    "    # print(hint_node.hint_str())\n",
    "    # print(i[0].cost)\n",
    "    # if j ==  0:\n",
    "    #     hint_node = FilterScansOrJoins(i[0].Copy())\n",
    "    #     print(hint_node.hint_str(), hint_node.info['sql_str'])\n",
    "    #     break\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 示例数据\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# 绘制 latency vs cost 散点图\n",
    "ax.scatter(latency, cost, label='Latency vs Cost', color='blue')\n",
    "\n",
    "# 将横轴和纵轴都设置为对数坐标\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "# 添加标题和标签\n",
    "ax.set_title('Latency vs Cost Scatter Plot (Logarithmic Scale)')\n",
    "ax.set_xlabel('Latency')\n",
    "ax.set_ylabel('Cost')\n",
    "\n",
    "# 显示图例\n",
    "ax.legend()\n",
    "\n",
    "# 创建新的坐标轴对象\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "# 绘制 latency vs cali_cost 散点图\n",
    "ax2.scatter(latency, cail_cost_list, label='Latency vs Cali Cost', color='red')\n",
    "\n",
    "# 添加标签\n",
    "ax2.set_ylabel('Cali Cost')\n",
    "\n",
    "# 显示图例\n",
    "ax2.legend()\n",
    "\n",
    "# 显示图形\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
>>>>>>> 182531d921 (1226)
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
