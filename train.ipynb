{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1000 test queries.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "canceling statement due to user request\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mQueryCanceled\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/data1/chenxu/projects/LEONForPostgres__1/util/pg_executor.py:135\u001b[0m, in \u001b[0;36mExecute\u001b[0;34m(sql, verbose, geqo_off, timeout_ms, cursor)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     result \u001b[38;5;241m=\u001b[39m cursor\u001b[38;5;241m.\u001b[39mfetchall()\n",
      "\u001b[0;31mQueryCanceled\u001b[0m: canceling statement due to user request\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,sql \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sqls):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mgetPlans\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mcheck_hint_used\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mENABLE_LEON\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurr_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data1/chenxu/projects/LEONForPostgres__1/util/postgres.py:166\u001b[0m, in \u001b[0;36mgetPlans\u001b[0;34m(sql, hint, verbose, check_hint_used, ENABLE_LEON, curr_file)\u001b[0m\n\u001b[1;32m    164\u001b[0m             cursor\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSET leon_query_name=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurr_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    165\u001b[0m     geqo_off \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_run_explain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexplain(verbose, format json)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                          \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mhint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mgeqo_off\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeqo_off\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mcursor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mresult\n\u001b[1;32m    173\u001b[0m     _SetGeneticOptimizer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, cursor)  \u001b[38;5;66;03m# Restores.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# if check_hint_used:\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m#     expected = hint\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m#     actual = node.hint_str(with_physical_hints=ContainsPhysicalHints(hint))\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m#     assert expected == actual, 'Expected={}\\nActual={}\\nactual node:{}\\nSQL={}'.format(\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m#         expected, actual, node, sql)\u001b[39;00m\n",
      "File \u001b[0;32m/data1/chenxu/projects/LEONForPostgres__1/util/postgres.py:269\u001b[0m, in \u001b[0;36m_run_explain\u001b[0;34m(explain_str, sql, comment, verbose, geqo_off, timeout_ms, cursor, is_test, remote)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pg_executor\u001b[38;5;241m.\u001b[39mExecuteRemote(s, verbose, geqo_off, timeout_ms)\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpg_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeqo_off\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data1/chenxu/projects/LEONForPostgres__1/util/pg_executor.py:140\u001b[0m, in \u001b[0;36mExecute\u001b[0;34m(sql, verbose, geqo_off, timeout_ms, cursor)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, psycopg2\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mQueryCanceled):\n\u001b[0;32m--> 140\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcanceling statement due to statement timeout\u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[1;32m    141\u001b[0m                \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mstrip(), e\n\u001b[1;32m    142\u001b[0m         result \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    143\u001b[0m         has_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: canceling statement due to user request\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from util.postgres import getPlans\n",
    "def load_sql(query_path):\n",
    "    \"\"\"\n",
    "    :param file_list: list of query file in str\n",
    "    :return: list of sql query string\n",
    "    \"\"\"\n",
    "    sqls = []\n",
    "    with open(query_path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            arr = line.strip().split(\"#####\")\n",
    "            sqls.append((arr[0], arr[1]))\n",
    "    print(\"Read\", len(sqls), \"test queries.\")\n",
    "    return sqls\n",
    "\n",
    "sqls = load_sql('./train/training_query/job.txt')\n",
    "for i,sql in enumerate(sqls):\n",
    "    print(i)\n",
    "    getPlans(sql[1], None,check_hint_used=False,ENABLE_LEON=True, curr_file=sql[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./log/exp_v2.pkl', 'rb') as f:\n",
    "    exp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of exp: 93\n",
      "length of sqls: 17\n",
      "********************\n",
      "3240.864\n",
      "25147.540669\n",
      "********************\n",
      "4348.969\n",
      "25852.404174\n",
      "********************\n",
      "4401.098\n",
      "26991.798643\n",
      "********************\n",
      "3691.521\n",
      "25148.532544\n",
      "********************\n",
      "4074.796\n",
      "25956.899662\n",
      "********************\n",
      "3914.095\n",
      "25159.229489\n",
      "********************\n",
      "3915.618\n",
      "25808.932294\n",
      "********************\n",
      "3983.113\n",
      "25162.961169\n",
      "********************\n",
      "4390.488\n",
      "25844.696643\n",
      "********************\n",
      "3646.769\n",
      "25163.910669\n",
      "********************\n",
      "7709.49\n",
      "1050359.307327\n",
      "********************\n",
      "4353.71\n",
      "25178.344669\n",
      "********************\n",
      "7627.494\n",
      "1049324.408346\n",
      "********************\n",
      "4201.248\n",
      "25185.462444\n",
      "********************\n",
      "7505.775\n",
      "1049176.440978\n",
      "********************\n",
      "4120.389\n",
      "25185.462444\n",
      "********************\n",
      "1297.377\n",
      "27160.907165\n",
      "********************\n",
      "1000000\n",
      "27738.136112\n",
      "********************\n",
      "1215.168\n",
      "27113.582004\n",
      "********************\n",
      "1000000\n",
      "30754.921771\n",
      "********************\n",
      "1255.355\n",
      "27117.281379\n",
      "********************\n",
      "1000000\n",
      "28055.086073\n",
      "********************\n",
      "1000000\n",
      "27595.783399\n",
      "********************\n",
      "1323.411\n",
      "27173.649504\n",
      "********************\n",
      "1000000\n",
      "27766.489628\n",
      "********************\n",
      "1272.758\n",
      "27177.402003\n",
      "********************\n",
      "1000000\n",
      "1151543.166484\n",
      "********************\n",
      "1393.011\n",
      "27233.654004\n",
      "********************\n",
      "1000000\n",
      "1148843.330787\n",
      "********************\n",
      "1396.414\n",
      "27262.994504\n",
      "********************\n",
      "1000000\n",
      "1148384.028113\n",
      "********************\n",
      "1406.069\n",
      "27274.144504\n",
      "********************\n",
      "4193.326\n",
      "29545.193602\n",
      "********************\n",
      "Q36\n",
      "20259.63\n",
      "27688.210017\n",
      "********************\n",
      "Q36\n",
      "15437.93\n",
      "26587.910045\n",
      "********************\n",
      "Q36\n",
      "21553.802\n",
      "30995.224449\n",
      "********************\n",
      "Q36\n",
      "17561.689\n",
      "26591.257795\n",
      "********************\n",
      "Q36\n",
      "18580.631\n",
      "27971.085442\n",
      "********************\n",
      "Q36\n",
      "18821.812\n",
      "26630.882197\n",
      "********************\n",
      "Q36\n",
      "18833.9\n",
      "27535.604321\n",
      "********************\n",
      "Q36\n",
      "18263.161\n",
      "26642.525045\n",
      "********************\n",
      "Q36\n",
      "21675.326\n",
      "27679.647783\n",
      "********************\n",
      "Q36\n",
      "15617.028\n",
      "26645.955045\n",
      "********************\n",
      "Q36\n",
      "25821.644\n",
      "1312512.676864\n",
      "********************\n",
      "Q36\n",
      "20848.638\n",
      "26697.110045\n",
      "********************\n",
      "Q36\n",
      "23142.61\n",
      "1309488.537856\n",
      "********************\n",
      "Q36\n",
      "22666.71\n",
      "26723.785045\n",
      "********************\n",
      "Q36\n",
      "23436.923\n",
      "1309053.056735\n",
      "********************\n",
      "Q36\n",
      "22978.364\n",
      "26734.935045\n",
      "********************\n",
      "Q36\n",
      "1121.679\n",
      "26550.964841\n",
      "********************\n",
      "1525.215\n",
      "27597.373993\n",
      "********************\n",
      "1659.409\n",
      "30753.597386\n",
      "********************\n",
      "1301.805\n",
      "26554.153091\n",
      "********************\n",
      "1465.448\n",
      "27868.275234\n",
      "********************\n",
      "1533.107\n",
      "26591.928982\n",
      "********************\n",
      "1497.23\n",
      "27452.799745\n",
      "********************\n",
      "1472.977\n",
      "26603.072841\n",
      "********************\n",
      "1716.931\n",
      "27590.233219\n",
      "********************\n",
      "1228.178\n",
      "26606.359841\n",
      "********************\n",
      "5049.401\n",
      "1021963.57005\n",
      "********************\n",
      "1541.17\n",
      "26655.148841\n",
      "********************\n",
      "4863.514\n",
      "1019078.247898\n",
      "********************\n",
      "1566.477\n",
      "26680.622841\n",
      "********************\n",
      "196.604\n",
      "25661.486916\n",
      "********************\n",
      "487.648\n",
      "25953.276874\n",
      "********************\n",
      "517.455\n",
      "27417.399081\n",
      "********************\n",
      "224.922\n",
      "25682.21883\n",
      "********************\n",
      "453.437\n",
      "26113.347578\n",
      "********************\n",
      "208.977\n",
      "25688.691291\n",
      "********************\n",
      "481.107\n",
      "25892.041039\n",
      "********************\n",
      "178.317\n",
      "25717.675791\n",
      "********************\n",
      "483.342\n",
      "25974.444795\n",
      "********************\n",
      "194.163\n",
      "25731.836291\n",
      "********************\n",
      "2661.671\n",
      "624710.75801\n",
      "********************\n",
      "192.21\n",
      "25736.630746\n",
      "********************\n",
      "2631.232\n",
      "623406.706506\n",
      "********************\n",
      "214.329\n",
      "25736.630746\n",
      "********************\n",
      "99.248\n",
      "27391.826298\n",
      "********************\n",
      "95.997\n",
      "26387.313047\n",
      "********************\n",
      "102.246\n",
      "30290.35448\n",
      "********************\n",
      "108.92\n",
      "26397.706797\n",
      "********************\n",
      "112.655\n",
      "27637.834801\n",
      "********************\n",
      "110.743\n",
      "26433.170927\n",
      "********************\n",
      "113.105\n",
      "27257.211861\n",
      "********************\n",
      "95.224\n",
      "26439.383046\n",
      "********************\n",
      "122.169\n",
      "27386.38323\n",
      "********************\n",
      "104.736\n",
      "26443.685297\n",
      "********************\n",
      "1000000\n",
      "1185442.68273\n",
      "********************\n",
      "98.313\n",
      "26492.626797\n",
      "********************\n",
      "1000000\n",
      "1182790.163051\n",
      "********************\n",
      "122.82\n",
      "26516.580297\n",
      "********************\n",
      "1000000\n",
      "1182409.540111\n",
      "********************\n",
      "103.09\n",
      "26527.730297\n"
     ]
    }
   ],
   "source": [
    "sqls = []\n",
    "print(\"Length of exp:\", len(exp['cc,cct1,cct2,cn,ct,it1,it2,k,kt,mc,mi,mi_idx,mk,t']))\n",
    "for item in exp['cc,cct1,cct2,cn,ct,it1,it2,k,kt,mc,mi,mi_idx,mk,t']:\n",
    "    # print(\"*\"*20)\n",
    "    node, encoding, attn = item\n",
    "    # print(node.info['latency'])\n",
    "    # print(node.cost)\n",
    "    # print(node.info['sql_str'])\n",
    "    sqls.append(node.info['sql_str'])\n",
    "\n",
    "\n",
    "q36 = list(set(sqls))[1]\n",
    "print(\"length of sqls:\", len([i for i in sqls if i == q36]))\n",
    "for item in exp['cc,cct1,cct2,cn,ct,it1,it2,k,kt,mc,mi,mi_idx,mk,t']:\n",
    "    print(\"*\"*20)\n",
    "    if (\"cn.country_code)::text <> '[de]'::text)\" in node.info['sql_str']):\n",
    "        print(\"Q36\")\n",
    "    node, encoding, attn = item\n",
    "    print(node.info['latency'])\n",
    "    print(node.cost)\n",
    "    # print(node.info['sql_str'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"SELECT cn.name,mi_idx.info,t.title   FROM   info_type AS it1, complete_cast AS cc, comp_cast_type AS cct1, comp_cast_type AS cct2, movie_info_idx AS mi_idx, info_type AS it2, title AS t, movie_info AS mi, movie_companies AS mc, company_name AS cn, company_type AS ct, movie_keyword AS mk, keyword AS k, kind_type AS kt  WHERE kt.id = t.kind_id AND t.id = mi.movie_id AND t.id = mk.movie_id AND t.id = mi_idx.movie_id AND t.id = mc.movie_id AND t.id = cc.movie_id AND mk.movie_id = mi.movie_id AND mk.movie_id = mi_idx.movie_id AND mk.movie_id = mc.movie_id AND mk.movie_id = cc.movie_id AND mi.movie_id = mi_idx.movie_id AND mi.movie_id = mc.movie_id AND mi.movie_id = cc.movie_id AND mc.movie_id = mi_idx.movie_id AND mc.movie_id = cc.movie_id AND mi_idx.movie_id = cc.movie_id AND k.id = mk.keyword_id AND it1.id = mi.info_type_id AND it2.id = mi_idx.info_type_id AND ct.id = mc.company_type_id AND cn.id = mc.company_id AND cct1.id = cc.subject_id AND cct2.id = cc.status_id AND ((it1.info)::text = 'LD official retail price'::text) AND ((cct1.kind)::text = 'cast'::text) AND ((cct2.kind)::text <> 'cast'::text) AND ((mi_idx.info)::text > '1001011002'::text) AND ((it2.info)::text = 'votes'::text) AND (t.production_year > 1976) AND ((mi.info)::text <> ALL ('{USA,Color,Germany,USA,Romance,Mono,War,PFM:35 mm,UK:5 November 2003}'::text[])) AND ((mc.note)::text !~~ '%dia) (%'::text) AND ((cn.country_code)::text <> '[jp]'::text) AND ((kt.kind)::text = ANY ('{video movie,tv mini series,tv series,video movie,episode,tv movie,video movie,tv series,video game,tv series}'::text[]));\",\n",
       " \"SELECT cn.name,mi_idx.info,t.title   FROM   info_type AS it1, complete_cast AS cc, comp_cast_type AS cct1, comp_cast_type AS cct2, movie_info_idx AS mi_idx, info_type AS it2, title AS t, movie_info AS mi, movie_companies AS mc, company_name AS cn, company_type AS ct, movie_keyword AS mk, keyword AS k, kind_type AS kt  WHERE kt.id = t.kind_id AND t.id = mi.movie_id AND t.id = mk.movie_id AND t.id = mi_idx.movie_id AND t.id = mc.movie_id AND t.id = cc.movie_id AND mk.movie_id = mi.movie_id AND mk.movie_id = mi_idx.movie_id AND mk.movie_id = mc.movie_id AND mk.movie_id = cc.movie_id AND mi.movie_id = mi_idx.movie_id AND mi.movie_id = mc.movie_id AND mi.movie_id = cc.movie_id AND mc.movie_id = mi_idx.movie_id AND mc.movie_id = cc.movie_id AND mi_idx.movie_id = cc.movie_id AND k.id = mk.keyword_id AND it1.id = mi.info_type_id AND it2.id = mi_idx.info_type_id AND ct.id = mc.company_type_id AND cn.id = mc.company_id AND cct1.id = cc.subject_id AND cct2.id = cc.status_id AND ((it1.info)::text = 'LD video standard'::text) AND ((cct1.kind)::text = 'crew'::text) AND ((cct2.kind)::text <> 'crew'::text) AND ((mi_idx.info)::text > '16'::text) AND ((it2.info)::text = 'rating'::text) AND (t.production_year > 1933) AND ((mi.info)::text <> ALL ('{Mono,USA,Netherlands:12,Documentary}'::text[])) AND ((mc.note)::text !~~ '%05) (worldwide%'::text) AND ((cn.country_code)::text <> '[de]'::text) AND ((kt.kind)::text = ANY ('{movie,tv mini series,movie,tv movie,video movie,video game,tv mini series,movie}'::text[]));\",\n",
       " \"SELECT cn.name,mi_idx.info,t.title   FROM   info_type AS it1, complete_cast AS cc, comp_cast_type AS cct1, comp_cast_type AS cct2, movie_info_idx AS mi_idx, info_type AS it2, title AS t, movie_info AS mi, movie_companies AS mc, company_name AS cn, company_type AS ct, movie_keyword AS mk, keyword AS k, kind_type AS kt  WHERE kt.id = t.kind_id AND t.id = mi.movie_id AND t.id = mk.movie_id AND t.id = mi_idx.movie_id AND t.id = mc.movie_id AND t.id = cc.movie_id AND mk.movie_id = mi.movie_id AND mk.movie_id = mi_idx.movie_id AND mk.movie_id = mc.movie_id AND mk.movie_id = cc.movie_id AND mi.movie_id = mi_idx.movie_id AND mi.movie_id = mc.movie_id AND mi.movie_id = cc.movie_id AND mc.movie_id = mi_idx.movie_id AND mc.movie_id = cc.movie_id AND mi_idx.movie_id = cc.movie_id AND k.id = mk.keyword_id AND it1.id = mi.info_type_id AND it2.id = mi_idx.info_type_id AND ct.id = mc.company_type_id AND cn.id = mc.company_id AND cct1.id = cc.subject_id AND cct2.id = cc.status_id AND ((it1.info)::text = 'production process protocol'::text) AND ((cct1.kind)::text = 'cast'::text) AND ((cct2.kind)::text <> 'crew'::text) AND ((mi_idx.info)::text > '2......312'::text) AND ((it2.info)::text = 'rating'::text) AND (t.production_year > 1988) AND ((mi.info)::text <> ALL ('{MET:,UK,Color,Black and White}'::text[])) AND ((mc.note)::text !~~ '%ed%'::text) AND ((cn.country_code)::text <> '[us]'::text) AND ((kt.kind)::text = ANY ('{movie,movie,episode,tv series}'::text[]));\",\n",
       " \"SELECT cn.name,mi_idx.info,t.title   FROM   info_type AS it1, complete_cast AS cc, comp_cast_type AS cct1, comp_cast_type AS cct2, movie_info_idx AS mi_idx, info_type AS it2, title AS t, movie_info AS mi, movie_companies AS mc, company_name AS cn, company_type AS ct, movie_keyword AS mk, keyword AS k, kind_type AS kt  WHERE kt.id = t.kind_id AND t.id = mi.movie_id AND t.id = mk.movie_id AND t.id = mi_idx.movie_id AND t.id = mc.movie_id AND t.id = cc.movie_id AND mk.movie_id = mi.movie_id AND mk.movie_id = mi_idx.movie_id AND mk.movie_id = mc.movie_id AND mk.movie_id = cc.movie_id AND mi.movie_id = mi_idx.movie_id AND mi.movie_id = mc.movie_id AND mi.movie_id = cc.movie_id AND mc.movie_id = mi_idx.movie_id AND mc.movie_id = cc.movie_id AND mi_idx.movie_id = cc.movie_id AND k.id = mk.keyword_id AND it1.id = mi.info_type_id AND it2.id = mi_idx.info_type_id AND ct.id = mc.company_type_id AND cn.id = mc.company_id AND cct1.id = cc.subject_id AND cct2.id = cc.status_id AND ((it1.info)::text = 'production dates'::text) AND ((cct1.kind)::text = 'cast'::text) AND ((cct2.kind)::text <> 'complete'::text) AND ((mi_idx.info)::text > '....111212'::text) AND ((it2.info)::text = 'rating'::text) AND (t.production_year > 2006) AND ((mi.info)::text <> ALL ('{English,Bulgaria,Color,RAT:1.78 : 1}'::text[])) AND ((mc.note)::text !~~ '% (Lebanon) (all m%'::text) AND ((cn.country_code)::text <> '[tw]'::text) AND ((kt.kind)::text = ANY ('{tv series,tv movie,video movie,tv mini series,episode,tv mini series,tv series,video movie,video movie,tv movie}'::text[]));\",\n",
       " \"SELECT cn.name,mi_idx.info,t.title   FROM   info_type AS it1, complete_cast AS cc, comp_cast_type AS cct1, comp_cast_type AS cct2, movie_info_idx AS mi_idx, info_type AS it2, title AS t, movie_info AS mi, movie_companies AS mc, company_name AS cn, company_type AS ct, movie_keyword AS mk, keyword AS k, kind_type AS kt  WHERE kt.id = t.kind_id AND t.id = mi.movie_id AND t.id = mk.movie_id AND t.id = mi_idx.movie_id AND t.id = mc.movie_id AND t.id = cc.movie_id AND mk.movie_id = mi.movie_id AND mk.movie_id = mi_idx.movie_id AND mk.movie_id = mc.movie_id AND mk.movie_id = cc.movie_id AND mi.movie_id = mi_idx.movie_id AND mi.movie_id = mc.movie_id AND mi.movie_id = cc.movie_id AND mc.movie_id = mi_idx.movie_id AND mc.movie_id = cc.movie_id AND mi_idx.movie_id = cc.movie_id AND k.id = mk.keyword_id AND it1.id = mi.info_type_id AND it2.id = mi_idx.info_type_id AND ct.id = mc.company_type_id AND cn.id = mc.company_id AND cct1.id = cc.subject_id AND cct2.id = cc.status_id AND ((it1.info)::text = 'adaption'::text) AND ((cct1.kind)::text = 'crew'::text) AND ((cct2.kind)::text <> 'crew'::text) AND ((mi_idx.info)::text > '101'::text) AND ((it2.info)::text = 'rating'::text) AND (t.production_year > 1991) AND ((mi.info)::text <> ALL ('{Canada:91,Color,Czechoslovakia,CAM:Red One Camera}'::text[])) AND ((mc.note)::text !~~ '%tralia) (video) (%'::text) AND ((cn.country_code)::text <> '[rs]'::text) AND ((kt.kind)::text = ANY ('{movie,video movie,tv movie,tv series,tv movie,tv movie,video game,tv mini series}'::text[]));\",\n",
       " \"SELECT cn.name,mi_idx.info,t.title   FROM   info_type AS it1, complete_cast AS cc, comp_cast_type AS cct1, comp_cast_type AS cct2, movie_info_idx AS mi_idx, info_type AS it2, title AS t, movie_info AS mi, movie_companies AS mc, company_name AS cn, company_type AS ct, movie_keyword AS mk, keyword AS k, kind_type AS kt  WHERE kt.id = t.kind_id AND t.id = mi.movie_id AND t.id = mk.movie_id AND t.id = mi_idx.movie_id AND t.id = mc.movie_id AND t.id = cc.movie_id AND mk.movie_id = mi.movie_id AND mk.movie_id = mi_idx.movie_id AND mk.movie_id = mc.movie_id AND mk.movie_id = cc.movie_id AND mi.movie_id = mi_idx.movie_id AND mi.movie_id = mc.movie_id AND mi.movie_id = cc.movie_id AND mc.movie_id = mi_idx.movie_id AND mc.movie_id = cc.movie_id AND mi_idx.movie_id = cc.movie_id AND k.id = mk.keyword_id AND it1.id = mi.info_type_id AND it2.id = mi_idx.info_type_id AND ct.id = mc.company_type_id AND cn.id = mc.company_id AND cct1.id = cc.subject_id AND cct2.id = cc.status_id AND ((it1.info)::text = 'locations'::text) AND ((cct1.kind)::text = 'crew'::text) AND ((cct2.kind)::text <> 'complete'::text) AND ((mi_idx.info)::text > '14'::text) AND ((it2.info)::text = 'votes distribution'::text) AND (t.production_year > 1971) AND ((mi.info)::text <> ALL ('{France,Color,Italian,Italy}'::text[])) AND ((mc.note)::text !~~ '%(Spa%'::text) AND ((cn.country_code)::text <> '[ca]'::text) AND ((kt.kind)::text = ANY ('{tv mini series,tv movie,movie,movie,tv series}'::text[]));\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(sqls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/chenxu/miniconda3/envs/leon/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-12-26 20:36:29,274\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL config:\n",
      "(666,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Tree Transformer Block\n",
    "\"\"\"\n",
    "import util.postgres as postgres\n",
    "from util import envs\n",
    "from util import plans_lib\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# load workload and queryFeaturizer\n",
    "if not os.path.exists('./log/workload_job_training.pkl'):\n",
    "    workload = envs.JoinOrderBenchmark_Train(envs.JoinOrderBenchmark_Train.Params())\n",
    "    workload.workload_info.table_num_rows = postgres.GetAllTableNumRows(workload.workload_info.rel_names)\n",
    "    workload.workload_info.alias_to_names = postgres.GetAllAliasToNames(workload.workload_info.rel_ids)\n",
    "    print(workload.workload_info)\n",
    "    # dump queryFeaturizer and workload\n",
    "    with open('./log/workload_job_training.pkl', 'wb') as f:\n",
    "        pickle.dump(workload, f)\n",
    "else:\n",
    "    \n",
    "    with open('./log/workload_job_training.pkl', 'rb') as f:\n",
    "        workload = pickle.load(f)\n",
    "queryFeaturizer = plans_lib.QueryFeaturizer(workload.workload_info)\n",
    "\n",
    "for item in exp['cc,cct1,cct2,cn,ct,it1,it2,k,kt,mc,mi,mi_idx,mk,t']:\n",
    "    # print(\"*\"*20)\n",
    "    node, encoding, attn = item\n",
    "    plans_lib.GatherUnaryFiltersInfo(node)\n",
    "    postgres.EstimateFilterRows(node)  \n",
    "    print(queryFeaturizer(node).shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/chenxu/miniconda3/envs/leon/lib/python3.8/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "from util.postgres import getPlans\n",
    "from util.dataset import *\n",
    "from util.model import *\n",
    "from leon_pl import load_callbacks\n",
    "from test_case import *\n",
    "import pytorch_lightning.loggers as pl_loggers\n",
    "import os\n",
    "from leon_experience import TIME_OUT\n",
    "\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "Transformer_model = SeqFormer(\n",
    "                        input_dim=configs['node_length'],\n",
    "                        hidden_dim=256,\n",
    "                        output_dim=1,\n",
    "                        mlp_activation=\"ReLU\",\n",
    "                        transformer_activation=\"gelu\",\n",
    "                        mlp_dropout=0.1,\n",
    "                        transformer_dropout=0.1,\n",
    "                        query_dim=666,\n",
    "                        node_embedding_dim=30,\n",
    "                        padding_size=40\n",
    "                    )\n",
    "\n",
    "def Getpair(exp, key=None):\n",
    "    pairs = []\n",
    "    if key:\n",
    "        for j in exp[key]:\n",
    "            for k in exp[key]:\n",
    "                ############################NEW\n",
    "                if j[0].info['sql_str'] != k[0].info['sql_str']:\n",
    "                    continue    \n",
    "\n",
    "                if (j[0].info['sql_str'] == k[0].info['sql_str']) and (j[0].hint_str() == k[0].hint_str()): # sql 和 hint 都相同\n",
    "                    continue\n",
    "\n",
    "                if j[0].info['sql_str'] != k[0].info['sql_str'] and (j[0].info['latency'] == TIME_OUT or k[0].info['latency'] == TIME_OUT):\n",
    "                        continue\n",
    "                # if (j[0].info['latency'] == k[0].info['latency']): # latency 相同 1s之内不把他train_pair\n",
    "                if max(j[0].info['latency'],k[0].info['latency']) / min(j[0].info['latency'],k[0].info['latency']) < 1.2:\n",
    "                    continue\n",
    "                # if j[0].info['latency'] == 90000 or k[0].info['latency'] == 90000:\n",
    "                #     continue\n",
    "                tem = [j, k]\n",
    "                pairs.append(tem)\n",
    "    else:          \n",
    "        for eq in exp.keys():\n",
    "            for j in exp[eq]:\n",
    "                for k in exp[eq]:\n",
    "                    if j[0].info['sql_str'] != k[0].info['sql_str']:\n",
    "                        continue    \n",
    "\n",
    "                    if (j[0].info['sql_str'] == k[0].info['sql_str']) and (j[0].hint_str() == k[0].hint_str()): # sql 和 hint 都相同\n",
    "                        continue\n",
    "                    if j[0].info['sql_str'] != k[0].info['sql_str'] and (j[0].info['latency'] == TIME_OUT or k[0].info['latency'] == TIME_OUT):\n",
    "                        continue\n",
    "                    # if (j[0].info['latency'] == k[0].info['latency']): # latency 相同 1s之内不把他train_pair\n",
    "                    if max(j[0].info['latency'],k[0].info['latency']) / min(j[0].info['latency'],k[0].info['latency']) < 1.2:\n",
    "                        continue\n",
    "                    # if j[0].info['latency'] == 90000 or k[0].info['latency'] == 90000:\n",
    "                    #     continue\n",
    "                    tem = [j, k]\n",
    "                    pairs.append(tem)\n",
    "    return pairs\n",
    "\n",
    "prev_optimizer_state_dict = None\n",
    "model = Transformer_model\n",
    "model = PL_Leon(model, prev_optimizer_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# key = 'cc,cct1,cct2,cn,ct,it1,it2,k,kt,mc,mi,mi_idx,mk,t'\n",
    "\n",
    "# new_exp = {key:[]}\n",
    "# for item in exp['cc,cct1,cct2,cn,ct,it1,it2,k,kt,mc,mi,mi_idx,mk,t']:\n",
    "#     node, encoding, attn = item\n",
    "#     if (\"cn.country_code)::text <> '[de]'::text)\" in node.info['sql_str']):\n",
    "#         # print(\"Q36\")\n",
    "#         continue\n",
    "#     new_exp[key].append(item)\n",
    "\n",
    "# print(len(new_exp[key]))\n",
    "\n",
    "logger = pl_loggers.WandbLogger(save_dir=os.getcwd() + '/logs', name=\"test\", project='leon3')\n",
    "\n",
    "key = None\n",
    "train_pairs = Getpair(exp, key=key)\n",
    "leon_dataset = prepare_dataset(train_pairs, queryFeaturizer=queryFeaturizer)\n",
    "dataloader_train = DataLoader(leon_dataset, batch_size=512, shuffle=True, num_workers=0)\n",
    "# dataloader_val = DataLoader(leon_dataset, batch_size=512, shuffle=False, num_workers=0)\n",
    "dataset_val = BucketDataset(exp, keys=key)\n",
    "batch_sampler = BucketBatchSampler(dataset_val.buckets, batch_size=1)\n",
    "dataloader_val = DataLoader(dataset_val, batch_sampler=batch_sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/chenxu/miniconda3/envs/leon/lib/python3.8/site-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data1/chenxu/projects/LEONForPostgres__1/logs/wandb/run-20231226_203822-izq1j0s1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leon1/leon3/runs/izq1j0s1' target=\"_blank\">test</a></strong> to <a href='https://wandb.ai/leon1/leon3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/leon1/leon3' target=\"_blank\">https://wandb.ai/leon1/leon3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/leon1/leon3/runs/izq1j0s1' target=\"_blank\">https://wandb.ai/leon1/leon3/runs/izq1j0s1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name  | Type      | Params\n",
      "------------------------------------\n",
      "0 | model | SeqFormer | 196 K \n",
      "------------------------------------\n",
      "196 K     Trainable params\n",
      "0         Non-trainable params\n",
      "196 K     Total params\n",
      "0.785     Total estimated model params size (MB)\n",
      "/data1/chenxu/miniconda3/envs/leon/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n",
      "/data1/chenxu/miniconda3/envs/leon/lib/python3.8/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (20) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 20/20 [00:00<00:00, 26.74it/s, v_num=j0s1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 20/20 [00:00<00:00, 26.01it/s, v_num=j0s1]\n",
      "********************\n",
      "Current Accuracy For Each EqSet:  {}\n",
      "********************\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(accelerator=\"gpu\",\n",
    "                        devices=[0],\n",
    "                        max_epochs=500,\n",
    "                        callbacks=None,\n",
    "                        logger=logger)\n",
    "\n",
    "# trainer.fit(model, dataloader_train, dataloader_val)\n",
    "trainer.fit(model, dataloader_train)\n",
    "prev_optimizer_state_dict = trainer.optimizers[0].state_dict()\n",
    "\n",
    "print(\"*\"*20)\n",
    "print(\"Current Accuracy For Each EqSet: \", model.eq_summary)\n",
    "print(\"*\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3个sql\n",
    "********************\n",
    "Current Accuracy For Each EqSet:  {'cc,cct1,cct2,cn,ct,it1,it2,k,kt,mc,mi,mi_idx,mk,t': (0.8683127572016461, 243)}\n",
    "********************\n",
    "\n",
    "2个sql 不要q36\n",
    "********************\n",
    "Current Accuracy For Each EqSet:  {'cc,cct1,cct2,cn,ct,it1,it2,k,kt,mc,mi,mi_idx,mk,t': (0.7298444130127298, 707)}\n",
    "********************\n",
    "\n",
    "3个sql overfit train 500 epoch\n",
    "********************\n",
    "Current Accuracy For Each EqSet:  {'cc,cct1,cct2,cn,ct,it1,it2,k,kt,mc,mi,mi_idx,mk,t': (0.7086280056577087, 707)}\n",
    "********************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
