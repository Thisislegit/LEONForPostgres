{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "import lightning.pytorch.callbacks as plc\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from util import postgres\n",
    "from util import pg_executor\n",
    "from util import postgres\n",
    "from util import envs\n",
    "from util import plans_lib\n",
    "import pytorch_lightning.loggers as pl_loggers\n",
    "import pickle\n",
    "import math\n",
    "import json\n",
    "from test_case import SeqFormer\n",
    "from test_case import get_plan_encoding, configs, load_json, get_op_name_to_one_hot, plan_parameters, add_numerical_scalers\n",
    "from leon_experience import Experience\n",
    "import numpy as np\n",
    "import ray\n",
    "import time\n",
    "from argparse import ArgumentParser\n",
    "import copy\n",
    "import wandb\n",
    "import time\n",
    "import random\n",
    "DEVICE = 'cuda:2' if torch.cuda.is_available() else 'cpu'\n",
    "Transformer_model = SeqFormer(\n",
    "                        input_dim=configs['node_length'],\n",
    "                        hidden_dim=128,\n",
    "                        output_dim=1,\n",
    "                        mlp_activation=\"ReLU\",\n",
    "                        transformer_activation=\"gelu\",\n",
    "                        mlp_dropout=0.3,\n",
    "                        transformer_dropout=0.2,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PL_Leon(pl.LightningModule):\n",
    "    def __init__(self, model, optimizer_state_dict=None, learning_rate=0.001):\n",
    "        super(PL_Leon, self).__init__()\n",
    "        self.model = model\n",
    "        self.optimizer_state_dict = optimizer_state_dict\n",
    "        self.learning_rate = 0.001\n",
    "\n",
    "    def forward(self, batch_pairs):\n",
    "        pass\n",
    "\n",
    "    def getBatchPairsLoss(self, labels, costs1, costs2, encoded_plans1, encoded_plans2, attns1, attns2):\n",
    "\n",
    "        loss_fn = nn.BCELoss()\n",
    "        batsize = costs1.shape[0]\n",
    "        encoded_plans = torch.cat((encoded_plans1, encoded_plans2), dim=0)\n",
    "        attns = torch.cat((attns1, attns2), dim=0)\n",
    "        cali = self.model(encoded_plans, attns)\n",
    "        cali = cali[:, 0]\n",
    "        costs = torch.cat((costs1, costs2), dim=0)\n",
    "\n",
    "        calied_cost = torch.log(costs) * cali\n",
    "        try:\n",
    "            sigmoid = F.sigmoid(-(calied_cost[:batsize] - calied_cost[batsize:]))\n",
    "            loss = loss_fn(sigmoid, labels.float())\n",
    "        except:\n",
    "            print(calied_cost, sigmoid)\n",
    "        with torch.no_grad():\n",
    "            prediction = torch.round(sigmoid)\n",
    "            accuracy = torch.sum(prediction == labels).item() / len(labels)\n",
    "        return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(prev_optimizer_state_dict=None):\n",
    "    model = Transformer_model.to(DEVICE)\n",
    "    model = PL_Leon(model, prev_optimizer_state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeonDataset(Dataset):\n",
    "    def __init__(self, labels, costs1, costs2, encoded_plans1, encoded_plans2, attns1, attns2):\n",
    "        self.labels = labels\n",
    "        self.costs1 = costs1\n",
    "        self.costs2 = costs2\n",
    "        self.encoded_plans1 = encoded_plans1\n",
    "        self.encoded_plans2 = encoded_plans2\n",
    "        self.attns1 = attns1\n",
    "        self.attns2 = attns2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.labels[idx],\n",
    "                self.costs1[idx],\n",
    "                self.costs2[idx],\n",
    "                self.encoded_plans1[idx],\n",
    "                self.encoded_plans2[idx],\n",
    "                self.attns1[idx],\n",
    "                self.attns2[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(pairs):\n",
    "    labels = []\n",
    "    costs1 = []\n",
    "    costs2 = []\n",
    "    encoded_plans1 = []\n",
    "    encoded_plans2 = []\n",
    "    attns1 = []\n",
    "    attns2 = []\n",
    "    for pair in pairs:\n",
    "        if pair[0][0].info['latency'] > pair[1][0].info['latency']:\n",
    "            label = 0\n",
    "        else:\n",
    "            label = 1\n",
    "        labels.append(label)\n",
    "        costs1.append(pair[0][0].cost)\n",
    "        costs2.append(pair[1][0].cost)\n",
    "        encoded_plans1.append(pair[0][1])\n",
    "        encoded_plans2.append(pair[1][1])\n",
    "        attns1.append(pair[0][2])\n",
    "        attns2.append(pair[1][2])\n",
    "    labels = torch.tensor(labels)\n",
    "    costs1 = torch.tensor(costs1)\n",
    "    costs2 = torch.tensor(costs2)\n",
    "    encoded_plans1 = torch.stack(encoded_plans1)\n",
    "    encoded_plans2 = torch.stack(encoded_plans2)\n",
    "    attns1 = torch.stack(attns1)\n",
    "    attns2 = torch.stack(attns2)\n",
    "    dataset = LeonDataset(labels, costs1, costs2, encoded_plans1, encoded_plans2, attns1, attns2)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_callbacks(logger):\n",
    "    callbacks = []\n",
    "    callbacks.append(plc.EarlyStopping(\n",
    "        monitor='v_acc',\n",
    "        mode='max',\n",
    "        patience=3,\n",
    "        min_delta=0.001\n",
    "    ))\n",
    "    if logger:\n",
    "        callbacks.append(plc.ModelCheckpoint(\n",
    "            dirpath= logger.experiment.dir,\n",
    "            monitor='val_scan',\n",
    "            filename='best-{epoch:02d}-{val_scan:.3f}',\n",
    "            save_top_k=1,\n",
    "            mode='min',\n",
    "            save_last=False\n",
    "        ))\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Getpair(exp):\n",
    "    pairs = []\n",
    "    for eq in exp.keys():\n",
    "        for j in exp[eq]:\n",
    "            for k in exp[eq]:\n",
    "                if (j[0].info['sql_str'] == k[0].info['sql_str']) and (j[0].hint_str() == k[0].hint_str()): # sql 和 hint 都相同\n",
    "                    continue\n",
    "                if (j[0].info['latency'] == k[0].info['latency']): # latency 相同 1s之内不把他train_pair\n",
    "                # if max(j[0].info['latency'],k[0].info['latency']) / min(j[0].info['latency'],k[0].info['latency']) < 1.2:\n",
    "                    continue\n",
    "                tem = [j, k]\n",
    "                pairs.append(tem)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../log/exp.pkl', 'rb') as f:\n",
    "        exp = pickle.load(f)\n",
    "logger =  pl_loggers.WandbLogger(save_dir=os.getcwd() + '/../logs', name=\"base\", project='leon3')\n",
    "prev_optimizer_state_dict = None\n",
    "model = load_model().to(DEVICE)\n",
    "callbacks = load_callbacks(logger=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_pairs) 334674\n"
     ]
    }
   ],
   "source": [
    "train_pairs = Getpair(exp)\n",
    "print(\"len(train_pairs)\" ,len(train_pairs))\n",
    "leon_dataset = prepare_dataset(train_pairs)\n",
    "trainer = pl.Trainer(accelerator=\"gpu\",\n",
    "                        devices=[2],\n",
    "                        max_epochs=100,\n",
    "                        callbacks=callbacks,\n",
    "                        logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(leon_dataset, batch_size=256, shuffle=True, num_workers=0)\n",
    "dataloader_val = DataLoader(leon_dataset, batch_size=256, shuffle=False, num_workers=0)\n",
    "trainer.fit(model, dataloader_train, dataloader_val)\n",
    "prev_optimizer_state_dict = trainer.optimizers[0].state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
