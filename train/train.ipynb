{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "import lightning.pytorch.callbacks as plc\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import sys\n",
    "import pytorch_lightning.loggers as pl_loggers\n",
    "import pickle\n",
    "import math\n",
    "import json\n",
    "from test_case import SeqFormer\n",
    "from test_case import get_plan_encoding, configs, load_json, get_op_name_to_one_hot, plan_parameters, add_numerical_scalers\n",
    "from leon_experience import Experience\n",
    "import numpy as np\n",
    "import ray\n",
    "import time\n",
    "from argparse import ArgumentParser\n",
    "import copy\n",
    "import wandb\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "import pickle\n",
    "DEVICE = 'cuda:2' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../log/exp_v2.pkl', 'rb') as f:\n",
    "    exp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Getpair(exp):\n",
    "    pairs = []\n",
    "    for eq in exp.keys():\n",
    "        for j in exp[eq]:\n",
    "            for k in exp[eq]:\n",
    "                if (j[0].info['sql_str'] == k[0].info['sql_str']) and (j[0].hint_str() == k[0].hint_str()): # sql 和 hint 都相同\n",
    "                    continue\n",
    "                if j[0].info['sql_str'] != k[0].info['sql_str'] and (j[0].info['latency'] == 90000 or k[0].info['latency'] == 90000):\n",
    "                    continue\n",
    "                # if (j[0].info['latency'] == k[0].info['latency']): # latency 相同 1s之内不把他train_pair\n",
    "                if max(j[0].info['latency'],k[0].info['latency']) / min(j[0].info['latency'],k[0].info['latency']) < 1.2:\n",
    "                    continue\n",
    "                # if j[0].info['latency'] == 90000 or k[0].info['latency'] == 90000:\n",
    "                #     continue\n",
    "                tem = [j, k]\n",
    "                pairs.append(tem)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/data1/wyz/miniconda3/envs/leon/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:389: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/data1/wyz/miniconda3/envs/leon/lib/python3.8/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:639: Checkpoint directory /data1/wyz/online/LEONForPostgres/logs/leon3/8xbhajas/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name  | Type      | Params\n",
      "------------------------------------\n",
      "0 | model | SeqFormer | 48.8 K\n",
      "------------------------------------\n",
      "48.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "48.8 K    Total params\n",
      "0.195     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1472/1472 [00:52<00:00, 27.78it/s, v_num=ajas]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1472/1472 [00:53<00:00, 27.77it/s, v_num=ajas]\n",
      "********************\n",
      "Current Accuracy For Each EqSet:  {'ci,cn,k,mc,mk,t': (0.9175704989154013, 461), 'ci,cn,k,mc,mk,n,t': (0.9232693911592994, 1199), 'cc,cct1,cct2,ci,k,kt,mk,t': (0.8498402555910544, 313), 'ci,it1,it2,k,mi,mi_idx,mk,n,t': (0.9515545914678236, 1383), 'an1,ci,cn,mc,n1,rt,t': (0.8, 120), 'a1,ci,cn,mc,n1,rt,t': (0.7796610169491526, 59), 'cn,ct,it1,it2,mc,mi,mi_idx,t': (0.6201834862385321, 545), 'cc,cct1,cct2,ci,it1,it2,k,mi,mi_idx,mk,n,t': (0.9167008617152236, 2437), 'an,ci,k,mc,mk,n': (0.5454545454545454, 11), 'an,cc,cct1,cct2,chn,ci,cn,it,it3,k,mc,mi,mk,n,pi,rt,t': (0.8097269624573379, 1172), 'ci,k,mc,mk,n,t': (0.9015151515151515, 660), 'ci,it1,it2,mi,mi_idx': (0.15625, 32), 'cc,cct1,cct2,chn,ci,k,kt,mk,t': (0.8461538461538461, 533), 'ct,it,kt,mc,miidx,t': (1.0, 64), 'cn,it1,it2,mc,mi,mi_idx,t': (0.838150289017341, 346), 'cn,ct,it1,k,kt,mc,mi,mi_idx,mk,t': (0.9018733273862622, 1121), 'cn,ct,k,lt,mc,mk,ml,t': (0.9214285714285714, 420), 'an,ci,cn,it,mc,mi,n,rt,t': (0.8735177865612648, 253), 'it,mi_idx,mk,t': (0.8, 15), 'cc,cct1,cct2,cn,ct,k,kt,mc,mi,mi_idx,mk,t': (0.7918781725888325, 1773), 'chn,ci,cn,ct,mc,rt,t': (0.8589743589743589, 156), 'cc,cct1,cct2,chn,ci,it2,k,mi_idx,mk,n,t': (0.8918918918918919, 333), 'cc,cct1,cct2,cn,ct,k,mc,mi,mk,ml,t': (0.7703703703703704, 405), 'chn,ci,cn,mc,n,rt': (1.0, 98), 'an,ci,lt,ml,n,pi,t': (0.7837837837837838, 185), 'cc,cct1,cct2,cn,ct,it1,it2,k,kt,mc,mi,mi_idx,mk,t': (0.8192955589586524, 3265), 'ci,lt,ml,n,pi,t': (0.925, 40), 'ct,mc,mi,t': (0.8947368421052632, 95), 'it,k,mi_idx,mk,t': (0.8421052631578947, 38), 'cn,ct,k,lt,mc,mk,ml': (0.6703296703296703, 91), 'an,chn,ci,cn,it,mc,mi,n,t': (0.8327137546468402, 269), 'cc,cct1,cct2,chn,ci,it2,k,kt,mi_idx,mk,n,t': (0.9144144144144144, 666), 'k,lt,mk,ml,t1,t2': (0.8333333333333334, 60), 'chn,ci,cn,mc,n,rt,t': (0.9394812680115274, 347), 'an,chn,ci,mc,n,rt,t': (0.9806295399515739, 413), 'ci,k,mk,n,t': (0.9522613065326633, 398), 'ci,it1,it2,mi,mi_idx,n': (0.8111888111888111, 143), 'ci,cn,it1,it2,mc,mi,mi_idx,mk,n,t': (0.9440203562340967, 393), 'at,cn,ct,it1,k,mc,mi,mk,t': (0.9452054794520548, 292), 'an,ci,it,lt,ml,n,pi,t': (0.8709677419354839, 248), 'cc,cct1,cn,it1,kt,mc,mi,mk,t': (0.8345454545454546, 1100), 'ci,k,mi,mi_idx,mk,n,t': (0.9422110552763819, 398), 'chn,ci,cn,it,mc,mi,n,rt,t': (0.7175141242937854, 177), 'cn,ct,it,kt,mc,mi,miidx,t': (0.8638743455497382, 382), 'cn,ct,k,lt,mc,mi,mk,ml,t': (0.8765060240963856, 664), 'cn,it2,k,kt,mc,mi,mi_idx,mk,t': (0.9245901639344263, 305), 'cc,cct1,cn,it1,k,kt,mc,mi,mk,t': (0.7664027149321267, 1768), 'cc,cct1,cct2,cn,ct,k,lt,mc,mi,mk,ml,t': (0.9336585365853659, 1025), 'ci,it1,it2,mi,mi_idx,n,t': (0.8762214983713354, 307), 'an1,ci,cn,mc,rt,t': (0.9032258064516129, 31), 'cn1,cn2,it1,it2,kt1,kt2,lt,mc1,mc2,mi_idx1,mi_idx2,ml,t1,t2': (0.8357771260997068, 682), 'an,cc,cct1,cct2,chn,ci,cn,k,mc,mi,mk,n,pi,rt,t': (0.5833333333333334, 72), 'cc,cct1,cct2,chn,ci,k,kt,mk,n,t': (0.7651869158878505, 856), 'it1,it2,k,kt,mi,mi_idx,mk,t': (0.9118086696562033, 669), 'chn,ci,ct,mc,rt,t': (0.8888888888888888, 45), 'k,mc,mk,t': (0.9489795918367347, 196), 'cn,k,lt,mc,mk,ml,t': (0.8618421052631579, 152), 'k,mk,ml,t1,t2': (1.0, 16), 'aka_t,cn,ct,it1,k,mc,mi,mk,t': (0.9671052631578947, 152), 'cn,ct,it1,k,mc,mi,mk,t': (0.8896551724137931, 290), 'ct,k,lt,mc,mk,ml': (0.7758620689655172, 58), 'ci,k,mk,t': (0.9475806451612904, 248), 'cn,ct,it,it2,kt,mc,mi,miidx,t': (0.7704081632653061, 392), 'ci,k,mc,mk,n': (0.9517241379310345, 145), 'cn,ct,it2,k,kt,mc,mi,mi_idx,mk,t': (0.8605028386050284, 1233), 'an,chn,ci,cn,mc,n,rt,t': (0.9618441971383148, 629), 'cc,cct1,cct2,chn,ci,it2,k,kt,mi_idx,mk,t': (0.886535552193646, 661), 'an,ci,cn,k,mc,mk,n,t': (0.9340277777777778, 288), 'an,cc,cct1,cct2,chn,ci,cn,it,k,mc,mi,mk,n,pi,rt,t': (0.5942028985507246, 69), 'an,ci,cn,k,mc,mk,t': (0.9121338912133892, 239), 'cn,k,lt,mc,mi,mk,ml,t': (0.9013698630136986, 365), 'an,chn,ci,cn,it,k,mc,mi,mk,n,rt,t': (0.8978246539222149, 1517), 'an,ci,cn,mc,n,rt,t': (0.9518987341772152, 395), 'cc,cct1,cct2,cn,ct,k,lt,mc,mi,mk,ml': (0.9098143236074271, 377), 'ct,mc,mi_idx,t': (0.9041916167664671, 167), 'cc,cct1,cct2,cn,ct,it2,k,kt,mc,mi,mi_idx,mk,t': (0.8385115606936416, 2768), 'cn1,cn2,it1,it2,kt1,lt,mc1,mc2,mi_idx1,mi_idx2,ml,t1,t2': (0.8904507998061076, 4126), 'cn,k,mc,mk': (0.8309859154929577, 213), 'k,mi,mk,t': (0.9148936170212766, 141), 'at,cn,ct,k,mc,mi,mk,t': (0.9416243654822335, 394), 'it,mc,mi_idx,t': (0.9047619047619048, 21), 'cc,cct1,cn,ct,it1,k,kt,mc,mi,mk,t': (0.7557776389756402, 1601), 'cc,cct1,cct2,ci,k,mi,mi_idx,mk,n,t': (0.9770642201834863, 654), 'an,ci,k,mc,mk,n,t': (0.8205128205128205, 195), 'ci,cn,it1,it2,k,mc,mi,mi_idx,mk,n,t': (0.9438377535101404, 1282), 'ci,it2,k,mi,mi_idx,mk,n,t': (0.9331823329558324, 883), 'cc,cct1,cct2,ci,it2,k,mi,mi_idx,mk,n,t': (0.8700120918984281, 1654), 'cn,ct,it,kt,mc,miidx,t': (0.875, 88), 'an,chn,ci,cn,it,k,mc,mi,mk,n,t': (0.9092542677448338, 1113), 'k,kt,mi,mi_idx,mk,t': (0.9470198675496688, 302), 'ci,k,mk,n': (0.66, 50), 'chn,ci,cn,ct,mc,t': (0.76, 50), 'cn,ct,k,mc,mk,t': (0.8809523809523809, 462), 'cn,ct,it1,it2,k,kt,mc,mi,mi_idx,mk,t': (0.7633587786259542, 1572), 'it1,it2,mc,mi,mi_idx,t': (0.8602150537634409, 93), 'ct,it,mc,mi,t': (0.0, 4), 'it,k,mi_idx,mk': (0.47368421052631576, 19), 'cn1,cn2,it1,it2,kt2,lt,mc1,mc2,mi_idx1,mi_idx2,ml,t1,t2': (0.9435079726651481, 2195), 'ct,it,mc,mi_idx,t': (0.8108108108108109, 74), 'an,chn,ci,cn,it,mc,mi,n,rt,t': (0.9145038167938931, 655), 'it2,k,kt,mi,mi_idx,mk,t': (0.9423963133640553, 434), 'cn,k,mc,mk,t': (0.8947368421052632, 437)}\n",
      "********************\n"
     ]
    }
   ],
   "source": [
    "from util.dataset import *\n",
    "from util.model import *\n",
    "DEVICE = 'cuda:2' if torch.cuda.is_available() else 'cpu'\n",
    "Transformer_model = SeqFormer(\n",
    "                        input_dim=configs['node_length'],\n",
    "                        hidden_dim=256,\n",
    "                        output_dim=1,\n",
    "                        mlp_activation=\"ReLU\",\n",
    "                        transformer_activation=\"gelu\",\n",
    "                        mlp_dropout=0.1,\n",
    "                        transformer_dropout=0.1,\n",
    "                    )\n",
    "prev_optimizer_state_dict = None\n",
    "model = Transformer_model.to(DEVICE)\n",
    "model = PL_Leon(model, prev_optimizer_state_dict)\n",
    "train_pairs = Getpair(exp)\n",
    "leon_dataset = prepare_dataset(train_pairs)\n",
    "dataloader_train = DataLoader(leon_dataset, batch_size=256, shuffle=True, num_workers=0)\n",
    "# dataloader_val = DataLoader(leon_dataset, batch_size=256, shuffle=False, num_workers=0)\n",
    "dataset_val = BucketDataset(exp, keys=exp.keys())\n",
    "batch_sampler = BucketBatchSampler(dataset_val.buckets, batch_size=1)\n",
    "dataloader_val = DataLoader(dataset_val, batch_sampler=batch_sampler)\n",
    "# model = load_model(model_path, prev_optimizer_state_dict).to(DEVICE)\n",
    "model.optimizer_state_dict = prev_optimizer_state_dict\n",
    "current_directory = os.getcwd()\n",
    "# 获取上一级目录\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "logger =  pl_loggers.WandbLogger(save_dir=parent_directory + '/logs', name=\"exp_pair\", project='leon3')\n",
    "trainer = pl.Trainer(accelerator=\"gpu\",\n",
    "                    devices=[2],\n",
    "                    max_epochs=10,\n",
    "                    logger=logger)\n",
    "trainer.fit(model, dataloader_train, dataloader_val)\n",
    "prev_optimizer_state_dict = trainer.optimizers[0].state_dict()\n",
    "print(\"*\"*20)\n",
    "print(\"Current Accuracy For Each EqSet: \", model.eq_summary)\n",
    "print(\"*\"*20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
