{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "import lightning.pytorch.callbacks as plc\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import pytorch_lightning.loggers as pl_loggers\n",
    "import pickle\n",
    "import math\n",
    "import json\n",
    "from test_case import configs\n",
    "import numpy as np\n",
    "import wandb\n",
    "import random\n",
    "DEVICE = 'cuda:2' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqFormer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        hidden_dim,\n",
    "        output_dim,\n",
    "        mlp_activation=\"ReLU\",\n",
    "        transformer_activation=\"gelu\",\n",
    "        mlp_dropout=0.1,\n",
    "        transformer_dropout=0.1,\n",
    "    ):\n",
    "        super(SeqFormer, self).__init__()\n",
    "        # input_dim: node bits\n",
    "        self.tranformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=input_dim,\n",
    "                dim_feedforward=hidden_dim,\n",
    "                nhead=3,\n",
    "                batch_first=True,\n",
    "                activation=transformer_activation,\n",
    "                dropout=transformer_dropout,\n",
    "            ),\n",
    "            num_layers=1,\n",
    "        )\n",
    "        self.node_length = input_dim\n",
    "        if mlp_activation == \"ReLU\":\n",
    "            self.mlp_activation = nn.ReLU()\n",
    "        elif mlp_activation == \"GELU\":\n",
    "            self.mlp_activation = nn.GELU()\n",
    "        elif mlp_activation == \"LeakyReLU\":\n",
    "            self.mlp_activation = nn.LeakyReLU()\n",
    "        # self.mlp_hidden_dims = [128, 64, 32]\n",
    "        self.mlp_hidden_dims = [256, 128, 1]\n",
    "        self.mlp = nn.Sequential(\n",
    "            *[\n",
    "                nn.Linear(self.node_length, self.mlp_hidden_dims[0]),\n",
    "                nn.Dropout(mlp_dropout),\n",
    "                self.mlp_activation,\n",
    "                nn.Linear(self.mlp_hidden_dims[0], self.mlp_hidden_dims[1]),\n",
    "                nn.Dropout(mlp_dropout),\n",
    "                self.mlp_activation,\n",
    "                nn.Linear(self.mlp_hidden_dims[1], output_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.apply(self._init_weights)\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        # change x shape to (batch, seq_len, input_size) from (batch, len)\n",
    "        # one node is 18 bits\n",
    "        # x = x.view(x.shape[0], self.node_length, -1)\n",
    "        # x = x.transpose(1,2)\n",
    "        x = x.view(x.shape[0], -1, self.node_length)\n",
    "        # attn_mask = attn_mask.repeat(4,1,1)\n",
    "        attn_mask = attn_mask.repeat(1, 3, 1, 1)\n",
    "        out = self.tranformer_encoder(x, mask=attn_mask)\n",
    "        # out = self.transformer_decoder(out, out, tgt_mask=attn_mask)\n",
    "        out = self.mlp(out)\n",
    "        # out = (torch.tanh(out).squeeze(dim=2) * 5).add(5) \n",
    "        # out = torch.tanh(out).squeeze(dim=2).add(1) * 5\n",
    "        out = torch.tanh(out).squeeze(dim=2).add(1)\n",
    "        return out # [0, 1] -> [1, 2] [??]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/wyz/miniconda3/envs/leon/lib/python3.8/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "Transformer_model = SeqFormer(\n",
    "                        input_dim=configs['node_length'],\n",
    "                        hidden_dim=256,\n",
    "                        output_dim=1,\n",
    "                        mlp_activation=\"ReLU\",\n",
    "                        transformer_activation=\"gelu\",\n",
    "                        mlp_dropout=0.1,\n",
    "                        transformer_dropout=0.1,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PL_Leon(pl.LightningModule):\n",
    "    def __init__(self, model, optimizer_state_dict=None, learning_rate=0.001):\n",
    "        super(PL_Leon, self).__init__()\n",
    "        self.model = model\n",
    "        self.optimizer_state_dict = optimizer_state_dict\n",
    "        self.learning_rate = 0.001\n",
    "\n",
    "    def forward(self, batch_pairs):\n",
    "        pass\n",
    "\n",
    "    def getBatchPairsLoss(self, labels, costs1, costs2, encoded_plans1, encoded_plans2, attns1, attns2):\n",
    "        \"\"\"\n",
    "        batch_pairs: a batch of train pairs\n",
    "        return. a batch of loss\n",
    "        \"\"\"\n",
    "        loss_fn = nn.BCELoss()\n",
    "        batsize = costs1.shape[0]\n",
    "        encoded_plans = torch.cat((encoded_plans1, encoded_plans2), dim=0)\n",
    "        attns = torch.cat((attns1, attns2), dim=0)\n",
    "        cali = self.model(encoded_plans, attns) # cali.shape [# of plan, pad_length] cali 是归一化后的基数估计\n",
    "        cali = cali[:, 0]\n",
    "        costs = torch.cat((costs1, costs2), dim=0)\n",
    "        calied_cost = torch.log(costs) * cali\n",
    "        try:\n",
    "            sigmoid = F.sigmoid(-(calied_cost[:batsize] - calied_cost[batsize:]))\n",
    "            loss = loss_fn(sigmoid, labels.float())\n",
    "        except:\n",
    "            print(calied_cost, sigmoid)\n",
    "        with torch.no_grad():\n",
    "            prediction = torch.round(sigmoid)\n",
    "            accuracy = torch.sum(prediction == labels).item() / len(labels)\n",
    "        return loss, accuracy\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        labels, costs1, costs2, encoded_plans1, encoded_plans2, attns1, attns2, latency1, latency2 = batch\n",
    "        loss, acc  = self.getBatchPairsLoss(labels, costs1, costs2, encoded_plans1, encoded_plans2, attns1, attns2)\n",
    "        # loss = (torch.abs(latency1 - latency2) * loss / 90000).mean()\n",
    "        self.log_dict({'t_loss': loss, 't_acc': acc}, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        labels, costs1, costs2, encoded_plans1, encoded_plans2, attns1, attns2, latency1, latency2 = batch\n",
    "        loss, acc  = self.getBatchPairsLoss(labels, costs1, costs2, encoded_plans1, encoded_plans2, attns1, attns2)\n",
    "        # loss = (torch.abs(latency1 - latency2) * loss / 90000).mean()\n",
    "        self.log_dict({'v_loss': loss, 'v_acc': acc}, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=0.001)\n",
    "        if self.optimizer_state_dict is not None:\n",
    "            curr = optimizer.state_dict()['param_groups'][0]['params']\n",
    "            prev = self.optimizer_state_dict['param_groups'][0]['params']\n",
    "            assert curr == prev, (curr, prev)\n",
    "            optimizer.load_state_dict(self.optimizer_state_dict)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = self.learning_rate\n",
    "            assert optimizer.state_dict(\n",
    "            )['param_groups'][0]['lr'] == self.learning_rate\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(prev_optimizer_state_dict=None):\n",
    "    model = Transformer_model.to(DEVICE)\n",
    "    model = PL_Leon(model, prev_optimizer_state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeonDataset(Dataset):\n",
    "    def __init__(self, labels, costs1, costs2, encoded_plans1, encoded_plans2, attns1, attns2, latency1, latency2):\n",
    "        self.labels = labels\n",
    "        self.costs1 = costs1\n",
    "        self.costs2 = costs2\n",
    "        self.encoded_plans1 = encoded_plans1\n",
    "        self.encoded_plans2 = encoded_plans2\n",
    "        self.attns1 = attns1\n",
    "        self.attns2 = attns2\n",
    "        self.latency1 = latency1\n",
    "        self.latency2 = latency2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.labels[idx],\n",
    "                self.costs1[idx],\n",
    "                self.costs2[idx],\n",
    "                self.encoded_plans1[idx],\n",
    "                self.encoded_plans2[idx],\n",
    "                self.attns1[idx],\n",
    "                self.attns2[idx],\n",
    "                self.latency1[idx],\n",
    "                self.latency2[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(pairs):\n",
    "    labels = []\n",
    "    costs1 = []\n",
    "    costs2 = []\n",
    "    encoded_plans1 = []\n",
    "    encoded_plans2 = []\n",
    "    attns1 = []\n",
    "    attns2 = []\n",
    "    latency1 = []\n",
    "    latency2 = []\n",
    "    for pair in pairs:\n",
    "        if pair[0][0].info['latency'] > pair[1][0].info['latency']:\n",
    "            label = 0\n",
    "        else:\n",
    "            label = 1\n",
    "        labels.append(label)\n",
    "        costs1.append(pair[0][0].cost)\n",
    "        costs2.append(pair[1][0].cost)\n",
    "        encoded_plans1.append(pair[0][1])\n",
    "        encoded_plans2.append(pair[1][1])\n",
    "        attns1.append(pair[0][2])\n",
    "        attns2.append(pair[1][2])\n",
    "        latency1.append(pair[0][0].info['latency'])\n",
    "        latency2.append(pair[1][0].info['latency'])\n",
    "    labels = torch.tensor(labels)\n",
    "    costs1 = torch.tensor(costs1)\n",
    "    costs2 = torch.tensor(costs2)\n",
    "    encoded_plans1 = torch.stack(encoded_plans1)\n",
    "    encoded_plans2 = torch.stack(encoded_plans2)\n",
    "    attns1 = torch.stack(attns1)\n",
    "    attns2 = torch.stack(attns2)\n",
    "    latency1 = torch.tensor(latency1)\n",
    "    latency2 = torch.tensor(latency2)\n",
    "    dataset = LeonDataset(labels, costs1, costs2, encoded_plans1, encoded_plans2, attns1, attns2, latency1, latency2)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_callbacks(logger):\n",
    "    callbacks = []\n",
    "    callbacks.append(plc.EarlyStopping(\n",
    "        monitor='v_acc',\n",
    "        mode='max',\n",
    "        patience=5,\n",
    "        min_delta=0.001\n",
    "    ))\n",
    "    if logger:\n",
    "        callbacks.append(plc.ModelCheckpoint(\n",
    "            dirpath= logger.experiment.dir,\n",
    "            monitor='val_scan',\n",
    "            filename='best-{epoch:02d}-{val_scan:.3f}',\n",
    "            save_top_k=1,\n",
    "            mode='min',\n",
    "            save_last=False\n",
    "        ))\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Getpair(exp):\n",
    "    pairs = []\n",
    "    for eq in exp.keys():\n",
    "        for j in exp[eq]:\n",
    "            for k in exp[eq]:\n",
    "                if (j[0].info['sql_str'] == k[0].info['sql_str']) and (j[0].hint_str() == k[0].hint_str()): # sql 和 hint 都相同\n",
    "                    continue\n",
    "                # if (j[0].info['latency'] == k[0].info['latency']): # latency 相同 1s之内不把他train_pair\n",
    "                if max(j[0].info['latency'],k[0].info['latency']) / min(j[0].info['latency'],k[0].info['latency']) < 1.2:\n",
    "                    continue\n",
    "                # if j[0].info['latency'] == 90000 or k[0].info['latency'] == 90000:\n",
    "                #     continue\n",
    "                tem = [j, k]\n",
    "                pairs.append(tem)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../log/exp.pkl', 'rb') as f:\n",
    "        exp = pickle.load(f)\n",
    "current_directory = os.getcwd()\n",
    "# 获取上一级目录\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "logger =  pl_loggers.WandbLogger(save_dir=parent_directory + '/logs', name=\"embedding mlp\", project='leon3')\n",
    "prev_optimizer_state_dict = None\n",
    "model = load_model().to(DEVICE)\n",
    "callbacks = load_callbacks(logger=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "cn,k,mc,mk,t 458\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "filtered_keys = [key for key in exp.keys() if len(key) > 10 and len(exp[key]) < 500 and len(exp[key]) > 457]\n",
    "print(len(filtered_keys))\n",
    "for eq in filtered_keys:\n",
    "    print(eq, len(exp[eq]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_pairs) 1228676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "train_pairs = Getpair(exp)\n",
    "print(\"len(train_pairs)\" ,len(train_pairs))\n",
    "leon_dataset = prepare_dataset(train_pairs)\n",
    "trainer = pl.Trainer(accelerator=\"gpu\",\n",
    "                        devices=[2],\n",
    "                        max_epochs=40,\n",
    "                        logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwyz12234\u001b[0m (\u001b[33mleon1\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data1/wyz/online/LEONForPostgres/logs/wandb/run-20231222_134823-7f0pixmy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leon1/leon3/runs/7f0pixmy' target=\"_blank\">embedding mlp</a></strong> to <a href='https://wandb.ai/leon1/leon3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/leon1/leon3' target=\"_blank\">https://wandb.ai/leon1/leon3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/leon1/leon3/runs/7f0pixmy' target=\"_blank\">https://wandb.ai/leon1/leon3/runs/7f0pixmy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name  | Type      | Params\n",
      "------------------------------------\n",
      "0 | model | SeqFormer | 48.8 K\n",
      "------------------------------------\n",
      "48.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "48.8 K    Total params\n",
      "0.195     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/wyz/miniconda3/envs/leon/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The shape of the 3D attn_mask is torch.Size([1024, 40, 40]), but should be (3072, 40, 40).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/data1/wyz/online/LEONForPostgres/train/train copy.ipynb 单元格 13\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B121.48.161.202:22/data1/wyz/online/LEONForPostgres/train/train%20copy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m dataloader_train \u001b[39m=\u001b[39m DataLoader(leon_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B121.48.161.202:22/data1/wyz/online/LEONForPostgres/train/train%20copy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m dataloader_val \u001b[39m=\u001b[39m DataLoader(leon_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B121.48.161.202:22/data1/wyz/online/LEONForPostgres/train/train%20copy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model, dataloader_train, dataloader_val)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B121.48.161.202:22/data1/wyz/online/LEONForPostgres/train/train%20copy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m prev_optimizer_state_dict \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39moptimizers[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mstate_dict()\n",
      "File \u001b[0;32m~/miniconda3/envs/leon/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m TrainerStatus\u001b[39m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    545\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    546\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/leon/lib/python3.8/site-packages/lightning/pytorch/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     46\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/leon/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    582\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/leon/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py:989\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    986\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 989\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m    991\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    992\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    994\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/leon/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py:1033\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[1;32m   1032\u001b[0m     \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1033\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check()\n\u001b[1;32m   1034\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1035\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/miniconda3/envs/leon/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py:1062\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1059\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1061\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1062\u001b[0m val_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   1064\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1066\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/leon/lib/python3.8/site-packages/lightning/pytorch/loops/utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     context_manager \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mno_grad\n\u001b[1;32m    181\u001b[0m \u001b[39mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 182\u001b[0m     \u001b[39mreturn\u001b[39;00m loop_run(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/leon/lib/python3.8/site-packages/lightning/pytorch/loops/evaluation_loop.py:134\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mis_last_batch \u001b[39m=\u001b[39m data_fetcher\u001b[39m.\u001b[39mdone\n\u001b[1;32m    133\u001b[0m     \u001b[39m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n\u001b[1;32m    135\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m     \u001b[39m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/leon/lib/python3.8/site-packages/lightning/pytorch/loops/evaluation_loop.py:391\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    385\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest_step\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    386\u001b[0m step_args \u001b[39m=\u001b[39m (\n\u001b[1;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    388\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    389\u001b[0m     \u001b[39melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    390\u001b[0m )\n\u001b[0;32m--> 391\u001b[0m output \u001b[39m=\u001b[39m call\u001b[39m.\u001b[39;49m_call_strategy_hook(trainer, hook_name, \u001b[39m*\u001b[39;49mstep_args)\n\u001b[1;32m    393\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n\u001b[1;32m    395\u001b[0m \u001b[39mif\u001b[39;00m using_dataloader_iter:\n\u001b[1;32m    396\u001b[0m     \u001b[39m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/leon/lib/python3.8/site-packages/lightning/pytorch/trainer/call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 309\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    311\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    312\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/miniconda3/envs/leon/lib/python3.8/site-packages/lightning/pytorch/strategies/strategy.py:403\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module:\n\u001b[1;32m    402\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_redirection(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module, \u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 403\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlightning_module\u001b[39m.\u001b[39;49mvalidation_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m/data1/wyz/online/LEONForPostgres/train/train copy.ipynb 单元格 13\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B121.48.161.202:22/data1/wyz/online/LEONForPostgres/train/train%20copy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalidation_step\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B121.48.161.202:22/data1/wyz/online/LEONForPostgres/train/train%20copy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m     labels, costs1, costs2, encoded_plans1, encoded_plans2, attns1, attns2, latency1, latency2 \u001b[39m=\u001b[39m batch\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B121.48.161.202:22/data1/wyz/online/LEONForPostgres/train/train%20copy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m     loss, acc  \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgetBatchPairsLoss(labels, costs1, costs2, encoded_plans1, encoded_plans2, attns1, attns2)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B121.48.161.202:22/data1/wyz/online/LEONForPostgres/train/train%20copy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39m# loss = (torch.abs(latency1 - latency2) * loss / 90000).mean()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B121.48.161.202:22/data1/wyz/online/LEONForPostgres/train/train%20copy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_dict({\u001b[39m'\u001b[39m\u001b[39mv_loss\u001b[39m\u001b[39m'\u001b[39m: loss, \u001b[39m'\u001b[39m\u001b[39mv_acc\u001b[39m\u001b[39m'\u001b[39m: acc}, on_epoch\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32m/data1/wyz/online/LEONForPostgres/train/train copy.ipynb 单元格 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B121.48.161.202:22/data1/wyz/online/LEONForPostgres/train/train%20copy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m encoded_plans \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((encoded_plans1, encoded_plans2), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B121.48.161.202:22/data1/wyz/online/LEONForPostgres/train/train%20copy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m attns \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((attns1, attns2), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B121.48.161.202:22/data1/wyz/online/LEONForPostgres/train/train%20copy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m cali \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(encoded_plans, attns) \u001b[39m# cali.shape [# of plan, pad_length] cali 是归一化后的基数估计\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B121.48.161.202:22/data1/wyz/online/LEONForPostgres/train/train%20copy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m cali \u001b[39m=\u001b[39m cali[:, \u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B121.48.161.202:22/data1/wyz/online/LEONForPostgres/train/train%20copy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m costs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((costs1, costs2), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/leon/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/leon/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/data1/wyz/online/LEONForPostgres/train/train copy.ipynb 单元格 13\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B121.48.161.202:22/data1/wyz/online/LEONForPostgres/train/train%20copy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_length)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B121.48.161.202:22/data1/wyz/online/LEONForPostgres/train/train%20copy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39m# attn_mask = attn_mask.repeat(4,1,1)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B121.48.161.202:22/data1/wyz/online/LEONForPostgres/train/train%20copy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtranformer_encoder(x, mask\u001b[39m=\u001b[39;49mattn_mask)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B121.48.161.202:22/data1/wyz/online/LEONForPostgres/train/train%20copy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39m# out = self.transformer_decoder(out, out, tgt_mask=attn_mask)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B121.48.161.202:22/data1/wyz/online/LEONForPostgres/train/train%20copy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp(out)\n",
      "File \u001b[0;32m~/miniconda3/envs/leon/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/leon/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/leon/lib/python3.8/site-packages/torch/nn/modules/transformer.py:387\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    384\u001b[0m is_causal \u001b[39m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    386\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> 387\u001b[0m     output \u001b[39m=\u001b[39m mod(output, src_mask\u001b[39m=\u001b[39;49mmask, is_causal\u001b[39m=\u001b[39;49mis_causal, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask_for_layers)\n\u001b[1;32m    389\u001b[0m \u001b[39mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    390\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mto_padded_tensor(\u001b[39m0.\u001b[39m, src\u001b[39m.\u001b[39msize())\n",
      "File \u001b[0;32m~/miniconda3/envs/leon/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/leon/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/leon/lib/python3.8/site-packages/torch/nn/modules/transformer.py:707\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    705\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x))\n\u001b[1;32m    706\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sa_block(x, src_mask, src_key_padding_mask, is_causal\u001b[39m=\u001b[39;49mis_causal))\n\u001b[1;32m    708\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(x))\n\u001b[1;32m    710\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/leon/lib/python3.8/site-packages/torch/nn/modules/transformer.py:715\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sa_block\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor,\n\u001b[1;32m    714\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 715\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(x, x, x,\n\u001b[1;32m    716\u001b[0m                        attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m    717\u001b[0m                        key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[1;32m    718\u001b[0m                        need_weights\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, is_causal\u001b[39m=\u001b[39;49mis_causal)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    719\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/leon/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/leon/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/leon/lib/python3.8/site-packages/torch/nn/modules/activation.py:1241\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1228\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[1;32m   1229\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1239\u001b[0m         is_causal\u001b[39m=\u001b[39mis_causal)\n\u001b[1;32m   1240\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1241\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[1;32m   1242\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[1;32m   1243\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n\u001b[1;32m   1244\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n\u001b[1;32m   1245\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m   1246\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[1;32m   1247\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[1;32m   1248\u001b[0m         need_weights\u001b[39m=\u001b[39;49mneed_weights,\n\u001b[1;32m   1249\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m   1250\u001b[0m         average_attn_weights\u001b[39m=\u001b[39;49maverage_attn_weights,\n\u001b[1;32m   1251\u001b[0m         is_causal\u001b[39m=\u001b[39;49mis_causal)\n\u001b[1;32m   1252\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n\u001b[1;32m   1253\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/miniconda3/envs/leon/lib/python3.8/site-packages/torch/nn/functional.py:5323\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5321\u001b[0m     correct_3d_size \u001b[39m=\u001b[39m (bsz \u001b[39m*\u001b[39m num_heads, tgt_len, src_len)\n\u001b[1;32m   5322\u001b[0m     \u001b[39mif\u001b[39;00m attn_mask\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m correct_3d_size:\n\u001b[0;32m-> 5323\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe shape of the 3D attn_mask is \u001b[39m\u001b[39m{\u001b[39;00mattn_mask\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m, but should be \u001b[39m\u001b[39m{\u001b[39;00mcorrect_3d_size\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   5324\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   5325\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mattn_mask\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms dimension \u001b[39m\u001b[39m{\u001b[39;00mattn_mask\u001b[39m.\u001b[39mdim()\u001b[39m}\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The shape of the 3D attn_mask is torch.Size([1024, 40, 40]), but should be (3072, 40, 40)."
     ]
    }
   ],
   "source": [
    "dataloader_train = DataLoader(leon_dataset, batch_size=512, shuffle=True, num_workers=0)\n",
    "dataloader_val = DataLoader(leon_dataset, batch_size=512, shuffle=False, num_workers=0)\n",
    "trainer.fit(model, dataloader_train, dataloader_val)\n",
    "prev_optimizer_state_dict = trainer.optimizers[0].state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
